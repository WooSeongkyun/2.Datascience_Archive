# 5장 정규선형모델

## 1.단순회귀: 연속형 독립변수가 하나인 경우

### 1. 분석준비

```python
#수치 계산에 쓰이는 라이브러리
import numpy as np
import pandas as pd
import scipy as sp
import scipy as sp
from scipy import stats
#시각화에 쓰이는 라이브러리
from matplotlib import pyplot as plt
import seaborn as sns
sns.set()
#선형모델을 추정하는 라이브러리(경고가 나올수 있다)
import statsmodels.formula.api as smf
import statsmodels.api as sm
#표시 자릿수 지정
%precision 3
#그래프를 주피터 노트북에 그리기 위한 설정
%matplotlib inline

#데이터 받아오기
beer= pd.read_csv('sample/5-1-1-beer.csv')
#산포도 그리기
sns.jointplot(x='temperature',y='beer', data=beer,color='black')
```

![Untitled](1%20데이터과학%20및%20수학%20아카이브/파이썬과%20통계학/레퍼런스_5장%20정규선형모델/Untitled.png)

### 2.모델 설정

- 맥주매상 $y$~$N(\beta_0+\beta_1 t,\sigma^2)$이라 (정규분포형태라) 가정
- 독립변수를 기온 $t$, 종속변수를 맥주 매상 $y$로 둔 정규선형모델
- $\sigma^2$는 장애모수이니 무시하고, 파라미터 추정으로 $\beta_0,\beta_1$을 추정한다

### 3. $statsmodel$을 이용한 모델링

```python
#ols는 Ordinary Least Squares(범용최소제곱법)의 약자. 모집단의 분포가 정규분포임을 가정했을
#떄 최대우도법의 결과는 최소제곱법의 결과와 일치한다
lm_model=smf.ols(formula='beer~temperature',data=beer).fit()
#추정 결과 표시
lm_model.summary()

result)
           coef	    std    err	  t	P>|t|	[0.025	0.975]
Intercept	  34.6102	3.235	10.699	0.000	27.984	41.237
temperature	0.7654	0.144	5.334	0.000	0.471	1.059

Dep. Variable:	beer	R-squared:	0.504
Model:	OLS	Adj. R-squared:	0.486
Method:	Least Squares	F-statistic:	28.45
Date:	Tue, 12 Apr 2022	Prob (F-statistic):	1.11e-05
Time:	14:11:28	Log-Likelihood:	-102.45
No. Observations:	30	AIC:	208.9
Df Residuals:	28	BIC:	211.7
Df Model:	1		
Covariance Type:	nonrobust
```

- Intercept: $\beta_0$
- temperature: $\beta_1$
- coef: 계숫값
- std/err/t :계수의 표준오차, t값/귀무가설을 계수값이 0이라고 했을 때 p값/하측 신뢰구간/상측 신뢰구간
    - Dep.Variable: 종속 변수 이름
    - Model,Method: 모델 학습에 사용한 방법
    - Data,TIme:모델을 추정한 일시
    - No.Obervation:샘플 사이즈
    - Df.Residuals: 샘플사이즈에서 추정돈 파라미터수를 뺸 것
    - Df Model: 사용된 독립 변수 수
    - Covariance Type: 공분산 타입
    - R-sqaured, adj.R-sqaured: 결정계수와 자유도 조정이 끝난 결정계수
    - F-statistics,Prob:분산분석 결과
    - Log-Likelihood:최대로그우도
    - AIC:아카이케 정보 기준
    - BIC:베이즈 정보 기준
    
    ### null모델과 1변수 모델의 AIC비교
    
    ```python
    #null 모델 구축하기. 독립변수가 없을 땐 beer~1이라고 함수에 파라미터를 넘기기
    null_model= smf.ols('beer~1',data=beer).fit()
    #null 모델의 AIC 계산하기
    print(null_model.aic)
    #1변수의 AIC 계산하기
    print(lm_model.aic)
    #따라서 기온이란 독립변수가 있는 쪽이 예측 정확도가 높은 것이 아닌가 판단하게 된다
    
    result)
    227.94194972563105
    208.9090293557544
    ```
    

$AIC=-2(Maximal\,\,Log\,\,Likelihood-Number\,\,of\,\,Estimated\,\,Parameter)$

```python
#추정된 모델의 로그우도 계산
print(lm_model.llf)
#사용된 독립변수의 수 계산
print(lm_model.df_model)

result)
-102.4545146778772
1.0

print(2*(lm_model.llf-(lm_model.df_model+1)))
208.9090293557544
```

### 3.회귀직선 그리기

```python
sns.lmplot(x='temperature',y='beer',data=beer, scatter_kws={'color':'black'},line_kws={'color':'black'})
#음영부분은 회귀직선의 95% 신뢰구간을 나타낸다
```

![Untitled](1%20데이터과학%20및%20수학%20아카이브/파이썬과%20통계학/레퍼런스_5장%20정규선형모델/Untitled%201.png)

### 회귀직선의 예측값 사용하기

```python
#파라미터에 아무것도 넣지 않을 시 훈련데이터의 input값이 들어간다
lm_model.predict()

result)
array([50.301, 53.746, 42.264, 55.2  , 46.704, 37.825, 44.943, 54.511,
       52.445, 41.116, 54.664, 49.23 , 53.21 , 52.445, 41.04 , 52.598,
       45.25 , 61.783, 55.43 , 50.301, 42.418, 50.301, 51.143, 40.657,
       66.911, 52.904, 62.854, 41.423, 62.472, 39.509])

lm_model.predict(pd.DataFrame({'temperature':[0]}))

result)
0    34.610215
dtype: float64

#파라미터값 나타내기
lm_model.params

result)
Intercept      34.610215
temperature     0.765428
dtype: float64

```

### 4. 잔차/결정계수

잔차 $residual=y-\hat{y}$

$R^2=\cfrac{\sum_{i=1}^{N}(\hat{y_i}-\mu)^2}{\sum_{i=1}^{N}(y_i-\mu)^2}$ 이때 $y,\hat{y},\mu$는 각각 종속변수, 모델에 의한 예측치, $y$의 평균값이다

만약 모델의 의한 추측치가 종속변수의 실제값과 일치하면 $R^2$는 1이 된다

```python
#결정계수 R^2 계산하는 코드 세우기/ 또는 코드 사용하기
mu= np.mean(beer.beer) * np.ones(len(y))
y=beer.beer
yhat=lm_model.predict()
R_square= np.dot((yhat-mu),(yhat-mu))/np.dot((y-mu),(y-mu))
print(R_square)
print(lm_model.rsquared)
```

### 잔차 히스토그램 그리기

```python
sns.distplot(resid,color='black')
```

![Untitled](1%20데이터과학%20및%20수학%20아카이브/파이썬과%20통계학/레퍼런스_5장%20정규선형모델/Untitled%202.png)

### 잔차 산포도 그리기

```python
sns.jointplot(lm_model.fittedvalues,resid,joint_kws={'color':'black'},marginal_kws={'color':'black'})
```

![Untitled](1%20데이터과학%20및%20수학%20아카이브/파이썬과%20통계학/레퍼런스_5장%20정규선형모델/Untitled%203.png)

## 2.분산분석 $ANOVA$

$ANalysis\,\,Of\,\,VAriation$ :2개 이상의 다수 집단을 비교할 때 사용하는 가설검정방법 

사용 조건

- 각 집단들의 분포는 독립적이여야 한다
- 각 모집단의 표준편차는 동일해야 한다
- 각 모집단은 정규분포를 따라야 한다

### 용어

- 요인 $factor$: 카테고리형 독립변수
- 수준 $level$ : 카테고리형 독립변수중 특정 하나를 지칭하는 말
- $F(Fisher)value\equiv$ 효과의 분산크기/ 오차의 분산크기
    - 효과: 카테고리 차이에 의한 종속변수의 변동 / 효과의 크기를 군간변동이라 부른다
    - 오차: 카테고리 차이론 설명할수 없는 종속변수의 변동/ 오차의 크기를 군내변동이라 부른다
    - 군간 제곱합 $\equiv \sum_{i=1}^{N}(\nu-\mu_i)^2$, $\mu_i,\nu$는 각각 카테고리별 평균,  카테고리별 평균의 평균
    - 군내 제곱합 $\equiv \sum_{i=1}^{N}\sum_{j=1}^{m_i}(x_{ij}-\mu_i)^2$, $x_{ij}$는 $i$번째 카테고리의 $j$번째 원소

### 예시1. 날씨:비/흐림/맑음에 따른 맥주 매상

```python
weather=['cloudy','cloudy','rainy','rainy','sunny','sunny']
beer=[6,8,2,4,10,12]
weather_beer=pd.DataFrame({'beer':beer,'weather':weather})
print(weather_beer)
#샘플이 작으니까 상자그림으로 그리자
sns.boxplot(x='weather',y='beer',data=weather_beer,color='gray')
print(weather_beer.groupby('weather').mean())
```

![Untitled](1%20데이터과학%20및%20수학%20아카이브/파이썬과%20통계학/레퍼런스_5장%20정규선형모델/Untitled%204.png)

```python
#군간 제곱 구하기
effect=[7,7,3,3,11,11]
mu_effect=np.mean(effect)*np.ones(len(effect))
square_model= np.dot((effect-mu_effect),(effect-mu_effect))
print(square_model)
#군내 제곱 구하기
resid= weather_beer.beer -effect
square_resid =np.dot(resid,resid)
print(square_resid)

result)
64
6

#f값 계산하기
f_val = variance_model/ variance_resid
f_val
p_val= 1- sp.stats.f.cdf(x=f_val,dfn=df_model,dfd=df_resid)
print(f_val)
print(p_val)

result)

16.0
0.02509457330439091
```

### 2.독립변수가 카테고리형인 일반선형모델

- $y \sim N(\beta_0 +\beta_1r+\beta_2 c,\sigma^2)$
    - $r$ 는 비가 오면 1, 그 외의 날에는 0인 변수
    - $c$는 맑으면 1, 그 외에 날엔 0을 나타내는 변수
    - 이렇게 카테고리를 숫자로 표현하는 것을 더미변수라 부른다
    

```python
anova_model= smf.ols('beer~weather',data=weather_beer).fit()
print(sm.stats.anova_lm(anova_model,typ=2))
anova_model.params

result)
           sum_sq   df     F    PR(>F)
weather     64.0  2.0  16.0  0.025095
Residual     6.0  3.0   NaN       NaN
Intercept           7.0
weather[T.rainy]   -4.0
weather[T.sunny]    4.0
dtype: float64
```

- $Intercept$: $\beta_0$

### 회귀모델의 분산분석

```python
#데이터 읽어 들이기
beer= pd.read_csv('sample/5-1-1-beer.csv')
#모델 추정
lm_model= smf.ols(formula='beer~ temperature',data=beer).fit()

df_lm_model=1
df_lm_resid=28

```

- 자유도 정의
    - 모델의 자유도: 군간변동의 자유도 $\equiv$ 추정된 파라미터수 -1
    - 전차의 자유도: 군내변동의 자유도 $\equiv$ 샘플사이즈 수 - 추정된 파라미터 수

```python
#F비 계산하기
#모델을 적용한 값
lm_effect= lm_model.fittedvalues
#잔차
lm_resid= lm_model.resid
#기온의 효과의 크기
mu= np.mean(lm_effect)* np.ones(len(lm_effect))
square_lm_model=np.dot((lm_effect-mu),(lm_effect-mu))
variance_lm_model= square_lm_model /df_lm_model
#잔차의 크기
square_lm_resid=np.dot(lm_resid,lm_resid)
variance_lm_resid= square_lm_resid / df_lm_resid
#F비
f_val_lm = variance_lm_model / variance_lm_resid
print(f_val_lm)

result)
28.44698368850466

print(sm.stats.anova_lm(lm_model,typ=2))

result)
                sum_sq    df          F    PR(>F)
temperature  1651.532489   1.0  28.446984  0.000011
Residual     1625.582178  28.0        NaN       NaN

lm_model.summary()

```

## 3.다변수 모델

```python
#데이터를 받고 일단 페어플롯으로 한번 살펴보기
sales=pd.read_csv('sample/5-3-1-lm-model.csv')
sns.pairplot(data=sales,hue='weather',palette='gray')
```

![Untitled](1%20데이터과학%20및%20수학%20아카이브/파이썬과%20통계학/레퍼런스_5장%20정규선형모델/Untitled%205.png)

```python
#가격- 판매량 회귀직선
sns.lmplot(x='price',y='sales',data=sales,scatter_kws={'color':'black'}, 
line_kws={'color':'black'})
plt.xlim(285,320)
plt.show()
```

![Untitled](1%20데이터과학%20및%20수학%20아카이브/파이썬과%20통계학/레퍼런스_5장%20정규선형모델/Untitled%206.png)

### 날씨별로 분류하여 매상-상품 가격의 관계 살펴보기

```python
sns.lmplot(x='price', y='sales', data=sales, hue='weather', palette= 'gray')
plt.xlim(285,320)
```

![Untitled](1%20데이터과학%20및%20수학%20아카이브/파이썬과%20통계학/레퍼런스_5장%20정규선형모델/Untitled%207.png)

### 다변수 독립변수를 갖는 모델

```python
#복수의 독립변수를 가진 모델을 추정하기
lm_sales= smf.ols('sales~ weather+ humidity + temperature + price', data=sales).fit()
#추정된 결과
lm_sales.params
#가격계수가 음수인 꼴

result)
Intercept           278.627722
weather[T.sunny]     19.989119
humidity             -0.254055
temperature           1.603115
price                -0.329207
dtype: float64
```

### 회귀계수의 $t$검정

```python
lm_sales.summary().tables[1]

result)
coef	           std err	    t	  P>|t|	[0.025	0.975]
Intercept	278.6277	46.335	6.013	0.000	186.641	370.615
weather[T.sunny]	19.9891	3.522	5.675	0.000	12.997	26.982
humidity	-0.2541	0.456	-0.558	0.578	-1.159	0.651
temperature	1.6031	0.443	3.620	0.000	0.724	2.482
price	-0.3292	0.155	-2.123	0.036	-0.637	-0.021

```

|  | coef | std err | t | p>|t| | 0.025 | 0.975 |
| --- | --- | --- | --- | --- | --- | --- |
| Intercept | 278.6277 | 46.335 | 6.013 | 0.000 | 186.641 | 370.615 |
| weather[T.sunny] | 19.9891 | 3.522 | 5.675 | 0.000 | 12.997 | 26.982 |
| humidity | -0.2541 | 0.456 | -0.558 | 0.578 | -1.159 | 0.651 |
| temperature | 1.6031 | 0.443 | 3.620 | 0.000 | 0.724 | 2.482 |
| price | -0.3292 | 0.155 | -2.123 | 0.036 | -0.637 | 0.021 |

```python
#독립변수의 순서 바꾸기
lm_sales_2=smf.ols('sales~ weather+ temperature + humidity + price', data=sales).fit()
#순서바뀐 모델의 검정 결과
lm_sales_2.summary().tables[1]
#습도의 regression coefficient가 0.578
```

|  | coef | std err | t | p>|t| | 0.025 | 0.975 |
| --- | --- | --- | --- | --- | --- | --- |
| Intercept | 278.6277 | 46.335 | 6.013 | 0.000 | 186.641 | 370.615 |
| weather[T.sunny] | 19.9891 | 3.522 | 5.675 | 0.000 | 12.997 | 26.982 |
| temperature | 1.6031 | 0.443 | 3.620 | 0.000 | 0.724 | 2.482 |
| humidity | -0.2541 | 0.456 | -0.558 | 0.578 | -1.159 | 0.651 |
| price | -0.3292 | 0.155 | -2.123 | 0.036 | -0.637 | 0.021 |

Type 1 ANOVA 방법

```python
#Null Model의 잔차제곱합
mod_null = smf.ols('sales~1', sales).fit()
resid_sq_null = np.dot(mod_null.resid,mod_null.resid)
resid_sq_null

#날씨 모델의 잔차 제곱합
mod_1 = smf.ols('sales~ weather',sales).fit()
resid_sq_1 =np.dot(mod_1.resid,mod_1.resid)
resid_sq_1

#잔차제곱차
print(resid_sq_null- resid_sq_1)

print(sm.stats.anova_lm(mod_1).round(3))

#날씨 + 습도 모델의 잔차제곱합
mod_2 = smf.ols('sales~ weather+humidity',sales).fit()
resid_sq_2= np.dot(mod_2.resid,mod_2.resid)
print(resid_sq_2)

#잔차제곱차
print(resid_sq_1-resid_sq_2)
print(sm.stats.anova_lm(mod_2).round(3))

#이렇게 독립변수를 1개씩 늘려가며, 독립변수가 늘어남에 따라 잔차제곱합이 늘어남으로서 독립변수 효과를
#측정하는 방식은 독립변수를 추가하는 순서가 의미를 갖는다
```

### Type 1과 Type2 ANOVA 비교

- Type 1

| 모델0 |             “ |  |  |  |  | +잔차제곱합 |
| --- | --- | --- | --- | --- | --- | --- |
| 모델1 |      종속변수~ | +변수1 |  |  |  |             “ |
| 모델2 |             “ | +변수1 | +변수2 |  |  |             “ |
| ... |             “ | .. |  |  |  |             “ |
| 모델N |             “ | +변수1 | +변수2 | ... | +변수N |             “ |
- 로 모델 0-1, 1-2, 2-3, ... 의 순서로 잔차제곱합을 비교하여 독립변수의 유의미함을 검증한다
- Type2

| 모델0 |             “ | +변수1 | +변수2 | .... | +변수N | +잔차제곱합 |
| --- | --- | --- | --- | --- | --- | --- |
| 모델1 |      종속변수~ | +변수1 |  | .... | +변수N |             “ |
| ... |             “ | .. |  |  |  |             “ |
| 모델N |             “ | +변수1 | +변수2 | ... |  |             “ |
- 로 모델 0-1, 0-2,...로 이와같이 모두 모델 0과 잔차제곱합과 비교한다
- 이러한 방식은 변수를 추가하는 순서를 바꾸어도 검정 결과는 바뀌지 않는다

예

```python
#모든 변수가 포함된 모델의 잔차제곱합
mod_full=smf.ols('sales~ weather+humidity+temperature+price',sales).fit()
resid_sq_full= np.dot(mod_full.resid,mod_full.resid)
print(resid_sq_full)

#습도만 제거한 모델의 잔차제곱합
mod_non_hum=smf.ols('sales~weather+temperature+price',sales).fit()
resid_sq_non_hum = np.dot(mod_non_hum.resid,mod_non_hum.resid)
print(resid_sq_non_hum)
print(resid_sq_non_hum - resid_sq_full)

#모듈 사용
print(sm.stats.anova_lm(mod_full,typ=2).round(3))

result)
17242.716942366493
17299.14201610766
56.42507374116758
                sum_sq    df       F  PR(>F)
weather       5845.878   1.0  32.208   0.000
humidity        56.425   1.0   0.311   **0.578 => 유의미한 결과로 볼 수 없다**
temperature   2378.017   1.0  13.102   0.000
price          818.402   1.0   4.509   0.036
Residual     17242.717  95.0     NaN     NaN

#습도를 제외하여 모델이 가장 적합하다
print(sm.stats.anova_lm(mod_non_hum,typ=2).round(3))

result)
               sum_sq    df       F  PR(>F)
weather       6354.966   1.0  35.266   0.000
temperature   4254.736   1.0  23.611   0.000
price          803.644   1.0   4.460   0.037
Residual     17299.142  96.0     NaN     NaN

print(mod_non_hum.params)

result)
Intercept           273.301800
weather[T.sunny]     20.393871
temperature           1.417860
price                -0.326001
dtype: float64
```