# 4장 통계모델 기본

## 1. 통계 모델

- 수학적 모델$matheatical\,\,model$: 수학적 개념과 언어를 사용하여 시스템( 각 구성요소가 상호작용하고 복잡하게 얽혀있는 하나의 집합체)을 서술하는 것
- 확률 모델$stochastic\,\,model$: 수학적 모델중 확률적 표현이 존재하는 모델
- 통계 모델$statistical\,\,model$: 데이터에 적합하게 구축된 확률 모델

## 2.통계 모델 만들기

### 변수들

- 독립변수$independent\,\,varialbe$ (원인)
    - 다른 변수에 영향을 받지 않는 변수이면서 다른 변수에 영향을 주는 변수
    - 연구자가 의도적으로 변화시키는 변수
- 종속변수 $dependent\,\,variable$ (결과)
    - 다른 변수에 영향을 받으면서 다른 변수에 영향을 미칠 수 없는 변수
    - 연구자의 관찰대상이 되는 변수
- 매개변수$parametric\,\,variable$
    - 다른 변수에 영향을 받을 수도 다른 변수에 영향을 줄 수 있는 변수
    - 독립변수와 종속변수 사이 간접적으로 영향을 준다
- 외재변수 $extraneous\,\,variable$
    - 종속변수에 영향을 미칠 수 있으나 연구에선 다루지 않는 변수
    - 외재변수로서의 작용을 금하기 위해 변수를 제거하거나, 외재변수를 동일한 상태로 유지하려 할 때 해당 변수를 통제변수 $control\,\,variable$이라 부른다

### 계수와 가중치

- 계수$coefficient$: 변수 앞에 곱해진 상수/ 머신러닝에선 주로 가중치$weight$란 이름으로 불린다

### 모델의 구축

- 모델의 특정: 모델의 구조를 수식으로 표현하기
    - 변수 선택하기
        - 통계적 가설검증 활용: 귀무가설을 세워 기각되는 경우에는 독립변수를 필요하다고 판단/ 기각되지 않는 경우에는 독립변수를 제거하여 모델을 단순화 시킨다
        - 정보 기준: AIC라는 것을 활용하여 모델에서 가능한 변수의 패턴을 총 망라하고 AIC가 가장 적은 모델을 선택한다
- 파라미터 추정하기
- 모델 평가

## 3.데이터 표현과 모델의 명칭

### 모델의 종류

- 파라메트릭/ 논파라메트릭
    - 파라메트릭 모델: 가능한 현상을 단순화 하여 소수의 파라미터만 사용하는 모델
    - 논파라메트릭 모델: 소수의 파라미터를 사용한다는 방침을 취하지 않는 모델/ 복잡한 모델이 되기 쉬워 추정과 해석이 어려워질 수 있다
- 선형회귀모델$linear\,\,regression\,\,model$: $y_i=\sum_jx_{ij}\beta_j$ 로 정의된 수학적 모델
    - ( $x_{ij},\beta_j$는 각각 i번째 데이터의 j번째 성분의 값, j번째 계수를 의미한다.
    - 선형성$linearity$를 따지는 대상은 독립변수$x_{ij}$가 아니라 계수$\beta_j$ 이다
    - 독립변수 $x_{ij}$를 1개 사용한 식을 단순회귀분석식 $simple\,\,regression$ / 독립변수 $x_{ij}$를 2개 이상 사용한 식을 다중회귀분석식$multiple\,\,regression$이라 한
- 정규선형모델: 종속변수가 정규분포를 따르는 것을 가정한 선형모델
- 분산분석: 독립변수가 카테고리형 변수인 모델
    - 독립변수가 1종류면 일원분산분석 / 독립변수가 2종류면 이원분산분석이라 한다
    
    ![Untitled](1%20데이터과학%20및%20수학%20아카이브/파이썬과%20통계학/레퍼런스_4장%20통계모델%20기본/Untitled.png)
    

## 4.최대우도법$MLE$:우도$likelihood$의 최대화

$likelihood$ 

- 어떤 값 $X$가 관측되었을 때 이것이 어떤 확률 분포와 모수에 잘 들어맞는지 측정하는 수치
- 표본으로부터 확률분포 형태를 역으로 추론할 때 사용한다
- $L(\theta \mid x)\equiv P(x \mid \theta)=\prod_{i=1}^{N}P(x_i \mid \theta)$
- $log(L(\theta \mid x))= \sum_{i=1}^{N}log(P(x_i \mid\theta))$

### 로그의 성질

1. 단조증가 $monotonic\,\,increasing$: 독립변수값이 증가하면 함수값도  항상 증가한다.
2. 곱셈이 덧셈으로 바뀐다 ⇒ $log(\prod_{i=1}^{N}a_i)=\sum_{i=1}^{N}log(a_i)$
3. 절댓값이 극단적으로 작은 값이 되기 어렵다

### 최대우도법$MLE\,\,Maximum\,\,Likelihood\,\,Estimation$

- 최대우도추정량$Maximum\,\,Likelihood\,\,Estimator$ $\hat{\theta}$: 최대우도법에 의해 추정된 파라미터
- 최대화 로그우도: 최대우도추정량을 사용했을 때의 로그 우도
- 장애모수: 직접적인 관심의 대상이 아닌 파라미터
    - 정규분포의 모수는 평균과 분산으로, 분산은 평균값에서 계산이 가능하다. 즉 분산이란 파라미터는 관심을 두지 않고 이미 알고 있는 것으로 취급한다 ⇒ 최대우도법에선 분산 $\sigma^2$를 장애모수 취급한다
    

### 우도함수 예시들

---

- 동전던지기 모델
    - $L(\theta)=\theta(1-\theta)$ , $\theta$= 1/2

---

- 맥주-기온 매상 상관관계 모델
    - $y\sim N(\beta_0+\beta_1t,\sigma^2), \,\,y,t$는 각각 맥주 매상과 기온
    - $\beta_0,\beta_1$는 이미 구했다고 가정하자
    - 우도는 이때 다음과 같이 계산한다
    
    $L=N(y_1 \mid \beta_0+\beta_1t_1,\sigma^2)N(y_2 \mid \beta_0 + \beta_1 t_2,\sigma^2)$
    
    $logL=\sum_{i=1}^{N}log{N(y_i \mid\beta_0+\beta_1t_i,\sigma^2)}$
    
    함수의 결과값을 최대로하는 파라미터를 구하는 것을 $arg\,\,max$라고 쓴다
    
    $arg\,\,max_{\beta_0,\beta_1}logL$
    
    $=arg\,\,max_{\beta_0,\beta_1} \sum_{i=1}^{N}log[N(y_i \mid \beta_0 +\beta_1t_i,\sigma^2)]$
    
    $=arg\,\,max_{\beta_0,\beta_1} \sum_{i=1}^{N}log[\cfrac{1}{\sqrt{2\pi\sigma^2}}exp(-\cfrac{(y_i-(\beta_0+\beta_1x_i))^2}{2\sigma^2})]$
    
    $=arg\,\,max_{\beta_0,\beta_1} \sum_{i=1}^{N}log(\cfrac{1}{\sqrt{2\pi\sigma^2}})-\cfrac{(y_i-(\beta_0+\beta_1x_i))^2}{2\sigma^2}$
    
    ---
    
- 맥주 매상- Null모델(독립변수X)
    
    $y \sim N(\mu,\sigma^2),y$는 맥주 매상
    
     $argmax_\mu logL$
    
    $=argmax_\mu\sum_{i=1}^{N}log[N(y_i \mid\mu,\sigma^2)]$
    
    $=argmax_\mu\sum_{i=1}^{N}log(\cfrac{1}{\sqrt{2\pi\sigma^2}}-\cfrac{(y_i-\mu)^2}{2\sigma^2})$
    
    $\sigma^2$는 장애모수 취급하므로
    
    $=\sum_{i=1}^{N}\cfrac{2(y_i-\mu)}{2\sigma^2}=0$
    
    $=\sum_{i=1}^{N}y_i-\mu=0$
    
    $=\sum_{i=1}^{N}y_i-N\mu=0$
    
    $\therefore \mu=\cfrac{1}{N}\sum_{i=1}^{N}y_i$
    
    $\mu$값을 종속변수의 평균값으로 할 때 우도가 최대가 된다
    
    ---
    

## 5.파라미터의 추정

### 손실함수/비용함수 $loss/cost\,\,function$

모델의 추정치와 실제값의 차이를 나타내는 지표

오차값이 작아질수록 손실함수는 작아진다

- 잔차$residual$
    - 실제 종속변수값과 모델을 이용하여 계산한 추정치의 차이값
    - $residual=y-\hat{y}$
- 최소제곱법 $Least \,\,Squared\,\,Method$
    - 잔차제곱의 합을 손실함수로 정의하고, 이를 최소로 하는 파라미터를 구하는 방법
    - 최소제곱법을 이용한 파라미터 추정은 모집단분포가 정규분포를 가정했을 때의 최대우도법의 결과와 동일하다.

## 6.예측 정확도 평가와 변수 선택

### 적합도와 예측 정확도

- 적합도: 가지고 있는 데이터에 대해 모델을 적용했을 때 잘 들어맞는 정도
- 예측 정확도: 갖고 있지 않는 데이터에 대해 모델을 적용했을 때 들어맞는 정도
- 과적합과 과소적합
    - 과적합$overfitting$: 가지고 있는 데이터에 지나치게 적합한 모델을 만들어, 예측 정확도가 떨어지는 현상
    - 과소적합$underfitting$: 모델이 지나치게 단순해서 제대로 된 학습이 안 이루어진 현상
    

### 데이터 집합

- 훈련 데이터$training\,\,dataset$: 파라미터 추정/ 모델 학습에 활용되는 데이터
- 테스트 데이터$test\,\,dataset$:모델의 최종성능 평가지표/ 학습과정에서 전혀 쓰이지 않는 데이터이자 경쟁하는 모델을 평가하는데 쓰이는 데이터
- 검증 데이터$validation\,\,dataset$:모델의 중간성능 평가지표/모델의 미세조정을 위해 사용한다/ 튜닝과정에서 간접 학습에 쓰이게 된다

### 교차검증$CV\,\,cross\,\,validation$

- $k-fold$ 교차검증법: 데이터 집합을 $k$등분하여 $k-1$조각은 학습에, 나머지 한조각은 검증에 활용한다. 이때 순서대로 검증에 활용하는 데이터 조각을 바꿔가면서 $k$번 실험을 반복하고, 이 예측 평가를 평균내어 $k-fold$ 평가 결과에 활용한다

![Untitled](1%20데이터과학%20및%20수학%20아카이브/파이썬과%20통계학/레퍼런스_4장%20통계모델%20기본/Untitled%201.png)

- $leave-p-out$ 교차검증: 가지고 있는 데이터 중 $p$개의 데이터를 추출하고 남은 데이터를 검증 데이터로 활용하는 방법/ 나머지는 $k-fold$ 교차검증법과 같이 반복계산 한다
    
    ![Untitled](1%20데이터과학%20및%20수학%20아카이브/파이썬과%20통계학/레퍼런스_4장%20통계모델%20기본/Untitled%202.png)
    

### $AIC$ 아카이케 정보기준

$AIC$=$-2(Maximum\,\,Log\,\,Likelihood-Numbers\,\,of\,\,Estimated\,\,Parameter)$