# 3장 파이썬을 이용한 데이터 분석 2 :시각화

## 3.matplotlib과 seaborn을 이용한 시각화

```python
import seaborn as sns
sns.set()                  #앞 두줄이 좌우의 차이
x=np.array([0,1,2,3,4,5,6,7,8,9])
y=np.array([2,3,4,3,5,4,6,7,4,8])
plt.plot(x,y,color='black')
plt.title('lineplot matplotlib')
plt.xlabel('x')
plt.ylabel('y')

result)
```

### 1.꺽은선 그래프 (pyplot 이용)

### 2.꺽은선 그래프(pyplot과 seaborn 이용)

![Untitled](1%20데이터과학%20및%20수학%20아카이브/파이썬과%20통계학/레퍼런스_3장%20파이썬을%20이용한%20데이터%20분석%202%20시각화/Untitled.png)

![Untitled](1%20데이터과학%20및%20수학%20아카이브/파이썬과%20통계학/레퍼런스_3장%20파이썬을%20이용한%20데이터%20분석%202%20시각화/Untitled%201.png)

### 3.seaborn을 이용한 히스토그램

```python
fish_data=np.array([2,3,3,4,4,4,4,5,5,6])
sns.histplot(fish_data,bins=5,color='black',kde=False)
#kde=False는 커널밀도추정(주어진 데이터를 보고 모집단분포를 추정하는 테크닉)
#을 하지 않겠다고 지정하는 명령어 kde=True로 하면 오른쪽처럼 분포를 추정하는 곡선

```

![Untitled](1%20데이터과학%20및%20수학%20아카이브/파이썬과%20통계학/레퍼런스_3장%20파이썬을%20이용한%20데이터%20분석%202%20시각화/Untitled%202.png)

![Untitled](1%20데이터과학%20및%20수학%20아카이브/파이썬과%20통계학/레퍼런스_3장%20파이썬을%20이용한%20데이터%20분석%202%20시각화/Untitled%203.png)

### 4. 2변량 데이터에 대한 히스토그램

- 데이터 분류하기

```python
fish_multi=pd.read_csv('sample/3-3-2-fish_multi_2.csv')
fish_multi.groupby('species').describe()

result)
count	   mean	 std	  min	25%	 50%	75%	  max
species								
A	10.0	4.0	1.154701	2.0	3.25	4.0	4.75	6.0
B	10.0	7.0	1.154701	5.0	6.25	7.0	7.75	9.0

#종류별로 길이를 따로 분류하기
length_a = fish_multi.query("species=='A'")['length']
length_b= fish_multi.query("species=='B'")['length']
```

- 그래프 동시에 그리기: 함수를 두번 실행하면 됨

```python
sns.histplot(length_a,bins=5,color='black',kde=False)
sns.histplot(length_b,bins=5,color='gray',kde=False)
plt.savefig('겹친 히스토그램')
```

![Untitled](1%20데이터과학%20및%20수학%20아카이브/파이썬과%20통계학/레퍼런스_3장%20파이썬을%20이용한%20데이터%20분석%202%20시각화/Untitled%204.png)

```python
sns.boxplot(x='species',y='length',data=fish_multi,color='gray')
sns.violinplot(x='species',y='length',data=fish_multi,color='gray')
```

### 5.상자 그래프: 카테고리형 X 수치형 변수 데이터 시각화

### 6.바이올린 그래프: 카테고리형 X 수치형 변수 커널밀도추정 시각화

![Untitled](1%20데이터과학%20및%20수학%20아카이브/파이썬과%20통계학/레퍼런스_3장%20파이썬을%20이용한%20데이터%20분석%202%20시각화/Untitled%205.png)

![Untitled](1%20데이터과학%20및%20수학%20아카이브/파이썬과%20통계학/레퍼런스_3장%20파이썬을%20이용한%20데이터%20분석%202%20시각화/Untitled%206.png)

### 7.산포도: 수치형 X 수치형 데이터 시각화

```python
cov_data= pd.read_csv('sample/3-2-3-cov.csv')
cov_data
result)
x	y
0	18.5	34
1	18.7	39
2	19.1	41
3	19.7	38
4	21.5	45
5	21.7	41
6	21.8	52
7	22.0	44
8	23.4	44
9	23.8	49

sns.jointplot(x='x',y='y',data=cov_data,color='black')
```

![Untitled](1%20데이터과학%20및%20수학%20아카이브/파이썬과%20통계학/레퍼런스_3장%20파이썬을%20이용한%20데이터%20분석%202%20시각화/Untitled%207.png)

### 8.페어플롯: 다변수 데이터의 그래프 그리기

```python
iris=sns.load_dataset('iris')
iris.groupby('species').mean() # 종에 따른 특성의 평균값 구하기
sns.pairplot(iris,hue='species',palette='gray') 
# hue='species': 종별로 색을 달리하여 산포도/히스토그램 그리기
```

![Untitled](Untitled%208.png)

## 4.모집단에서 표본 추출 시뮬레이션 하기

### 1. 5마리 물고기 모집단

```python
#모집단
fish_5=np.array([2,3,4,5,6])
#랜덤으로 고르기/ replace=False시 비복원 추출, repace=True시 복원 추출
np.random.choice(fish_5,size=3,replace=False)
```

### 2.난수 시드$seed$의 역할

- 난수를 만드는 알고리즘은 특정 시작 숫자(난수)를 받고 정해진 알고리즘에 따라 난수처럼 보이는 숫자를 제공한다. 따라서 난수를 수동으로 정한다면 그 난수 알고리즘은 항상 동일한 값을 제공한다.

### 3. 10만마리 물고기 모집단

- 모집단의 평균/표준편차/ 히스토그램

```python
#np.random.choice는 1차원의 data를 input으로 받을 수 있으므로 
#변수= 데이터프레임['열 이름']로 지정하여 변수를 1차원 배열로 받아야 한다 
fish_10000 = pd.read_csv('sample/3-4-1-fish_length_100000.csv')['length']
fish_10000

#모평균/ 모표준편차/ 모집단의 히스토그램/ 평균4, 표준편차 0.8인 정규분포와의 비교
print(np.mean(fish_10000))
print(np.std(fish_10000,ddof=0))

#stat='density'는 히스토그램의 면적을 1로 정규화하는 함수다. 
#정규화하지 않으면 너무커서 정규분포와 비교 불가능
sns.histplot(fish_10000,kde=False,stat='density',color='gray')
x=np.arange(1,7.1,0.1)

#loc:평균, scale:표준편
plt.plot(x,stats.norm.pdf(x=x,loc=4,scale=0.8),color='black')
plt.savefig('모집단 히스토그램')
```

![Untitled](Untitled%209.png)

- 표본 추출하기

```python
#무작위 추출하여 만든 표본집단과의 비교
sampling_fish= np.random.choice(fish_10000,size=10,replace=False)
sampling_fish

result)
array([5.548, 4.021, 2.637, 2.413, 3.495, 3.695, 4.38 , 3.964, 3.077,
       3.494])

np.mean(sampling_fish)
result)
3.67226682361824
```

### 4.정규분포를 따르는 난수 생성하기

```python
#평균:loc, 표준편차scale, 샘플사이즈size
sampling_norm = stats.norm.rvs(loc=4,scale=0.8,size=10)
print(sampling_norm)

#표본평균
np.mean(sampling_norm)

result)
[4.744 4.835 3.923 4.888 2.184 3.868 3.77  5.428 4.998 3.273]
4.191074859242585
```

## 5.표본 통계량의 성질

- 표본분포: 표본의 통계량이 따르는 확률분포
- 표본의 수: 시뮬레이션을 하여 얻은  데이터 집합들의 수
- 샘플 사이즈: 표본들이 가지고 있는 데이터의 수

### 1.샘플사이즈가 커질수록 표본평균의 평균은 모평균에 가까워진다

```python
#모집단은 평균은 4, 표준편차는 0.8인 정규분포라 설정하자.
#샘플사이즈가 10인 표본을 10000개 뽑아 각각에 대한 표본평균값을 구해보자
population=stats.norm(loc=4,scale=0.8)
sample_mean_array =np.zeros(10000)
np.random.seed(1)
for i in range(0,10000):
    sample= population.rvs(size=10)
    sample_mean_array[i]=np.mean(sample)
    

sns.histplot(sample_mean_array,kde=True,color='black')
#표본평균의 평균값은 모평균에 가깝다
np.mean(sample_mean_array)

result)
4.004202422791747

#10부터 100씩 증가하는 샘플사이즈 만들기
size_array=np.arange(10,100010,100)
sample_mean_array_size=np.zeros(len(size_array))

np.random.seed(1)
for i in range(0,len(size_array)):
    sample= population.rvs(size=size_array[i])
    sample_mean_array_size[i] = np.mean(sample)
    
plt.plot(size_array,sample_mean_array_size,color='black')
plt.xlabel('sample size')
plt.ylabel('sample mean')
```

![Untitled](Untitled%2010.png)

![Untitled](Untitled%2011.png)

- 표본평균을 몇번이고 계산하는 함수 만들기

 

```python
population=stats.norm(loc=4,scale=0.8)
def cal_sample_mean(size,n_trial):
    sample_mean_array=np.zeros(np_trial)
    for i in range(0,n_trial):
        sample = population.rvs(size= size)
        sample_mean_array[i]=np.mean(sample)
    return sample_mean_array
```

### 2. 샘플사이즈를 바꿀 때의 표본평균의 분산 변화 살피기⇒ 작아진다

```python
np.random.seed(1)

#샘플 사이즈 10개
size_10 = cal_sample_mean(size=10,n_trial=10000)
size_10_df = pd.DataFrame({
    "sample_mean":size_10,
    "size": np.tile("size 10",10000)
})

#샘플 사이즈 20개
size_20= cal_sample_mean(size=20, n_trial=10000)
size_20_df=pd.DataFrame({
    'sample_mean' :size_20,
    'size': np.tile('size 20',10000)
})
#샘플 사이즈 30개
size_30 = cal_sample_mean(size=30,n_trial=10000)
size_30_df=pd.DataFrame({
    'sample_mean' : size_30,
    'size': np.tile('size 30',10000)
})
#종합
sim_result= pd.concat([size_10_df,size_20_df,size_30_df])
sim_result.groupby('size').describe()

result)
       count	   mean      std	       min	      25%	     50%	     75%	     max
size								
size 10	10000.0	4.004202	0.251358	3.113375	3.835781	4.003931	4.172002	4.996211
size 20	10000.0	4.000662	0.179886	3.314246	3.878797	4.001035	4.124929	4.623140
size 30	10000.0	4.000859	0.145816	3.416744	3.901714	4.000289	4.098607	4.609366

sns.violinplot(x='size',y='sample_mean',data=sim_result,color='gray')
result)
```

![Untitled](Untitled%2012.png)

### 3.표준 오차$standard\,\,error$

표본 평균의 표준편차

$SE=\cfrac{\sigma}{\sqrt{N}}$ 

$pf.\,\,Var(\bar{X})=Var(\cfrac{1}{N}(X+X+...+X))=\cfrac{1}{N^2}N\sigma^2=\cfrac{\sigma^2}{N} \,\,,\sqrt{Var(\bar{X})}=\cfrac{\sigma}{\sqrt{N}}$

표준 오차의 직관적 설명

- 정원이 10명인 엘레베이터가 있다고 하자. 엘레베이터에 10명이 있을 때 탑승한 사람들이 모두 키가 작거나 모두 키가 큰 경우는 별로 없을 것이다. 키가 큰사람도, 작은 사람도 있는 다양한 사람이 타서 평균내면 중간쯤의 체중이 될 것이다
- 정원이 100명인 비행기를 생각해보자. 비행기는 더더욱 탑승한 사람이 모두 키가 크거나 작은 사람일 확률은 거의 없다. 이 경우 더더욱 평균신장은 모집단(탑승국가의 국민)의 평균 신장에 가까울 것이다.

```python
size_array=np.arange(2,102,2)
size_array
#표본평균의 표준편차를 저장할 변수
sample_mean_std_array=np.zeros(len(size_array))

#시행횟수 차이에 따른 표준편차의 변화를 저장
np.random.seed(1)
for i in range(0,len(size_array)):
    sample_mean= cal_sample_mean(size=size_array[i],n_trial=100)
    sample_mean_std_array[i]=np.std(sample_mean,ddof=1)
    
plt.plot(size_array,sample_mean_std_array,color='black')
plt.xlabel('sample_size')
plt.ylabel('mean_std value')
```

![Untitled](Untitled%2013.png)

### 4.표본분산의 정의가 특이한 이유: 그렇게 정의해야 표본분산의 평균 극한이 모분산이 되므로

```python
sample_var_array=np.zeros(10000)
#n으로 나눴을 때 
np.random.seed(1)
for i in range(0,10000):
    sample = population.rvs(size=10)
    sample_var_array[i] = np.var(sample,ddof=0)
print(np.mean(sample_var_array))

#n-1로 나눴을 때
np.random.seed(1)
for i in range(0,10000):
    sample = population.rvs(size=10)
    sample_var_array[i] = np.var(sample,ddof=1)
print(np.mean(sample_var_array))
```

### 샘플 사이즈를 키울때 표본분산은 모분산에 가까워진다

```python
size_array=np.arange(10,100010,100)
unbiased_var_array_size=np.zeros(len(size_array))

np.random.seed(1)
for i in range(0,len(size_array)):
    sample = population.rvs(size=size_array[i])
    unbiased_var_array_size[i]= np.var(sample,ddof=1)

plt.plot(size_array,unbiased_var_array_size,color='black')
plt.xlabel('sample size')
plt.ylabel('unbiased var')
```

![Untitled](Untitled%2014.png)

### 5.불편성 $unbiasedness$ 와 일치성$consistency$

불편성: 추정량의 기댓값이 모수와 같은 특성

1. $E(\bar{X})=\mu$ 

$pf)$

$\,E(\cfrac{X_1+X_2+...+X_N}{N})=\cfrac{1}{N}E(X_1+X_2+...x_N)=\cfrac{1}{N}(\mu+\mu+...)=\mu N=\mu$

1. $E(s^2)=\sigma^2$

$pf)$추후에 증명

일치성: 샘플사이즈가 커지면 추정량이 모수에 가까워지는 특성

### 6.중심극한정리 $Central\,\,Limit\,\,Theorem$

- 샘플 사이즈가 커질수록 표본평균의 분포는 모집단의 분포와 무관하게 정규분포에 유사해져간다는 정리
- 이때 표본평균의 평균은 모평균과 같고, 표본평균의 표준편차는 모표준편차를 sqrt of(샘플사이즈 )