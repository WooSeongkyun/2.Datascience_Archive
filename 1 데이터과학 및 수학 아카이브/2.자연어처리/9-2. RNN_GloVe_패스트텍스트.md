### 기존 방법론에 대한 비판
LSA는 DTM이나 TF-IDF 행렬과 같이 각 문서에서의 각 단어의 빈도수를 카운트 한 행렬이라는 전체적인 통계 정보를 입력으로 받아 차원을 축소(Truncated SVD)하여 잠재된 의미를 끌어내는 방법론다. 반면, Word2Vec는 실제값과 예측값에 대한 오차를 손실 함수를 통해 줄여나가며 학습하는 예측 기반의 방법론이다

## 윈도우 기반 동시 등장 행렬(Window based Co-occurrence Matrix)
 - ![](동시기반행렬.png)
  -  단어 $x$ 가 등장했을 때  주변에 단어 $y$ 가 등장하는 횟수를 카운트 하는 것이다. 이때 주변으로 기준삼는 영역은 윈도우 크기 N으로 좌우 N개의 단어다
  - 동시등장확률 $P(y|x)$ 는 특정 단어 $x$ 의 전체 등장 횟수를 카운트하고, 특정 단어 $x$가 등장했을 때, 어떤 단어 $y$가 등장한 횟수를 카운트하여 계산한 조건부 확률이다

  - 관련 용어
	-   $Xij$ : 중심 단어 i가 등장했을 때 윈도우 내 주변 단어 j가 등장하는 횟수
	-   $X_i:∑_jX_{ij}$ : 동시 등장 행렬에서 i행의 값을 모두 더한 값
	-   $P_{ik}$ : $P(k | i)$ = $X_{ik}/Xi$ : 중심 단어 i가 등장했을 때 윈도우 내 주변 단어 $k$가 등장할 확률  
	    Ex) $P(solid\,\, | \,\,ice)$ = 단어 $ice$가 등장했을 때 단어 $solid$가 등장할 확률 
	-   $\cfrac{P_{ik}}{P_{jk}}$ : $P_{ik}$를 $P_{jk}$로 나눠준 값  
	    Ex) $\frac{P(solid \,\, | \,\, ice)}{P(solid \,\,| \,\,steam)}$ = 8.9 
	-   $w_i$ : 중심 단어 $i$의 임베딩 벡터 
	-   $w_k$ : 주변 단어 $k$의 임베딩 벡터
- 임베딩 벡터의 정의
	- 임베딩 된 중심 단어와 주변 단어 벡터의 내적이 전체 코퍼스에서의 동시 등장 확률이 되도록 만드는 것'
	- $dot \,\, product(w_i,\tilde{w}_k~)≈ P(k | i)=P_{ik}$ 와 같은 형태를 생각할 수 있고
	- 더 정확히는 GloVe는 아래와 같은 관계를 가지도록 임베딩 벡터를 정의하였다
	- $dot\,\, product(w_i,\tilde{w}_k)≈ log P(k | i)=log P_{ik}$
- Glove의 수학적 증명은 상당히 어려워 보여서 패스함..


## 패스트텍스트란 무엇인가?
- 내부단어의 학습
	- FastText에서는 각 단어는 글자 단위 n-gram의 구성으로 취급한다. n을 몇으로 결정하는지에 따라서 단어들이 얼마나 분리되는지 결정된다 
	- 예:  n을 3으로 잡은 트라이그램(tri-gram)의 경우, apple은 app, ppl, ple로 분리하고 이들을 벡터로 만든다
		- `<ap, app, ppl, ple, le>,<apple>`
- 왜 내부단어로 쪼개어 쓰는가?
	- 모르는 단어에 대한 학습 OOV(Out of Vocabulary)에 대한 대응
		- 데이터 셋만 충분한다면 위와 같은 내부 단어(Subword)를 통해 모르는 단어(Out Of Vocabulary, OOV)에 대해서도 다른 단어와의 유사도를 계산할 수 있다
		- 예:FastText에서 birthplace(출생지)란 단어를 학습하지 않은 상태라고 하자. 하지만 다른 단어에서 birth와 place라는 내부 단어가 있었다면, FastText는 birthplace의 벡터를 얻을 수 있다.
	- 빈도수가 적은 단어Rare Word 에 대한 대응 
		- Word2Vec의 경우 등장 빈도수가 적은 단어는 임베딩의 정확도가 높지 않다는 단점이 존재한다. 그러나 FastText의 경우 만약 단어 빈도수가 적더라도, 그 단어 n-gram이 다른 단어 n-gram과 겹치는 경우라면 비교적 높은 임베딩 벡터값을 가질 수 있다
		- 이것은 노이즈가 많은 코퍼스에서도 장점이 된다. 오타가 섞인 단어는 당연히 등장 빈도수가 매우 적으므로 일종의 희귀 단어가 된다. 이 경우 Word2Vec에선 임베딩이 제대로 되지 않지만, FastText는 이에 대해서도 일정 수준의 성능을 보인다