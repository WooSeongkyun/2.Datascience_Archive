## Statistics
- Central Limit Theorem 이 무엇인가
	- 표본평균 $\bar{x}$의 분포는 샘플의 크기 n이 커지면 커질수록 정규분포의 모양에 가까워 진다는 정리입니다.
- Central Limit Theorem 을 어디에 활용할 수 있는가?
	- 모집단이 어떤 분포 모양을 하는가와 상관없이, 표본의 크기만 충분하다면 특정 표본평균을 가질 확률을 계산할 수 있습니다
- 큰수의 법칙이란?
	- 표본집단의 크기가 커질수록 표본평균이 모평균에 가까워진다는 정리입니다
	- 표본집단의 크기가 커질수록 경험적 확률이 수학적 확률에 가까워진다고 해석할 수도 있습니다
- 확률과 통계의 차이점은 무엇인가?
	- 확률은 어떤 사건이 일어날 수 있는 수학적 기대치를 계산한 것이고, 통계는 과거의 측정자료를 활용하여 미래에 일어날 일을 예측하는 수치적 지표입니다
- Marginal Distribution은 무엇인가?
	-  다변량분포의 경우, 일부 독립변수에만 의존하도록 이산확률변수인 경우summation을, 연속확률변수인 경우 적분을 하여 만든 결과입니다
- Conditional Distribution은 무엇인가?
	- 사건 $A$ 가 발생하였을 때, 사건 $B$가 발생할 확률로
	- $P(A|B)=\cfrac{P(A \cap B)}{P(A)}$ 입니다. 
	- 이 정의로부터 베이즈 정리($P(A|B)=\cfrac{P(B|A)P(A)}{P(B)}$) 를 유도할 수 있습니다
- Bias, Variance는 무엇인가
	- $Bias=E(T)-\theta$ ($T$ be a statistic used to estimate a parameter $θ$)로 예측값의 평균이 실제값과 얼마나 차이가 나는지를 측정하는 척도입니다
		- Expectation value of Statistic - Parameter라고 읽으면 됨
	- $Var=E[(X-E(X))^2]$ 으로 측정값과 측정값의 기댓값의 차를 제곱한 것의 기댓값입니다.
	- 확률변수가 확률변수의 평균으로부터 얼마나 떨어져 분포하고 있는가를 정량적으로 측정하는 척도입니다.
- Biased , Unbiased Estimate의 차이는 무엇인가
	- 추정량 Estimator: 모수를 추정하기 위해 표본의 측정값을 활용하여 계산된 값
	- Biased Estimator: 추정량의 기대값이 모수와 같지 않는 추정량
	 - 예: 표본분산의 평균은 $E(s^2)=\cfrac{n-1}{n}\sigma^2$ 이다
  - Unbiased Estimator: 추정량의 기대값이 모수와 같은 추정량
	- 예: 표본 평균의 평균은 모집단의 평균과 같다. 표본평균의 분포는 중심극한정리에 따라 모평균을 평균 으로 하는 정규분포의 모습을 따릅니다
- Sample Variance 란 무엇인가?
	-  관측값에서 모평균을 빼고 제곱한 값을 모두 더한 뒤 전체 데이터수 n-1을 나눈 값이다.
- Variance를 계산할 때 N 대신 N-1로 나누는 이유는?
	- 표본 분산을 불편추정량으로 만들기 위해서 입니다. ($E(s^2)=\sigma^2)$
- Gauss Distribution에서 MLE와 Sample Variance 중 어떤것을 활용해야 하는가
	- 최대 우도법 Mean Likelihood Estimation : 표본이 어떤 파라미터 $\theta=(\theta_1,\theta_2,...,\theta_n)$ 으로 구성된 모델에서 나왔을 가능성이 가장 높은지 측정하는 방법입니다 
	- 어떤 확률밀도함수 $P(x|\theta)$에서 관측된 표본집합 $(x_1,x_2,...,x_n)$을 활용하여 파라미터를 추정하는 방법입니다
	- 수치적으로 우도를 측정하기 위해서 각 샘플이 추출될 확률(확률분포상 샘플이 뽑힐 확률)을 곱합니다.(각 데이터의 추출은 연달아 일어나는 독립적 사건으로 가정하기 때문입니다)
    - ![](https://raw.githubusercontent.com/angeloyeo/angeloyeo.github.io/master/pics/2020-07-17-MLE/pic1.png)
      예시: 측정값들은 어느 곳에서 추출되었을 가능성이 높아 보이는가?
    - 이를 수학적으로 표현하면 표본집합의 결합확률밀도함수라고 하며 다음과 같은 수식으로 정의할 수 있다. $P(x|\theta)=\prod_{k=1}^{n}P(x_k|\theta)$
    - $P(x|\theta)$가 가장 커지는 $\theta$를 추정값 $\hat{\theta}$로 보는 것이 타당하다
    - 이때 $L(\theta|X)=log(P(x|\theta))$를 로그-최대우도함수라고 하며, 이를 최대화하는 $\theta$값을 찾는 방식, $\cfrac{\partial{}}{\partial{\theta}}L(\theta|x)$를 계산한다

---

- Binomial, Bernouli, Multinomial, Multinouli란 무엇인가?
	- 베르누이 시행 Bernouli trial: 결과가 성공 또는 실패로 두개로만 존재하는 실험이나 시행
	- 이항분포 Binomial Distribution: 성공할 확률이 p 인 베르누이 시행을 n번 반복하였을 때 성공한 횟수가 x라고 한다면, 이에 대응되는 확률의 분포를 이항분포라고 정의합니다
		- $P(n,x)=\displaystyle\binom{n}{x}p^x(1-x)^{n-x}$
	- 다항 분포 multinomial Distrubition: 이항분포의 일반화된 형태로, 여러개의 값을 가질 수 있는 독립확률변수들에 대한 분포입니다
- Beta 함수란 무엇인가?
	- $B(\alpha,\beta)=\displaystyle\int_{0}^{1}x^{\alpha-1}(1-x)^{\beta-1}dx =\cfrac{\Gamma(\alpha)\Gamma(\beta)}{\Gamma(\alpha+\beta)}$
	- 두 매개변수 $\alpha,\beta$에 의해 결정되고, $[0,1]$의 정의역을 갖고 있는 연속확률분포
	- factorial의 일반화된 형태인 감마함수와 특별한 관계식을 갖고 있다
- Beta distribution란 무엇인가?
	- $f(x;\alpha,\beta)=\cfrac{\Gamma(\alpha+\beta)}{\Gamma(\alpha)\Gamma(\beta)}x^{\alpha-1}(1-x)^{\beta-1}$로 정의된다
	- $E(X)=\cfrac{\alpha}{\alpha+\beta}\,\,,Var(X)=\cfrac{\alpha\beta}{(\alpha+\beta)^2(\alpha+\beta+1)}$의 성질을 갖는다
- Dirichlet Distribution이란 무엇인가?	
	- 베타분포의 일반화된 정의이자, 다항 분포에 대한 사전 켤레 확률이다.
	- $x_1,x_2,..,x_k$는 모두 양의 실수이며 $\sum_{i=1}^{k}x_i=1$의 값을 갖는다고 하자. $\alpha=(\alpha_1,\alpha_2,...,\alpha_k)$라고 하자., $B(\alpha)= \cfrac{\prod_{i=1}^{k}\Gamma(\alpha_i)}{\Gamma(\sum_{i=1}^{k}\alpha_i)}$로 정규화 상수라 하자
	- $f(x_1;\alpha_1,\alpha_2,...,\alpha_k)=\cfrac{1}{B(\alpha)}\prod_{i=1}^{k}x_i^{\alpha_i-1}$ 이다
- Gamma function은 무엇인가?
	- $\Gamma(\alpha)=\displaystyle\int_{0}^{\infty}x^{\alpha-1}e^{-x}dx=(\alpha-1)!\,\, if(\alpha\in \textbf{Z})$
- Gamma Distribution란 어디에 쓰이는가?
	- $\alpha,\beta$ 두 파라미터에 의해 결정되는 분포로, $\alpha$는 형태모수 shape paramter, $\beta$는 척도모수 scale parameter라고 부릅니다
	- $f(x;\alpha,\beta)=\cfrac{1}{\beta^{\alpha}\Gamma(\alpha)}x^{\alpha-1}\cdot exp(-x/\beta)$
	- 어떤 사건이 $\alpha$ 번 발생하는데 까지 걸리는 시간을 표현하는데 주로 쓰입니다
	- $E(X)=\alpha\beta ,\,\,Var(x)=\alpha\beta^2$ 의 성질을 갖습니다
- Poisson distribtion은 어디에 쓰이는가?
	- $f(x;\lambda)=\cfrac{\lambda^xe^{-\lambda}}{x!}$
	- 단위시간 발생된 사건의 횟수를 표현하는데 주로 쓰입니다
- Bias and Variance Trade-off는 무엇인가?
	- 편향은 학습 알고리즘에서 잘못된 가정을 하였을 때 발생하는 오차이고, 분산은 트래이닝 셋에 내재된 fluctuation에 의해 발생되는 오차입니다 모델이 단순한 형태라면 과적합이 발생하지 않지만, 과소적합 문제가 발생하는데 이 경우 높은 편향과 낮은 분산을 갖게 되고, 모델이 복잡한 형태라면 과적합이 발생하지만, 과소적합 문제를 줄일 수 있다. 이 경우 낮은 편향과 높은 분산값을 갖게 될 것입니다.
- Congugate Prior란?
	- $P(\theta|x)=\cfrac{P(x|\theta)P(\theta)}{p(x)}$ 의 관계식에서 각각을 Posterior, Likelihood, Prior,Evidence라고 부르고, $P(\theta|x),p(x|\theta)$ 쌍을 cojugate prior라고 부릅니다

---

### 가설 검정 Hypothesis Test

- 귀무가설 Null Hypothesis $H_0$, 대립가설Alternative Hypothesis $H_a$이란?
	- 기존의 주장이 틀렸음을 검증하기 위해 세우는 가설들로, 기존의 주장을 귀무가설$H_0$, 귀무가설에 반대되는 주장을 대립가설$H_a$이라고 부릅니다
- Confidence Interval 신뢰 구간, Confidence Level/Significance Probability 유의 수준/유의 확률
	- 1종 오류(귀무가설을 기각했지만 실제론 귀무가설이 맞는 경우)가 발생할 확률과 1종 오류가 발생되는 영역의 여집합을 각각 유의 수준$\alpha$ 과 신뢰구간이라고 부른다
	- 모수가 해당 범위내에 존재할 확률을 각각 신뢰구간, 1-유의 수준 $\alpha$ 으로 볼 수 있다
- 채택역 Acceptance Region, 기각역 Reject Region/Critical Region
	- Confidence Interval 영역안을 수용역 Acceptance Region, Confidence Interval의 영역 밖을 기각역Reject Regon/Critical Region이라 부릅니다
	- 표본값이 수용역에 있으면 귀무가설을 채택하고, 기각역에 있으면 대안가설을 대립가설을 채택합니다
- 임계값 Critical Value
	- Confidence Interval의 경계가 되는 값을 임계값 Critical Value라고 한다
- 단측검정One-Sided Test, 양측검정 Two-Sided Test
	- 기각역을 한쪽에 둘것인가, 양쪽에 둘것인가에 따라 단측검정 One-Sided Test, 양방향으로 검정하는 것을 양측검정 Two-Sided Test으로 분류합니다
- 1종 오류와 2종 오류	
	- 1종 오류(FP): 귀무가설을 기각했지만, 실제론 귀무가설이 맞는 경우,즉 False Positive 임을 의미합니다
	- 2종 오류(FN): 귀무가설을 채택했지만, 실제론 귀무가설이 아닐 경우, 즉 False Negative 임을 의미합니다
- Covariance와 Correlation이란 무엇인가?
	- Covariance와 Correlation Coefficient 모두 2개의 확률변수에 대하여 선형관계를 측정하는 척도입니다. 상관계수는 공분산을 -1~1의 scale 없는 값으로 정규화 시킨 값입니다.
	- $Cov(X,Y)=E[(X-E[X])(Y-E(Y)]$
- Coefficient of Determination이란 무엇인가?
	- 종속변수의 분산중 독립변수의 설명되는 비율을 측정한 지표입니다.
	- 해당 통계모델이 대상을 얼마나 잘 설명할 수 있는가를 측정한 지표입니다
	- SST(Sum of Squared Total): $SST=\sum_{i=1}^{n}(y_i-\bar{y})^2$
	- SSR(Sum of Squared Residual): $SSR=\sum_{i=1}^{n}(y_i-\hat{y}_i)^2$
	- $R^2=1-\cfrac{SSR}{SST}$
- P-value란 무엇인가?
	- 해당 표본을 기준으로 귀무가설을 기각하였을 때, 1종 오류를 범할 확률입니다

---

- Likelihood-ratio test란 무엇인가
	- parameter 수가 다른 모델을 세울 때 어떤 paramter 수를 갖고 있는 모델이 더 높은 우도를 갖고 있는가 비교하는 방법입니다
	- $l_0=L(x_1,x_2,...,x_n|\theta)$
- Explained variance란 무엇인가?
- Unexplained variation이란 무엇인가?
- Total Variance Distance란 무엇인가?

---

## Machine Learning

- Linear Regression이란 무엇인가?
	- 종속변수와 1개 이상의 독립변수의 관계를 affine 변환으로 가정하여, 해당 데이터에 가장 설득력있는 모델을 찾는 방법론입니다.
- Frequentist와 Bayesian의 차이점은 무엇인가?=
	- 확률을 장기적으로 일어나는 사건의 빈도로 볼 것인가 사건 발생에 대한 믿음 등의 주관적인 요소로 볼것인가에 따라 빈도주의와 베이지안 학파로 분류됩니다
  - 빈도주의
	- 얼마나 빈번하게 특정한 사건이 반복되는가를 관찰하여 가설을 세우고 모델을 만듭니다. 모수는 우리가 모르는 고정된 상수로 바라봅니다
	- 사건이 독립적이고, 반복적이며, 정규분포의 형태일 경우 사용하기 좋습니다
	- 계산이 비교적 복잡하지 않기 때문에 쉽게 처리할 수 있습니다.
	- 다만 사전에 관찰지식이 없는 경우 실험 결과의 신뢰가 떨어질 수 있습니다
  - 베이지안
	- 베이지안 학파는 고정된 데이터의 관점에서 파라미터에 대한 신념의 변화를 분석합니다
	- 모수는 확률적으로 변하는 수로 가정합니다
	- 베이지안은 수학적으로 어렵고, 계산량이 많지만 현대에 들어 컴퓨터 연산능력의 향상과, 알고리즘 개발로 점차 활용되고 있습니다
	- 확률 모델이 명확히 설정되어 있다면 조건부로 가설을 검증하기 때문에 가설의 타당성이 높습니다
	- 다만 사전지식 모델링에 따른 사후 확률결과가 크게 다를 수 있습니다
- 차원의 저주는 무엇인가?	
	* 데이터 공간의 차원이 커질수록, 가능한 벡터 경우의 수가 기하급수적으로 늘어나고, 그에 따라 학습에 필요한 데이터의 수도 증가합니다. 데이터 갯수가 유한하다면 데이터 공간속 train dataset은 점점 희박하게 분포되므로, 학습에 어려움을 발생시킵니다
- Train, Test, Validate 로 나누는 이유는 무엇인가?
	- Train Set과 Test Set은 각각 모델을 학습시키고, 모델의 성능평가를 위해 데이터를 분리한 것입니다. validation Set은 모델이 Test Set에만 좋은 성능을 갖지 않도록, 모델 평가에 사용되는 다른 데이터셋입니다
- Cross Validation이란 무엇인가?
	- 데이터셋을 k등분하여 각 j($1\le j\le k)$회 번쨰의 학습에서 j번째 fold를 validation set, 나머지를 training set으로 활용하여 학습시키는 방식이다
	- 데이터 셋을 k등분 하여, 각각을 폴드라고 할 떄, 하나의 폴드를 validation set, 나머지를 train set으로 활용하여 k번 반복하여 학습시키는 방법입니다
	- 이렇게 학습시키면 모든 데이터셋을 훈련 및 평가에 활용할 수 있다
	- 데이터 부족으로 인한 언더피팅을 방지하고, 평가에 활용되는 데이터셋의  편중을 막을 수 있다
	- 단 iteration 횟수가 많아지기 때문에, 모델 훈련과 평가 시간이 오래 걸리게 된다
- Supervised Learning이란 무엇인가?
	- 정답(레이블이) 존재하는 데이터를 활용하여 모델을 학습시키는 방법론입니다.
	- 레이블이 존재하기 때문에 모델이 예측한 값이 맞았는지 틀렸는지 평가할 수 있습니다
	- 분류Classification,회귀Regression 등이 대표적으로 존재합니다
- Unsupervised Learning이란 무엇인가?
	- 정답(레이블)이 존재하지 않는 데이터를 활용하여 모델이 데이터 내에 존재하는 패턴과 상관관계를 찾게 하는 방법론입니다
	- 해당 데이터에 대한 사전지식이 없는, 데이터의 숨겨진 특징이나 구조들을 파악하기 위하여 활용됩니다.
	- 군집화, 패턴 인식등의 방법이 있습니다. 해당 알고리즘으로는 K-Means, DBSCAN과 Mean-Shift, PCA 등이 존재합니다
- Semi-supervised Learning이란 무엇인가?
	- ![](https://blog.est.ai/assets/img/2020/1109/1.jpeg)
	

---

- Decision Theory란 무엇인가?
	- 수학적, 통계학적으로 불확실한 가운데 어떤 문제에 대한 가장 합리적인 결정을 내리는 방법들을 탐구하는 이론입니다.
- Receiver Operating characteristic Curve란 무엇인가?
	- $ROC=\cfrac{\cfrac{TP}{TP+FN}}{\cfrac{FP}{TN+FP}}=\cfrac{Recall}{1-Specificity}$
	- 세로축을 Sensitivity(민감도)(or Recall(재현율)), 가로축을 1-Specificity(특이도)로  하여 2차원 좌표평면에 그린 곡선으로, 해당 곡선의 아래면적이 1에 가까울수록 좋은 classifier라고 평가할 수 있는 척도입니다.
- Precisin Recall 이 무엇인가?
	- Precision는 참으로 예측한 것중 실제 참인것의 비율을 ,Recall은 실제 참인 사건중 참으로 예측한 것의 비율을 의미합니다. 
	- Precision은 참으로 예측하는 것을 보수적으로 취할 때, Recall은 되도록이면 참으로 예측하는 전략을 취할때 높아지는 경향이 있습니다. 따라서 대부분의 경우 Precision과 Recall은 서로 Trade-off하는 관계에 있습니다
	- Precision는 음성인 것을 양성으로 예측하였을 때 리스크가 큰 경우, Recall은 양성인 것을 음성으로 예측하였을 때 리스크가 큰 경우 중요도가 높아진다 볼 수 있습니다.
	- 예를 들면 어떤 주식을 샀을때 투자에 성공할까를 예측하는 것은 precision을 우선시여겨야 한다고 볼 수 있습니다. 반대로 암환자를 진단하는 의사의 경우 암환자를 정상이라 판별하는 경우 큰 문제가 발생할 수 있으므로, 되도록이면 작은 징후조차 놓치지 않고 recall을 높이는 것을 우선시여겨야 한다고 볼 수 있습니다
	- ![](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Ft1.daumcdn.net%2Fcfile%2Ftistory%2F999D9C465BE116E43C)
		- 해당 벤 다이어그램에선 A를 실제로 날씨가 맑은 날, B를 모델에서 날씨가 맑은 날로 예측하는 것으로 볼 수 있습니다. 그러면 a:FN, b:TP, c:FT, d를 TN으로 볼 수 있습니다
		- $precision=\cfrac{TP}{TP+FP}$
		- $recall=\cfrac{TP}{TP+FN}$
- Precision Recall Curve란 무엇인가?
	- Precision과 Recall 모두 중요한 지표이면서, 서로 trade-off의 관계가 있으므로, Precision과 Recall을 표현하는 2차원 좌표계로 시각화하여, 적절한 Precision,Recall value값을 선택하는 데 활용됩니다
- Type 1 에러와 Type 2 에러는 무엇인가?
	- Type1 error는 False Positive Error로, Positve로 예측하였지만 실제론 Negative 인 경우를 의미하고, Type2 error는 False Negative Error로, Negative로 예측하였지만 실제론 Positve인 경우의 에러를 의미합니다.
	
---

- Entropy는 무엇인가?
	- 새넌 엔트로피는 각 메세지에 포함된 정보량을 측정하는 척도입니다
	- 예를 들어 새넌 엔트로피는 밑이 2이고, 진수가 총 사건에서 발생할 수 있는 경우의 수인 로그로 정의하는데 동전을 N번 던져 발생하는 경우의 수는 $\log_{2}{2^N}=N$으로 N새넌 값을 갖게 됩니다. 
	- $H(x)= - \displaystyle\sum_{i=1}^{n}{p(x_i)log_{2}(p(x_i))}$ 
- Cross Entropy란 무엇인가?
	- 두 확률분포를 구분하기 위해 필요한 정보량을 측정하는 척도입니다
	- Entropy의 차이가 실제값과 예측값이 거의 맞는 경우 0에 수렴하고, 값이 틀릴 경우 KL-Divergence만큼 크도록 정의되었습니다
	- $H(p,q)=-\displaystyle\sum_{i=1}^{N}{p_{i}log({q_i})}$
	- $H(X)=-\mathbb{E}[\log_{2}{p(x)}]$
- Mutual Information이란 무엇인가?
	- 하나의 확률 변수가 다른 하나의 확률 변수에 대해 제공하는 정보의 량을 측정하는 척도입니다. 즉 이때 Mutual Information의 값이 0 이라면 두 확률변수는 독립되었다고 볼 수 있습니다.
	- $\mathbb{I}(x,y)\sim{KL(p(x,y)||P_{X}\otimes{P_{Y}})}$로 정의됩니다
- KL-Divergence란 무엇인가?
	- 두 확률분포의 차이를 계산하기 위해 사용되는 척도입니다.
	- $KL(P||Q)=H(p,q)-H(p)=\displaystyle\sum_{i}{P(i)log}{\cfrac{p(i)}{q(i)}}$
---

- Discriminative Model과 Generative Model은 무엇인가?
	- 판별모델 Discriminative Model은 데이터가 주어졌을 때, 특정 레이블에 속할 확률을 반환하는 알고리즘입니다
	- 생성 모델Generative Model은 주어진 데이터를 학습하여 그와 유사한 분포를 갖는 데이터를 형성하는 모델입니다. 
		- OpenAI에서 공개한 이미지 생성모델 AI 모델 $DALL \cdot E$ 가 그에 해당됩니다
- Discriminator function이란 무엇인가?
	- 적대적 모델 생성 모델 GAN에서 실제 데이터와 Generator가 만든 데이터를 구별함으로서, Generator의 성능을 높이는데 활용되는 함수입니다
---

- ![](https://ko.d2l.ai/_images/capacity_vs_error.svg)
- Overfitting 이란 어떤 문제이고 어떻게 해결하는가?
	- 모델의 구조와 파라미터를 학습 데이터에 너무 가깝게 맞추었을 때 발생하는 현상으로, 학습 데이터에서는 좋은 성능이지만 그 외의 추가된 데이터에 낮은 예측력을 보이는 모델을 만드는 현상입니다 
	- 과도하게 복잡한 모델에 패널티를 주어 규제하거나, 편향되지 않은 더 많은 데이터셋을 활용하여 학습시켜 해당 현상을 개선시킬 수 있습니다 
	- 규제하는 방법으로 Ridge 규제와 Lasso 규제를 활용할 수 있습니다
	- 
- Underfitting이란?
	- 모델의 구조를 지나치게 단순화 하여 낮은 예측력을 갖는 모델을 만드는 현상입니다
	- 데이터에 적합하도록 모델의 복잡도를 높혀주어서 해당 현상을 개선시킬 수 있습니다.

- 이를 해결하는 방법은?
  - Regularization이란?
	  - 모델이 과적합되게 학습되지 않고 일반성을 가질 수 있도록 규제하는 것
	  - 언더피팅을 피하기 위해 고차 회귀 모델을 세운 후, 오버피팅을 방지하는 규제를 활용하여 적합한 모델을 탐색한다
	  - Lasso 규제(L1 규제)
		  - $\hat{\beta}=argmin_{\beta}\cfrac{1}{n}(\mathbf{y}-\mathbf{X}\mathbf{\beta})^T(\mathbf{y}-\mathbf{X}\mathbf{\beta})+\lambda(\begin{Vmatrix} \beta \end{Vmatrix}))$
		  - 손실함수항에 $\lambda$를 곱한 가중치항들의 합을 포함한 것으로, 몇몇의 가중치들은 0에 수렴하게 하여, feature수를 줄이게 하는 역할을 한다
	  - Ridge 규제 (L2)규제
		  - $\hat{\beta}=argmin_{\beta}\cfrac{1}{n}(\mathbf{y}-\mathbf{X}\mathbf{\beta})^T(\mathbf{y}-\mathbf{X}\mathbf{\beta})+\lambda(\begin{Vmatrix} \beta \end{Vmatrix})^2)$
		  - $\cfrac{\partial {J}}{\partial {\beta}}=-2\mathbf{X}^{T}\mathbf{y}+2(\mathbf{X}^{T}\mathbf{X}+\lambda \mathbf{I})\beta=0$
		  - $\hat{\beta}=(\mathbf{X}^{T}\mathbf{X}+\lambda \mathbf{I})^{-1}\mathbf{X}^{T}\mathbf{y}$
		  - 가중치의 절대값을 가능한 작게끔 유도하는 역할을 한다. 따라서 특정 가중치가 지나치게 커져 다른 독립변수의 설명력을 저하시키는 것을 방지한다
	  - Elastic-Net Regression
		  - $\hat{\beta}=argmin_{\beta}(\mathbf{y}-\mathbf{X}\beta)^{T}(\mathbf{y}-\mathbf{X}\beta)+\alpha \begin{Vmatrix} \beta \end{Vmatrix}+(1-\alpha)\begin{Vmatrix} \beta \end{Vmatrix}^2$

---
### 딥러닝
- 딥러닝이란 무엇인가?
	- 여러층을 가진 인공신경망(ANN: Artificial Neural Network)를 활용하여 머신러닝 학습을 수행하는 모델입니다
- 인공신경망이란 무엇인가? 
	- 생물의 뉴런 연결구조를 모방하여 만든 네트워크 구조입니다. 인공신경망은 여러개의 layer로 이루어져 있고, 각 레이어는 정보를 입력받고 내보내는 노드를 뉴런이라 부르는데, 뉴런간의 결합세기를 변화시켜 학습을 하는 비선형적 예측 알고리즘입니다. 
- Activation Function이란 무엇인가?
	- 딥러닝이 비선형적인 수학모델이 되기 위하여 활용하는 함수로,  선형연산의 곱은 행렬곱으로 표현되어, 그 결과가 행렬이기 때문에 중간 활성화함수 없이 단순 선형연산만 활용하여 layer를 쌓는다면 수학적 의미가 없게 됩니다
- **CNN은** **무엇인가?**
	- Convolutional Neural Network의 약자로, 주어진 행렬에 컨볼루션 필터라 불리는 행렬과 Convolution 즉 ,Frobenius Inner Product하여, 특징을 추출합니다 이때 필터는 몇몇 특징을 가지고 있는가를 평가하는 데 활용할 수 있습니다
	- 이때 input 행렬과 output 행렬의 크기를 갖게 하기 위하여, 입력 배열 둘레를 확장하여 0으로 체워넣는 작업을 하는데, 이를 패딩이라 부릅니다
	- ![](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fk.kakaocdn.net%2Fdn%2FbUbC2p%2FbtrbW1UDt7D%2FXnR3xVYMo52kSn0TmQvWVK%2Fimg.png)
	- ![](https://k.kakaocdn.net/dn/OBx1e/btqXBWUBCiX/u3D2GlXJFv4VKHHR2xTYu0/img.gif)
	- 이미지의 크기를 적당히 줄이고, 특정 feature를 강조하기 위하여 Pooling 레이어를 활용합니다
	- 영역을 쪼개고, 각 영역에서 가장 큰 숫자를 선택하는 Max Pooling을 주로 활용합니다
	- 입력 데이터의 shape를 변환시키는 Flatten Layer를 거칩니다
	- 마지막으로 분류를 시행하고 결과를 출력합니다
- **RNN는 무엇인가?**
	- Recurrent Neural Network의 약자로 시퀀스 데이터를 처리하기 위해 도입된 모델입니다. RNN 이전 뉴럴 네트워크와는 다르게 앞서 입력된 데이터를 기억한다는 점에서 차이가 존재합니다.
	- 단 기존 RNN는 다음 단계로 업데이트를 전파할 때마다 전파되는 양이 점점 줄어드는 기울기 소멸 문제가 발생하여, 이를 개선하고자 LSTM이나 GRU 모델이 개발되었습니다
	- 자동 번역과 이미지 캡션 생성등에 활용될 수 있습니다
- **LSTM**이란 무엇인가
	- Long Short Term Memory의 약자로,  은닉층 메모리셀에 입력,망각,출력 게이트를 추가하여 불필요한 기억을 지우고 기억할 것을 정하는 기능을 추가한 RNN입니다
	- [레퍼런스](https://wikidocs.net/152773)
- **GRU**란 무엇인가?
	- LSTM과 비슷하지만, Tiem-Step의 Cell을 좀 더 간소화 시킨 버전으로서, 여러 평가에서 LSTM과 비슷한 성능 대비 빠른 학습 속도를 가지고 있는 모델입니다
	- 일반적으로 데이터의 양이 적을 때는 매개 변수의 양이 적은 GRU가 낫고, 데이터 양이 많으면 LSTM이 좋다고 경험적으로 알려져 있습니다
- Newton's Method는 무엇인가?
	- 근을 찾는 수치해석적 방법중 하나 입니다. 
	- $x_{n+1}=x_{n}-\cfrac{f(x_n)}{f'(x_n)}$
	- $f'(x_{n})(x_{n}-x_{n+1})=f(x_n)$ 을 만족시키는 $x_{n+1}$를 찾는 방법입니다
	- ![](https://upload.wikimedia.org/wikipedia/commons/thumb/e/e0/NewtonIteration_Ani.gif/600px-NewtonIteration_Ani.gif)
- Gradient Descent란 무엇인가?
	- global minimum을 찾기 위하여 경사의 반대방향으로 계속 이동시키는 것을 반복하는 최적화 알고리즘입니다. 
	- 이때 step size를 크게하면, 한번에 이동하는 거리가 크므로 빠르게 수렴할 수 있지만, global minumum을 지나치고 수렴하지 못하게 될 위험성이 존재합니다. 반대로 step size를 작게 하면 알고리즘이 구동되는 데 걸리는 시간이 길게 됩니다
	- 또한 해당 알고리즘이 global minumum이 아닌 local minumum에서 수렴할 가능성이 존재합니다
	- ![](obsidian://open?vault=My_Second_Brain&file=Image%20Storage%2Fgradient_descent.gif)
- Stochastic Gradient Descent란 무엇인가?
	- 파라미터를 업데이트하는데 전체 훈련 데이터셋을 활용하는 것이 아니라, 한번의 업데이트에 무작위 샘플 하나를 선택하여 진행한다. 즉 다시말하자면 배치 사이즈가 1인 경사하강법 알고리즘입니다
	- 배치사이즈가 매우 작기 때문에, 학습 속도가 매우 빠릅니다. 또한 Cost Function이  불규칙한 것이, local minumum을 빠져나오는데 도움이 될 수 있다
	- 다만 샘플의 선택이 확률적이기 때문에 기존 경사 하강법보다 노이즈가 많이 존재하고, 불안정하게 수렴하는 경향이 있다
>   reference)
		- epoch: 훈련 데이터셋에 포함된 모든 데이터들이 한번 모델을 통과한 횟수
		- batch size: 한번의 파라미터 업데이트에 활용되는 샘플 데이터의 수
		- batch: epoch/batch size
- Internal Covariate Shift란 무엇인가?
	- Covariate: 독립변수
	- Covariate Shift: deep learning에서 traing dataset과 test dataset에서의 data distribution의 차이가 심해지는 현상
	- Internal Covariate Shift: 신경망 층 사이에서 발생하는 입력 데이터의 분포 차이가 심해지는 현상
- Batch Normalization은 무엇이고 왜하는가?
	- Internal Covariate Shift 현상을 완화시키기 위해 배치단위로 정규화를 시키는 방법
- Backpropagation이란 무엇인가?
	- cost function을 활용하여, cost function을 최소화 시킬 수 있도록 output 직전 layer에서부터 input 직전 layer까지의 파라미터를 갱신하는 과정입니다
	- 최적의 parameter값을 구하기 위하여 chain rule을 구합니다
	- [레퍼런스 3Brown1Blue](https://youtu.be/Ilg3gGewQ5U)
- Optimizer의 종류와 차이에 대해 아는가?
	- Cost function을 최소화 시키기 위해 사용되는 알고리즘들
	- ![](https://velog.velcdn.com/images/chang0517/post/f955570a-69fb-4c2a-9f19-f9c7264599ca/image.png)
	- Batch Gradient Descent
		- 미분을 활용하여, 경사의 반대방향으로 진행하는 Gradient 방법론입니다. 이때 한번의 파라미터 업데이트에 전체 훈련 데이터셋을 활용합니다
	- Stochastic Gradient Descent
		-  미분을 활용하여, 경사의 반대방향으로 진행하는 Gradient 방법론입니다. 이때 한번의 파라미터 업데이트에 일부 또는 하나의 랜덤 배치활용합니다
	- Momentum
		- SGD에 모멘텀 개념을 추가한 것으로, global minimum이 아닌 Local minimum에 데이터가 빠져 수렴하는 현상을 방지하기 위해, 이전의 배치 학습결과도 활용하는 '관성'을 부여합니다
	- Adagrad(Adaptive Gradient Algorithm)
		- 학습을 통해 크게 변동이 있었던 가중치의 학습률을 줄이고,변동이 별로 없었던 가중치는 학습률을 증가시키는 알고리즘입니다
	- RMSprop
		- Adagrad와 유사하지만 Gradient의 합계 대신 지수 감쇠 평균을 활용합니다. 또한 운동량 계산에서 가장 최근의 기울기만 고려합니다
	- Adam(Adaptive Moment Estimation)
		- Momentum과 RMSProp을 결합한 방법입니다
	- Adabelief
		- Adam을 수정한 딥러닝 최적화 알고리즘입니다
		
- Gradient Vanishing 이 무슨 문제인지 아는가?
	- 역전파과정에서 정답과의 오차를 통해 가중치를 갱신하는데, 입력층으로 갈수록 기울기가 작아져 가중치들이 업데이트가 잘 되지 않는 현상입니다
	- 이 떄 acitvation function으로 시그모이드 함수 대신 ReLu(Recitified Linear Unit fuction) 계열 함수를 사용하는 것을 하거나, batch normalization을 통해 Gradient Vanishing 문제를 어느정도 완화시킬 수 있습니다
	- $Leakly \,\,ReLU=max(0.01x,x)$
---

- Ensemble이란?
	- 여러개의 분류기의 예측들을 결합함으로서 보다 정확한 예측을 하는 기법입니다
	- 앙상블 학습은 하드보팅(여러개의 분류기가 투표를 통해 최종 예측 결과를 선정),과 소프트 보팅(모든 분류기가 예측한 레이블 값의 확률 평균을 구한 뒤, 가장 높은 레이블 값을 최종 결과로 선정)으로 나뉩니다
- Bagging이란?
	- 부트스트래핑 Bootstrap을 통해 모델을 학습시키고, 결과를 집계 Aggregating하는 방법
	- 모두 같은 유형의 알고리즘 기반의 분류기를 활용한다
- Bootstrapping이란?
	- 머신러닝에서 bootstrapping이란 주어진 데이터셋으로부터 복원추출한 새로운 데이터셋을 만드는 방법입니다.
- Boosting이란?
	- 여러개의 분류기가 순차적으로 학습. 이전 분류기가 예측이 틀린 데이터에 대해 올바르게 예측할 수 있도록, 다음 분류기에게 가중치를 부여하면서 학습과 예측을 진행한다

- Support Vector Machine 이란 무엇인가?
	- 주어진 데이터집합을 바탕으로, 새로운 데이터를 어느 카테고리에 속하게 할지 결정하는 boundary를 만드는 알고리즘
- AdaBoost, Logit Boost, Gradient Boost란?


- [plus reference](https://deeesp.github.io/deep%20learning/AI_interview_qna_1/)
- 

---

## Linear Algebra

- Linearly independent란?
	- 하나의 벡터가 남은 벡터들의 선형결합으로 표현되지 않는 벡터들만 모인 집합입니다
	- 집합에 속한 벡터들로 선형결합하여서 그 합이 0일때, 가능한 선형조합의 계수가 0으로만 이루어졌다면 이를 선형독립이라 정의합니다
- Basis와 Dimension이란 무엇인가?
	- Basis: 선형독립집합 $\beta$ 의 $span(\beta)$가 어떤 벡터공간 $V$와 동일하다면, 선형독립집합$\beta$를 $V$의 기저라고 정의합니다. 그리고 기저 $\beta$ 의 원소의 갯수를 $V$의 차원이라 정의합니다
- Null space란 무엇인가?
	- 선형변환 $T$ : ($V \rightarrow W$)V to W가 있을 때, $T(x)$ 가 영벡터가 되는 벡터공간$V$의 원소 $x$를 모은 집합을 Null Space라고 정의합니다
- Symmetric Matrix란?
	- 어떤 행렬 $A$가 있을 때, $A_{ij}=A_{ji}$인 행렬을 대칭행렬이라고 부릅니다
	- 유한차원 복소내적공간 finite dimensional complex inner product space에선 선형연산자 $T$가 normal operator라면, 유한차원 실수내적공간에선 선형연산자 $T$가 self-adjoint라면 대각화가 가능합니다. 실수벡터공간에서 대칭행렬은 언제나 self-adjoint이므로, 대칭행렬은 항상 대각화가 가능하다는 특성을 가지고 있습니다
- Positive-Definite란?
	- 어떤 선형연산자 $T$가 있을 때, 모든 $x\ne0$에 대하여 $\langle T(x),x\rangle > 0$ 이면 $T$를 Positive-Definite라 부릅니다
	- 이때 Positive-Definite 이기 위한 필요충분조건은 모든 고유값이 양수인 것입니다
	- 이때 임의의 선형연산자 $T$에 대하여 $TT^*$는 Positive-Definite이므로, $TT^*$의 고유값은 모두 양수인데, 이는 Singular Value Theorem 정리에 활용됩니다
- Rank란?
	- 선형연산자 $T:V \to W$가 있을때, $T(V)$를 $T$의 range라고 하며, $dim(T(V))$를 $T$의 랭크라고 정의합니다
- Determinant가 의미하는 바는 무엇인가?
	- 행렬의 가역성을 판단하는데 활용할 수 있는 함수로, 행렬식이 0이라면 이에 대응되는 선형변환은 비가역적입니다. 반대로 행렬식이 0이 아니라면, 이에 해당되는 선형변환은 가역적입니다
- Eigenvector는 무엇인가?
	- 선형연산자 $T:V\to W$가 있을 때 $T(v_j)=\lambda_jv_j$ 인 $v_j\in V$ 를 고유벡터라고 정의합니다
- Eigenvector는 왜 중요한가?/SVD란 무엇인가? 왜 중요한가? /PCA란 무엇인가?
	- 임의의 한 행렬을 3개의 특별한 행렬의 곱(유니타리\*시그마\* 유니타리)으로 표현할수 있다는 정리입니다
	- 행렬의 값을 근사하거나 차원을 축소하는데 활용되는 PCA의 기반이 되기 때문입니다
	- 특이값 분해후 크기순으로 특이값 전체중 일부반 취한 $\Sigma^\prime$을 활용하여 차원을 축소하는 것을 PCA라고 한다
- Jacobian Matrix란 무엇인가
	- 직교좌표계에서 다른 좌표계로 변환하여 다중적분할 때 활용되는 행렬입니다

---

## Algorithm and Data Structure
### 시간복잡도란?
- 알고리즘이 완료되기 까지의 시간을 입력되는 배열의 길이를 독립변수로 하여, 계수없이 가장 높은 차수의 항으로 표현하는 방법이다

### 검색 알고리즘
- 선형 검색 linear search
	- 시간 복잡도
		- Best: $O(1)$
		- Avg: $O(n)$
		- Worst: $O(n)$
	- 선형으로 나열된 배열에서 target 키값이 나올 때 까지 맨 앞에서부터 스캔하는 알고리즘
- 이진 검색 binary search : 
	- 시간 복잡도
		- Best: $O(1)$
		- Avg: $O(\log_{}{n})$
		- Worst: $O(\log_{}{n})$
	- 배열이 오름차순으로 정렬되어 있을 때 (내림차순도 가능하다), 배열의 median 원소값과 target 원소값을 비교하여,  target값이 더 큰경우 median 을 포함한 왼쪽 원소들을 탐색 영역에서 제거,  target값이 더 작은 경우 median을 포함한 오른쪽 원소들을 탐색영역 제거하는 방법
	- ![](https://k.kakaocdn.net/dn/c7MbUC/btrfhIYVCht/Pv3AuFNI8ln9Mvi8Ab4OkK/img.gif)
	- 
- 해시법 hash search
	- 배열을 원소 길이로 나눈 값을 해시hash로 지정하여, 데이터의 인덱스로 활용하는 방법입니다.
	- 일반적으로 하나의 해시값에 여러개의 원소값이 대응될 수 있으므로, 이러한 충돌문제를 해결하기 위해 해시값이 같은 원소를 연결 리스트로 관리하는 체인법이나 빈 버킷을 찾을 때 까지 해시를 반복하는 오픈 주소법을 활용합니다
		

### 저장 알고리즘
- 스택 Stack : LIFO(Last In First Out을 원칙으로 하는 방식)
	- 스택 관련 용어 
	    - 푸시 $push$: 스택에 데이터를 넣는 작업
	    - 팝 $pop$: 스택에서 데이터를 꺼내는 작업
	    - 꼭대기 $top$ : 데이터를 꺼낼 부분
	    - 바텀 $bottom$ : 스택 맨 아래 부분
	- 스택 구현하기
	    - 리스트형으로 구현한다
	    - 인덱스 0을 바닥으로 표현한다
	    - 스택 포인터: 스택에 쌓여있는 데이터의 갯수
- 디큐 deque:  왼쪽 끝/ 오른쪽 끝 양방향으로 데이터를 접근하여 추가 및 삭제가 가능한 구조
- 큐 queue : 선입선출 FIFO(First in First Out)을 원칙으로 하는 데이터 구조
	- 큐 관련 용어
	    - 인큐$enqueue$: 큐안에 데이터를 추가하는 작업
	    - 디큐$dequeue$:큐에서 데이터를 꺼내는 작업
	    - 프론트$front$: 데이터를 꺼내는 쪽의 위치
	    - 리어 $rear$: 데이터를 넣는 쪽의 위치
	    
	- 링 버퍼 ring buffer로 큐 구현하기 : 시간 복잡도  $O(1)$
![Untitled](2%20컴퓨터과학%20아카이브/3%20알고리즘%20및%20자료구조/레퍼런스_4%20스택과%20큐/Untitled%202.png)
- 배열 맨 끝의 원소가 배열 맨 앞의 원소와 맞닿는 닫힌 띠 형태의 자료구조이다
- 프론트가 0이여야 할 필요가 없으므로, 인큐나 디큐를 할 시, 모든 원소를 한칸씩 땡김으로서 생기는 복잡도$O(n)$ 대신, $front$  또는 $rear$값을 업데이트 하는 복잡도 $O(1)$만 존재한다
- 이번 예제로 구현하는 것이 링 버퍼이다

### 재귀 알고리즘
- 자기 자신을 활용하여 정의내려진 알고리즘
- 예
	- 팩토리얼
	- 유클리드 호제법: 최대 공약수 구하기
	- 하노이의 탑
	- 8퀸 문제

### 정렬 알고리즘
- 순서가 있는 배열을 특정 기준에 따라 순서를 바꾸어 다시 늘어놓는 작업이다
- 용어
    - 오름차순 $ascending$: 작은 값부터 큰 값으로 원소를 나열하는 것
    - 내림차순 $descending$: 큰 값부터 작은값으로 원소를 나열하는 것
- 알고리즘의 안정성$stability\,\,of\,\,algorithm$
    - 동일한 키값을 가진 요소가 정렬을 한 후에도 순서가 동일한 정렬 알고리즘을 안정 정렬이라고 한다. 반대로 동일하지 않은 정렬 알고리즘을 불안정 정렬이라고 한다
- 단순 정렬 알고리즘의 시간복잡도: 버블,선택,삽입 알고리즘의 시간 복잡도는 모두 평균적으로 $O(n^2)$으로 프로그램 효율이 좋지 않다

#### 종류
- 버블 정렬- 단순 교환 정렬
	- 시간복잡도
		- Best: $O(n)$
		- Avg: $O(n^2)$
		- Worst $O(n^2)$
	- 이웃한 두 원소의 대소관계를 비교하여 교환을 반복하는 알고리즘
	- 개선안
		- 버블 알고리즘 개선 버전 1
			- 어떤 한번의 패스 과정동안 원소 교환이 이루어지지 않는다면, 모든 원소가 정렬된 상태이기 때문에 정렬하는 것은 멈추는 조건문을 추가할 수 있습니다
		- 버블 알고리즘 개선버전 2
			- 각각의 패스에서 비교 교환하다 특정 원소에서 교환을 하지 않는다면, 그 원소보다 앞에 있는 원소들은 이미 정렬된 것이다. 
		- shaker(cocktail) 정렬 알고리즘
			- 홀수 패스에선 가장 작은 원소를 왼쪽에 보내고, 짝수 패스에선 가장 큰 원소를 오른쪽으로 이동시키는 방법
	- ![](https://upload.wikimedia.org/wikipedia/commons/c/c8/Bubble-sort-example-300px.gif)
- 단순 선택 정렬 straight selection sort 
	- 시간 복잡도
		- $O(n^2)$
	- $j$번째로 작은 원소를 배열 $j-1$번째에 위치시키기 위해, 한번의 루프때마다 배열의 정렬되지 않는 부분중 가장 작은 원소를 찾아다가 $j-1$번째 원소와 위치와 교환시키는 방법입니다
	- ![](https://upload.wikimedia.org/wikipedia/commons/9/94/Selection-Sort-Animation.gif)
- 단순 삽입 정렬 straight insertion sort 
	- 시간 복잡도
		- Best: $O(n)$
		- Avg: $O(n^2)$
		- Worst: $O(n^2)$
	- 손안의 카드를 정렬하는 방법과 유사합니다
	- 두번째 원소부터 target 원소가 됩니다. target 원소 앞의 정렬된 배열들과 크기를 비교하여, 원소 배열이 계속 오름차순일수 있도록, target 원소를 정렬된 배열내에 삽입한다.
	- ![](https://upload.wikimedia.org/wikipedia/commons/0/0f/Insertion-sort-example-300px.gif)
- 셸 정렬 shell sort
	- 시간복잡도
		- Best: $O(n)$
		- Avg: $O(n^{1.5})$
		- Worst: $O(n^2)$
	- 단순 삽입 정렬의 장점(이미 정렬을 마쳤거나 정렬이 거의 마쳐가는 상황에서 속도가 빠름)을 갖고, 단점(삽입할 위치가 멀리 떨어져 있다면 이동속도가 많아짐)을 보완한다
	- 배열이 $[x_1,x_2,...,x_n]$ 의 길이를 $n$이라 하였을때  $gap_1=n//2$ 의 간격에 있는 원소쌍들 간 크기를 비교하여 정렬한다. 계속하여 $gap_k=n//2^k$의 간격으로 원소들간 크기들을 비교하여 정렬한다
	- 
- 퀵 정렬 quick sort
	- 시간복잡도
		- Best: $O(n\cdot \log_{}{n})$
		- Avg: $O(n\cdot \log_{}{n})$
		- Worst: $O(n^2)$
	- 피봇 Pivot이란 분할의 기준이 되는 원소를 정해 계속해서 배열을 이분할 하는 방법입니다. 피봇보다 작은 원소와 피봇보다 큰 원소들이 모인 배열로 이분할합니다.
	- 시간복잡도가 $O(n\cdot \log_{}{n})$으로 많은 상황에서 가장 빠른 알고리즘으로 알려져 있습니다
	- 그러나 매번 1개와 나머지 원소로 그룹이 나눠지는 경우 시간 복잡도는 $O(n^2)$가 될 수 있습니다
	- 서로 이웃하지 않는 원소를 교환하므로 불안정한 알고리즘입니다
	- 배열을 두 그룹으로 나누기
		- 중앙에 위치한 원소를 피벗으로 두고, 각 배열의 왼쪽끝을 $p_{l}$, 배열의 오른쪽 끝을 $p_{r}$이라고 한다. 이때 $a[p_{l}] \ge{x}$ 가 성립하는 원소를 찾을 때 까지 $p_{l}$를 오른쪽 방향으로 스캔, $a[p_{r}]\le{x}$가 성립하는 원소를 찾을 때 까지 $p_{l}$를 왼쪽 방향으로 스캔한다. 이때 $p_{l},p_{r}$이 각각 멈춘 위치의 원소를 서로 교환한다,
	- ![](https://user-images.githubusercontent.com/36489953/42190383-0923306a-7e5d-11e8-86b3-1e9f7a79b782.gif)
- 병합 정렬 merge sort : $O(n\cdot \log_{}{n})$ 이다
	- 안정정렬 알고리즘
	- 시간복잡도
		- Best: $O(n\cdot \log_{2}{n})$
		- Avg: $O(n\cdot \log_{2}{n})$
		- Wosrt: $O(n\cdot \log_{2}{n})$
	- 하나의 배열을 계속 이분할한다음, 분할된 배열을 정렬한 다음, 분할된 두 배열을 다시 합쳐 하나의 정렬된 배열로 만드는 알고리즘입니다
	- 두 배열을 하나로 합칠 때는 리스트의 원소값을 하나씩 비교해가며, 두 리스트의 원소값중 더 작은 값을 새로운 리스트로 옮기면서 합칩니다
	- ![](https://user-images.githubusercontent.com/36489953/42171944-ed5814c8-7e1a-11e8-9d30-10ae8047bb17.gif)
- 힙 정렬 heap sort:  $O(n\cdot \log_{2}{n})$
	- 시간복잡도
		- Best : $n\cdot \log_{}{n}$
		- Avg: $n\cdot \log_{}{n}$
		- Worst: $n\cdot \log_{}{n}$
	- 힙(heap: 부모의 값이 자식의 값보다 항상 크다는 조건을 만족시키는 완전 이진 트리)의 특성을 활용하여 정렬하는 알고리즘
	- 만약 힙에 새로운 요소가 들어온다면, 일단 마지막 노드에 삽입을 한다. 그리고 부모 노드와의 크기를 비교하면서 원소를 교환합니다
	- ![](https://upload.wikimedia.org/wikipedia/commons/4/4d/Heapsort-example.gif)

> ref
> - [Time complexity of Search and Sort algorithms](https://he-s3.s3.amazonaws.com/media/uploads/c950295.png)
> - ![](https://he-s3.s3.amazonaws.com/media/uploads/317c55e.png)
- [gif of Sorting-Algorithms](https://github.com/edwardmartins/Sorting-Algorithms)
- 
### 리스트list
- 데이터에 순서를 매겨 늘여놓은 자료구조이다
- 용어 
	- 노드 node : 리스트를 이루는 각각의 원소 element
	- 포인터 pointer: 	어떤 값을 가르키기 위한 형식 
	- 머리 노드 head node: 맨 앞에 있는 노드
	- 꼬리 노드 tail node: 맨 끝에 있는 노드
	- 앞쪽 노드 predecessor node:각 노드 바로 앞에 있는 노드
	- 뒤쪽 노드 successor node:각 노드 바로 뒤에 있는 노드

#### 리스트의 종류
- 연결 리스트 linked list
	- 노드가 1차원적으로 연결되어 있고, $1 \to 2\to 3\to ... \to N$로 한쪽 방향으로 호출할 수 있지만, 건너 뛰거나 반대방향으로 호출할 수 없는 데이터 구조

### 트리
- 트리는 다음과 같은 노드$node$와 가지$edge$로 구성된 구조이다
- 관련 용어들
    - 루트$root$
        - 트리의 가장 위쪽에 있는 노드
    - 리프 $leaf$ / 단말 노드 $terminal\,\,node$ / 외부 노드 $external\,\,node$
        - 트리의 가장 아래쪽에 있는 노드
    - 비단말 노드 $non-terminal\,\,node$/ 내부 노드$internal\,\,node$
        - 리프를 제외한 모든 노드(루트를 포함한다)
    - 노드의 가족관계
        - 어떤 노드 $y$ 가 가지로 연결된 아래쪽 노드 $x_{1},x_{2},...,x_{n}$을 가지고 있다면
            - $y$를 $x_{1},x_{2},...x_n$의 부모 $parent$라고 부른다
            - $x_1,x_2,...,x_n$을 $y$ 의 자식 $child$이라 부른다
            - $x_1,x_2,...,x_n$는 서로 형제 $sibling$이라 부른다
            - $y$는 $n$개의 자식을 가지고 있고, 이를 다시 말해 차수 $degree=n$이라고 표현한다
            - $y$에서 위쪽 방향으로 가지를 타고 이동하였을 때 접하는 노드를 $y$의 조상$ancestor$라고 부릅니다
            - $y$에서 아래쪽 방향으로만 가지를 타고 이동하였을 때 연결되어 있는 노드를 $y$의 자손$descendant$라 부릅니다
            - $y$와 $y$의 자손으로 구성된 트리를 서브트리$subtree$라 부른다
            
    - 레벨 $level$
        - 어떤 노드 $y$가 루트를 향하여 위쪽 방향으로 가지를 타고 이동하였을 때 몇번만에 도착하였는지를 측정한 값
    - 높이 $height$
        - 리프에서 루트까지의 레벨
    - 빈 트리 $null\,\,tree$
        - 노드와 가지가 전혀 없는 트리를 빈 트리라고 부른다
    - 순서 트리$ordered\,\,tree$와 무순서 트리$unordered\,\,tree$
        - 형제 노드의 순서관계를 구별하면 순서트리, 순서를 구별하지 않으면 무순서 트리라고 부른다


### 1-1. 순서트리의 검색방법

- 너비 우선 검색 $breadth-first\,\,search$
    - 같은 레벨 층의 왼쪽에서 부터 오른쪽으로 검색하고, 한층의 검색이 완료 되면 다음 레벨로 내려가는 방식의 탐색방법입니다.
- 깊이 우선 검색 $depth-first\,\,search$
    - 루트에서 리프까지 가고, 리프에 도달하여 더 이상 검색할 것이 없으면 부모노드로 가고, 그 뒤 다시 자식 노드로 내려가기를 반복하는 탐색방법입니다.
    - 어떤 노드의 방문을 우선시 하냐로 종류를 구분한다
    - 순회 방식
        - 전위 순회$preorder$
            - 노드 방문→ 왼쪽 자식→ 오른쪽 자식
        - 중위 순회 $inorder$
            - 왼쪽 자식→ 노드 방문 → 오른쪽 자식
        - 후위 순회 $postorder$
            - 왼쪽 자식→ 오른쪽 자식→ 노드 방문
        

#### 이진 트리$binary\,\,tree$란 무엇인가?

- 노드의 자식이 2개 이하이면 이진트리라고 정의한다
- 나아가 자식이 $n$개 이하이면 $n$진 트리라고 부른다
- 왼쪽 자식과 오른쪽 자식을 구분한다
- 완전이진트리 $complete\,\,binary\,\,tree$
    - 마지막 레벨을 제외하고 모든 레벨에 노드가 가득차 있는 트리를 완전이진트리라고 부른다.
    - 마지막 레벨에 한해선 왼쪽부터 오른쪽으로 노드를 채우되 반드시 끝까지 채우지 않아도 정의에 부합한다

#### 2-2. 이진 검색 트리$binary\,\,search\,\,tree$란 무엇인가?

- 어떤 노드 $y$가 있다고 할때 다음의 두 조건을 만족 시키는 트리를 이진검색트리라고 부릅니다
    - $y$의 왼쪽 서브트리의 키값이 $y$의 키값보다 작아야 한다
    - $y$의 오른쪽 서브트리의 키값이 $y$의 키값보다 커야 한다
- 이진 검색 트리를 중위 순회-깊이 우선 검색하면 노드의 키값을 오름차순으로 얻을 수 있습니다