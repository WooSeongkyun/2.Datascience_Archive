## Statistics
- Central Limit Theorem 이 무엇인가
	- 동일한 확률분포를 가진 독립확률변수 n개에 대하여 평균을 낸 값을 $\bar{x}$라고 하면,$\bar{x}$의 분포는 n이 커지면 커질수록 정규분포의 모양에 가까워 진다는 정리입니다.
- Central Limit Theorem 을 어디에 활용할 수 있는가?
	- 모집단이 어떤 분포 모양과 상관없이, 표본의 크기만 충분하다면 특정 표본평균을 가질 확률을 계산할 수 있다는 의미입니다
- 큰수의 법칙이란?
	- 표본집단의 크기가 커질수록 표본평균이 모평균에 가까워진다는 정리입니다
- 확률과 통계의 차이점은 무엇인가?
	- 확률은 어떤 사건이 일어날 수 있는 수학적 기대치를 계산한 것이고, 통계는 과거의 측정자료를 활용하여 미래에 일어날 일을 예측하는 것이 확률입니다
- Marginal Distribution은 무엇인가?
	-  다변량분포의 경우, 일부 독립변수에만 의존하도록 이산확률변수인 경우summation을, 연속확률변수인 경우 적분을 하여 만든 결과값
- Conditional Distribution은 무엇인가?

	 - $f(X_2=x_2|X_1=x_1)=\cfrac{f(x_1,x_2)}{f(x_1)}$으로, 변수 $X_1=x_1$ 일때 $X_2=x_2$ 일 확률을 의미한다
- Bias, Variance는 무엇인가
	- $Bias=[E(\hat{f}(x))-f(x)]^2$ 로 예측값의 평균이 실제값과 얼마나 차이가 나는지를 측정하는 척도입니다
	- $Var=E[(X-E(X))^2]$ 으로 예측값이 예측값의 평균과 얼마나 차이나는지를 측정하는 척도입니다
- Biased , Unbiased Estimation의 차이는 무엇인가
	- 추정량 Estimate: 모수를 추정하기 위해 표본의 측정값을 활용하여 계산된 값
	- Biased Estimation: 추정량의 기대값이 모수와 같지 않는 추정량
	 - 예: 표본분산의 평균은 $E(s^2)=\cfrac{n-1}{n}\sigma^2$ 이다
  - Unbiased Estimation: 추정량의 기대값이 모수와 같은 추정량
	- 예: 표본 평균의 평균은 모집단의 평균과 같다. 표본평균의 분포는 중심극한정리에 따라 모평균을 평균으로 하는 정규분포의 모습을 따른다
- Sample Variance 란 무엇인가?
	-  관측값에서 모평균을 빼고 제곱한 값을 모두 더한 뒤 전체 데이터수 n-1을 한 값이다.
- Variance를 계산할 때 N 대신 N-1로 나누는 이유는?
	- 표본 분산을 불편추정량으로 만들기 위해서 입니다. ($E(s^2)=\sigma^2$
- Gauss Distribution에서 MLE와 Sample Variance 중 어떤것을 활용해야 하는가
	- 최대 우도법 Mean Likelihood Estimation : 파라미터 $\theta=(\theta_1,\theta_2,...,\theta_n)$ 으로 구성된 어떤 확률밀도함수 $P(x|\theta) $에서 관측된 표본집합 $(x_1,x_2,...,x_n)$을 활용하여 파라미터를 추정하는 방법
	- 수치적으로 가능도를 우도를 측정하기 위해서 각 샘플이 추출될 확률(확률분포상 샘플이 뽑힐 확률)을 곱합니다.(각 데이터의 추출은 독립적으로 연달아 일어나는 사건으로 가정하기 때문이다)
    - ![](https://raw.githubusercontent.com/angeloyeo/angeloyeo.github.io/master/pics/2020-07-17-MLE/pic1.png)
      예시: 측정값들은 어느 곳에서 추출되었을 가능성이 높아 보이는가?
    - 이를 수학적으로 표현하면 표본집합의 결합확률밀도함수라고 하며 다음과 같은 수식으로 정의할 수 있다. $P(x|\theta)=\prod_{k=1}^{n}P(x_k|\theta)$
    - $P(x|\theta)$가 가장 커지는 $\theta$를 추정값 $\hat{\theta}$로 보는 것이 타당하다
    - 이때 $L(\theta|X)=log(P(x|\theta))  $를 로그-최대우도함수라고 하며, 이를 최대화하는 $\theta $값을 찾는 방식, $\cfrac{\partial{}}{\partial{\theta}}L(\theta|x)$를 계산한다

---

- Binomial, Bernouli, Multinomial, Multinouli란 무엇인가?
	- 베르누이 시행 Bernouli trial: 결과가 성공 또는 실패로 두개로만 존재하는 실험이나 시행
	- 이항분포 Binomial Distribution: 성공할 확률이 p 인 베르누이 시행을 n번 반복하였을 때 성공한 횟수가 x라고 한다면, 이에 대응되는 확률의 분포를 이항분포라고 정의한다
	- 다항 분포 multinomial Distrubition: 이항분포의 일반화된 형태로, 여러개의 값을 가질 수 있는 독립확률변수들에 대한 확률분포
- Beta 함수란 무엇인가?
	- $B(\alpha,\beta)=\displaystyle\int_{0}^{1}x^{\alpha-1}(1-x)^{\beta-1}dx =\cfrac{\Gamma(\alpha)\Gamma(\beta)}{\Gamma(\alpha+\beta)}$
	- 두 매개변수 $\alpha,\beta $에 의해 결정되고, $[0,1]$의 정의역을 갖고 있는 연속확률분포
	- factorial의 일반화된 형태인 감마함수와 특별한 관계식을 갖고 있다
- Beta distribution란 무엇인가?
	- $f(x;\alpha,\beta)=\cfrac{\Gamma(\alpha+\beta)}{\Gamma(\alpha)\Gamma(\beta)}x^{\alpha-1}(1-x)^{\beta-1}$로 정의된다
	- $E(X)=\cfrac{\alpha}{\alpha+\beta}\,\,,Var(X)=\cfrac{\alpha\beta}{(\alpha+\beta)^2(\alpha+\beta+1)}$의 성질을 갖는다
- Dirichlet Distribution이란 무엇인가?	
	- 베타분포의 일반화된 정의이자, 다항 분포에 대한 사전 켤레 확률이다.
	- $x_1,x_2,..,x_k $는 모두 양의 실수이며 $\sum_{i=1}^{k}x_i=1$의 값을 갖는다고 하자. $\alpha=(\alpha_1,\alpha_2,...,\alpha_k)$라고 하자., $B(\alpha)= \cfrac{\prod_{i=1}^{k}\Gamma(\alpha_i)}{\Gamma(\sum_{i=1}^{k}\alpha_i)}$로 정규화 상수라 하자
	- $f(x_1;\alpha_1,\alpha_2,...,\alpha_k)=\cfrac{1}{B(\alpha)}\prod_{i=1}^{k}x_i^{\alpha_i-1}$ 이다
- Gamma function은 무엇인가?
	- $\Gamma(\alpha)=\displaystyle\int_{0}^{\infty}x^{\alpha-1}e^{-x}dx=(\alpha-1)!\,\, if(\alpha\in \textbf{Z})$
- Gamma Distribution란 어디에 쓰이는가?
	- $\alpha,\beta$ 두 파라미터에 의해 결정되는 분포로, $\alpha$는 형태모수 shape paramter, $\beta$는 척도모수 scale parameter라고 부릅니다
	- $f(x;\alpha,\beta)=\cfrac{1}{\beta^{\alpha}\Gamma(\alpha)}x^{\alpha-1}\cdot exp(-x/\beta)$
	- 어떤 사건이 $\alpha$ 번 발생하는데 까지 걸리는 시간을 표현하는데 주로 쓰입니다
	- $E(X)=\alpha\beta ,\,\,Var(x)=\alpha\beta^2$ 의 성질을 갖습니다
- Poisson distribtion은 어디에 쓰이는가?
	- $f(x;\lambda)=\cfrac{\lambda^xe^{-\lambda}}{x!}$
	- 단위시간 발생된 사건의 횟수를 표현하는데 주로 쓰입니다
- Bias and Variance Trade-off는 무엇인가?
	- 편향은 학습 알고리즘에서 잘못된 가정을 하였을 때 발생하는 오차이고, 분산은 트래이닝 셋에 내재된 fluctuation에 의해 발생되는 오차이다. 모델이 단순한 형태라면 과적합이 발생하지 않지만, 과소적합 문제가 발생하는데 이 경우 높은 편향과 낮은 분산을 갖게 되고, 모델이 복잡한 형태라면 과적합이 발생하지만, 과소적합 문제를 줄일 수 있다. 이 경우 낮은 편향과 높은 분산값을 갖게 될 것이다.
- Congugate Prior란?
	- $P(\theta|x)=P(x|\theta)P(\theta)$ 의 관계식에서 각각을 Posterior, Likelihood, Prior라고 부르고, $P(\theta|x),p(x|\theta)$ 쌍을 cojugate prior라고 부른다

---

### 가설 검정 Hypothesis Test

- 귀무가설 Null Hypotesis $H_0$, 대립가설$H_a$
	- 기존의 주장이 틀렸음을 검증하기 위해 세우는 가설들로, 기존의 주장을 귀무가설$H_0$, 귀무가설에 반대되는 주장을 대립가설$H_a$이라고 부른다
	- 모수가 Confidence Interval에 포함될 것이란 주장을 귀무가설 Null
- Confidence Interval 신뢰 구간, Confidence Level/Significance Probability 유의 수준/유의 확률
	- 1종 오류(귀무가설을 기각했지만 실제론 귀무가설이 맞는 경우)가 발생할 확률과 1종 오류가 발생되는 영역의 여집합을 각각 유의 수준$\alpha$ 과 신뢰구간이라고 부른다
	- 모수가 해당 범위내에 존재할 확률을 각각 신뢰구간, 1-유의 수준 $\alpha$ 으로 볼 수 있다
- 채택역 Acceptance Region, 기각역 Reject Region/Critical Region
	- Confidence Interval 영역안을 수용역 Acceptance Region, Confidence Interval의 영역 밖을 기각역Reject Regon/Critical Region이라 부른다.
	- 측정값이 수용역에 있으면 귀무가설을 채택하고, 기각역에 있으면 대안가설을 대립가설을 채택한다
- 임계값 Critical Value
	- Confidence Interval의 경계가 되는 값을 임계값 Critical Value라고 한다
- 단측검정One-Sided Test, 양측검정 Two-Sided Test
	- 이때 한방향으로 검측하는 검정을 단측검정 One-Sided Test, 양방향으로 검정하는 것을 양측검정 Two-Sided Test라고 한다
- 1종 오류와 2종 오류	
	- 1종 오류: 귀무가설을 기각했지만, 실제론 귀무가설이 맞는 경우
	- 2종 오류: 귀무가설을 채택했지만, 실제론 귀무가설이 아닐 경우
- Covariance와 Correlation이란 무엇인가?
	- Covariance와 Correlation Coefficient 모두 2개의 확률변수에 대하여 선형관계를 측정하는 척도입니다. 상관계수는 공분산을 -1~1의 단위가 없는 값으로 정규화 시킨 값입니다.
	- $Cov(X,Y)=E[(X-E[X])(Y-E(Y)]$
- Coefficient of Determination이란 무엇인가?
	- 종속변수의 분산중 독립변수의 설명되는 비율을 측정한 지표입니다.
	- 해당 통계모델이 대상을 얼마나 잘 설명할 수 있는가를 측정한 지표입니다
	- SST(Sum of Squared Total): $SST=\sum_{i=1}^{n}(y_i-\bar{y})^2$
	- SSR(Sum of Squared Residual): $SSR=\sum_{i=1}^{n}(y_i-\hat{y}_i)^2$
	- $R^2=1-\cfrac{SSR}{SST}$
- P-value란 무엇인가?
	- 해당 통계량을 기준으로 귀무가설을 기각하였을 때, 1종 오류를 범할 확률입니다

---

- Likelihood-ratio test란 무엇인가
	- parameter 수가 다른 모델을 세울 때 어떤 paramter 수를 갖고 있는 모델이 더 높은 우도를 갖고 있는가 비교하는 방법입니다
	- $l_0=L(x_1,x_2,...,x_n|\theta)$
- Explained variance란 무엇인가?
- Unexplained variation이란 무엇인가?
- Total Variance Distance란 무엇인가?

---

## Machine Learning

- Linear Regression이란 무엇인가?
	- 종속변수와 1개 이상의 독립변수의 관계를 affine 변환으로 가정하여, 해당 데이터에 가장 설득력있는 모델을 찾는 방법론입니다.
- Frequentist와 Bayesian의 차이점은 무엇인가?=
	- 확률을 장기적으로 일어나는 사건의 빈도로 볼 것인가 사건 발생에 대한 믿음 또는 척도 등의 주관적인 요소로 볼것인가에 따라 빈도주의와 베이지안 학파로 분류됩니다
  - 빈도주의
	- 얼마나 빈번하게 특정한 사건이 반복되는가를 관찰하여 가설을 세우고 모델을 만듭니다. 모수는 우리가 모르는 고정된 상수로 바라봅니다
	- 사건이 독립적이고, 반복적이며, 정규분포의 형태일 경우 사용하기 좋습니다
	- 계산이 비교적 복잡하지 않기 때문에 쉽게 처리할 수 있습니다.
	- 다만 사전에 관찰지식이 없는 경우 실험 결과의 신뢰가 떨어질 수 있습니다
  - 베이지안
	- 베이지안 학파는 고정된 데이터의 관점에서 파라미터에 대한 신념의 변화를 분석합니다
	- 모수는 확률적으로 변하는 수로 가정합니다
	- 베이지안은 수학적으로 어렵고, 계산량이 많지만 현대에 들어 컴퓨터 연산능력의 향상과, 알고리즘 개발로 점차 활용되고 있습니다
	- 확률 모델이 명확히 설정되어 있다면 조건부로 가설을 검증하기 때문에 가설의 타당성이 높습니다
	- 다만 사전지식 모델링에 따른 사후 확률결과가 크게 다를 수 있습니다
- 차원의 저주는 무엇인가?	
	* 데이터 공간의 차원이 커질수록, 가능한 벡터 경우의 수가 기하급수적으로 늘어나고, 그에 따라 학습에 필요한 데이터의 수도 기하급수적으로 증가합니다. 데이터 갯수가 유한하다면 데이터 공간속 학습 데이터는 점점 희박하게 분포되므로, 학습에 어려움을 발생시킵니다
- Train, Test, Validate 로 나누는 이유는 무엇인가?
	- Train Set과 Test Set은 각각 모델을 학습시키고, 모델의 성능평가를 위해 데이터를 분리한 것입니다. validation Set은 모델이 Test Set에만 좋은 성능을 갖지 않도록, 모델 평가에 사용되는 다른 데이터셋입니다
- Cross Validation이란 무엇인가?
	- 데이터셋을 k등분하여 각 j($1\le j\le k)$회 번쨰의 학습에서 j번째 fold를 validation set, 나머지를 training set으로 활용하여 학습시키는 방식이다
	- 이렇게 학습시키면 모든 데이터셋을 훈련 및 평가에 활용할 수 있다
	- 데이터 부족으로 인한 언더피팅을 방지하고, 평가에 활용되는 데이터 편중을 막을 수 있다
	- 단 iteration 횟수가 많아지기 때문에, 모델 훈련과 평가 시간이 오래 걸리게 된다
- Supervised Learning이란 무엇인가?
	- 정답(레이블이) 존재하는 데이터를 활용하여 모델을 학습시키는 방법론입니다.
	- 레이블이 존재하기 때문에 모델이 예측한 값이 맞았는지 틀렸는지 평가할 수 있습니다
	- 분류Classification,회귀Regression 등이 대표적으로 존재합니다
- Unsupervised Learning이란 무엇인가?
	- 정답(레이블)이 존재하지 않는 데이터를 활용하여 모델이 데이터 내에 존재하는 패턴과 상관관계를 찾게 하는 방법론입니다
	- 해당 데이터에 대한 사전지식이 없는, 데이터의 숨겨진 특징이나 구조들을 파악하기 위하여 활용됩니다.
	- 군집화, 패턴 인식등의 방법이 있습니다. 해당 알고리즘으로는 K-Means, DBSCAN과 Mean-Shift, PCA 등이 존재합니다
- Semi-supervised Learning이란 무엇인가?

---

- Decision Theory란 무엇인가?
	- 수학적, 통계학적으로 불확실한 가운데 어떤 문제에 대한 가장 합리적인 결정을 내리는 방법들을 탐구하는 이론입니다.
- Receiver Operating characteristic Curve란 무엇인가?
	- $ROC=\cfrac{\cfrac{TP}{TP+FN}}{\cfrac{FP}{TN+FP}}$
	- 참으로 예측한 것 중에서 진짜 참인 것의 비율을, 거짓으로 예측한 것 중에서 잘못 거짓이라 예측한 비율로 나눈다
- Precisin Recall 이 무엇인가?
	- Precision는 참으로 예측한 것중 실제 참인것의 비율을 ,Recall은 실제 참인 사건중 참으로 예측한 것의 비율을 의미합니다. 
	- Precision은 참으로 예측하는 것을 보수적으로 취할 때, Recall은 되도록이면 참으로 예측하는 전략을 취할때 높아지는 경향이 있습니다. 따라서 대부분의 경우 Precision과 Recall은 서로 Trade-off하는 관계에 있습니다
	- Precision는 음성인 것을 양성으로 예측하였을 때 리스크가 큰 경우, Recall은 양성인 것을 음성으로 예측하였을 때 리스크가 큰 경우 사용하는 것이 좋습니다. 
	- 예를 들면 어떤 주식을 샀을때 투자에 성공할까를 예측하는 것은 precision을 우선시여겨야 한다고 볼 수 있습니다. 반대로 암환자를 진단하는 의사의 경우 암환자를 정상이라 판별하는 경우 큰 문제가 발생할 수 있으므로, 되도록이면 작은 징후조차 놓치지 않고 recall을 높이는 것을 우선시여겨야 한다고 볼 수 있습니다
	- ![](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Ft1.daumcdn.net%2Fcfile%2Ftistory%2F999D9C465BE116E43C)
		- 해당 벤 다이어그램에선 A를 실제로 날씨가 맑은 날, B를 모델에서 날씨가 맑은 날로 예측하는 것으로 볼 수 있습니다. 그러면 a:FN, b:TP, c:FT, d를 TN으로 볼 수 있습니다
		- $precision=\cfrac{TP}{TP+FP}$
		- $recall=\cfrac{TP}{TP+FN}$
- Precision Recall Curve란 무엇인가?
	- Precision과 Recall 모두 중요한 지표이면서, 서로 trade-off의 관계가 있으므로, Precision과 Recall을 표현하는 2차원 좌표계로 시각화하여, 적절한 Precision,Recall value값을 선택하는 데 활용됩니다
- Type 1 에러와 Type 2 에러는 무엇인가?
	- Type1 error는 False Positive Error로, Positve로 예측하였지만 실제론 Negative 인 경우를 의미하고, Type2 error는 False Negative Error로, Negative로 예측하였지만 실제론 Positve인 경우의 에러를 의미합니다.
	
---

- Entropy는 무엇인가?
	- 새넌 엔트로피는 각 메세지에 포함된 정보량을 측정하는 척도입니다
	- 예를 들어 새넌 엔트로피는 밑이 2이고, 진수가 총 사건에서 발생할 수 있는 경우의 수인 로그로 정의하는데 동전을 N번 던져 발생하는 경우의 수는 $\log_{2}{2^N}=N$으로 N새넌 값을 갖게 됩니다. 
	- $H(x)= - \displaystyle\sum_{i=1}^{n}{p(x_i)log_{2}(p(x_i))}$ 
- Cross Entropy란 무엇인가?
	- 실제 분포 p를 모르는 상태에서 모델링하여 얻은 분포인  q를 통하여 p를 예측하였을 때, 실제값과 예측값의 차이를 계산하는데 활용합니다
	- Entropy의 차이가 실제값과 예측값이 거의 맞는 경우 0에 수렴하고, 값이 틀릴 경우 KL-Divergence만큼 크도록 정의되었습니다
	- $H(p,q)=-\displaystyle\sum_{i=1}^{N}{p_{i}log({q_i})}$
	- $H(X)=-\mathbb{E}[\log_{2}{p(x)}]$
- Mutual Information이란 무엇인가?
	- 하나의 확률 변수가 다른 하나의 확률 변수에 대해 제공하는 정보의 량을 측정하는 척도입니다. 즉 하나의 확률변수가 다른 확률변수에 얼마나 dependent한지를 평가하는 척도로 활용됩니다.
	- $\mathbb{I}(x,y)\sim{KL(p(x,y)||P_{X}\otimes{P_{Y}})}$로 정의됩니다
- KL-Divergence란 무엇인가?
	- 두 확률분포의 차이를 계산하기 위해 사용되는 척도입니다.
	- $KL(P||Q)=H(p,q)-H(p)=\displaystyle\sum_{i}{P(i)log}{\cfrac{p(i)}{q(i)}}$
---

- Discriminative Model과 Generative Model은 무엇인가?
	- 판별모델 Discriminative Model은 데이터가 주어졌을 때, 특정 레이블에 속할 확률을 반환하는 알고리즘입니다
	- 생성 모델 Generative Model은 우도likelihood나 사후 확률 posterior probability를 활용하여, 분류 경계선을 만드는 방법입니다. 
- Discrinator function이란 무엇인가?

---

- Overfitting
- Underfitting이란?
- Overfitting과 Underfitting은 무슨 문제가 있는가?
- 이를 해결하는 방법은?
  **- Regularization이란?**
  - **Ridge 규제**
  - **Lasso 규제**

---

- Activation Function이란 무엇인가?
- **CNN은** **무엇인가?**
- **RNN는 무엇인가?**
- **GRU란 무엇인가?**
- Newton's Method는 무엇인가?
- Gradient Descent란 무엇인가?
- Stochastic Gradient Descent란 무엇인가?
- Local optimum으로 바찔때 성능이 좋은 이유는 무엇인가?
- Internal Covariance Shift란 무엇인가?
- Batch Normalization은 무엇이고 왜하는가?
- Backpropagation이란 무엇인가?
- Optimizer의 종류와 차이에 대해 아는가?

---

- Ensemble이란?
- Stacking Ensemble이란?
- Bagging이란?
- Bootstrapping이란?
- Boosting이란?
- AdaBoost, Logit Boost, Gradient Boost란?
- Support Vector Machine 이란 무엇인가?
- Margin을 최대화 하면 어떤 장점이 있는가?

---

- AI와 ML, DL의 차이는?
- Precision Recall, F1는 무엇이고 왜 쓰는가?
- MLE 와 MAP의 가장 큰 차이점은?
- 베이즈 정리란?
- Convolution Layer란?

---

## Linear Algebra

- Linearly independent란?
	- 하나의 벡터가 남은 벡터들의 선형결합으로 표현되지 않는 벡터들만 모인 집합입니다
- Basis와 Dimension이란 무엇인가?
	- Basis: 선형독립집합 $\beta$ 의 $span(\beta)$가 어떤 벡터공간 $V$와 동일하다면, 선형독립집합$\beta$를 $V$의 기저라고 정의합니다. 그리고 기저 $\beta$ 의 원소의 갯수를 $V$의 차원이라 정의합니다
- Null space란 무엇인가?
	- 선형변환 $T$ : ($V \rightarrow W$)V to W가 있을 때, $T(x)$ 가 영벡터가 되는 벡터공간$V$의 원소 $x$를 모은 집합을 Null Space라고 정의합니다
- Symmetric Matrix란?
	- 어떤 행렬 $A$가 있을 때, $A_{ij}=A_{ji}$인 행렬을 대칭행렬이라고 부릅니다
	- 유한차원 복소내적공간에선 선형연산자 $T$가 normal operator라면, 유한차원 실수내적공간에선 선형연산자 $T$가 self-adjoint라면 대각화가 가능합니다. 실수내적공간의 선형연산자가 self-adjoint라면, 행렬로 표현하였을 때 대칭행렬이므로, 대칭행렬은 항상 대각화가 가능하다는 특성을 가지고 있습니다
- Positive-Definite란?
	- 어떤 선형연산자 $T$가 있을 때, 모든 $x\ne0$에 대하여 $\langle T(x)|x\rangle > 0$ 이면 $T$를 Positive-Definite라 부릅니다
	- 이때 Positive-Definite 이기 위한 필요충분조건은 모든 고유값이 양수인 것입니다
	- 이때 임의의 선형연산자 $T$에 대하여 $TT^*$는 Positive-Definite이므로, $TT^*$의 고유값은 모두 양수인데, 이는 Singular Value Theorem 정리에 활용됩니다
- Rank란?
	- 선형연산자 $T:V \to W$가 있을때, $T(V)$를 $T$의 range라고 하며, $dim(T(V))$를 $T$의 랭크라고 정의합니다
- Determinant가 의미하는 바는 무엇인가?
	- 행렬의 가역성을 판단하는데 활용할 수 있는 함수로, 행렬식이 0이라면 이에 대응되는 선형변환은 비가역적입니다. 반대로 행렬식이 0이 아니라면, 이에 해당되는 선형변환은 가역적입니다
- Eigenvector는 무엇인가?
	- 선형연산자 $T:V\to W$가 있을 때 $T(v_j)=\lambda_jv_j$ 인 $v_j\in V$ 를 고유벡터라고 정의합니다
- Eigenvector는 왜 중요한가?
	- 행렬의 값을 근사하거나 차원을 축소하는데 활용되는 특이값정리의기반이 되기 때문입니다
- Eigenvector는 왜 중요한가?/SVD란 무엇인가? 왜 중요한가? /PCA란 무엇인가?
	- 임의의 한 행렬을 3개의 특별한 행렬의 곱(유니타리\*시그마\* 유니타리)으로 표현할수 있다는 정리입니다
	- 행렬의 값을 근사하거나 차원을 축소하는데 활용되는 PCA의 기반이 되기 때문입니다
	- 특이값 분해후 크기순으로 특이값 전체중 일부반 취한 $\Sigma^\prime$을 활용하여 차원을 축소하는 것을 PCA라고 한다
- Jacobian Matrix란 무엇인가
	- 직교좌표계에서 다른 좌표계로 변환하여 다중적분할 때 곱해지는

---

## Computerscience










