# 3장 파이썬을 이용한 데이터분석 3: 분포/추정/가설검정

## 6.정규분포 $normal\,\,distribution$

 $N(x \mid\mu,\sigma^2)\equiv\cfrac{1}{\sqrt{2\pi\sigma^2}}exp(-\cfrac{(x-\mu)^2}{2\sigma^2})$

### 1.정규분포 성질 살펴보기

```python
# loc: 평균, scale: 표준편차, x: 확률변수
stats.norm.pdf(loc=4,scale=0.8,x=3) 
# 정규분포 인스턴스를 생성해서 pdf함수를 출력해보기
norm_dist= stats.norm(loc=4 ,scale=0.8)
norm_dist.pdf(x=3)

result)
0.2283113567362774
```

```python
#평균이 4이고 표준편차가 0.8인 정규분포에서 샘플사이즈가 100000개로 샘플링 했을 때 
#3이하의 데이터 갯수는?
np.random.seed(1)
simulated_sample = stats.norm.rvs(loc=4,scale=0.8,size=100000)
simulated_sample
print( np.sum(simulated_sample<=3)/len(simulated_sample))
```

### 2.정규분포의 누적분포함수

$\Phi(x)\equiv \int_{-\infin}^{x} \cfrac{1}{\sqrt{2\pi\sigma^2}}exp(-\cfrac{(x-\mu)^2}{2\sigma^2})$

- 특정확률에 대응되는 누적분포의 확률변수 찾기

```python
#ppf: cdf함수의 역함수/ 특정 확률에 대응대는 누적분포의 확률변수 값을 알려줌 
stats.norm.ppf(loc=4, scale=0.8, q=0.025)

result)
2.4320288123679563
```

### 3.$t$값과 $t$분포

$t\equiv \cfrac{\bar{x}-\mu}{\sigma/ \sqrt{N}}$, $\sigma$는 $s$로 대체될 수 있다.

$t$분포 변환을 쓰는 이유

- 모표준편차$\sigma$를 모르는 상태에서 표본평균 분포를 추측하기 위해 사용한다.

$t$분포 특징

- 원점에 대해 좌우대칭이고 정규분포와 유사하나 꼬리쪽이 좀더 두터운 모양새이다.

자유도$degree\,\,of\,\,freedom$

- 통계적 추정을 할 때 표본자료중 모집단에 대한 정보를 주는 독립적인 자료의 수
- 샘플사이즈가 N일떄 N-1의 값을 갖는다

$var\,\,of \,\,t(n)=\cfrac{n}{n-2}$

```python
np.random.seed(1)
#표본의 개수 10000개/ 표본의 크기 10개
t_value_array = np.zeros(10000)
#정규분포 인스턴스
norm_dist = stats.norm(loc=4,scale=0.8)
#시뮬레이션 실행
for i in range (0,10000):
    sample= norm_dist.rvs(size=10)
    sample_mean = np.mean(sample)
    sample_std= np.std(sample,ddof=1)
    sample_se= sample_std/ np.sqrt(len(sample))
    t_value_array[i] = (sample_mean-4)/ sample_se

#t값 히스토그램 그리기
sns.distplot(t_value_array,color='gray')
#표준정규분포의 확률밀도
x=np.arange(-8,8.1,0.1)
plt.plot(x,stats.norm.pdf(x=x),color='black',linestyle='dotted')
```

![Untitled](1.%20수학%20아카이브/0.미완성_수학/파이썬과%20통계학/레퍼런스_3장%20파이썬을%20이용한%20데이터분석%203%20분포%20추정/Untitled.png)

- 표본평균의 평균은 모평균이므로 t 그래프의 중앙은 0에 위치한다

### 3.7 추정

### 1.점추정 $point\,\,estimation$

모수를 어느 1개의 값으로 추정하는 방법

- 모평균 추정: 표본평균을 점추정값으로 사용
- 모분산 추정: 표본분산을 점추정값으로 사용

```python
fish = pd.read_csv('sample/3-7-1-fish_length.csv')
#평균 점추정
mean_val= np.mean(fish)
#분산 점추정
s_square=np.var(fish,ddof=1)
print(mean_val)
print(s_square)

result)
length    4.187039
length    0.680302
```

### 2.신뢰구간 추정$confidence \,\,interval\,\,estimation$

모수값을 포함하리라고 예상되는 구간과 그 확률을 제시하는 추정 방법 

- 신뢰계수$confidence\,\,coefficient$: 예측한 신뢰구간내에 모수가 존재할 확률
- 신뢰구간 $confidene\,\,interval$:특정 신뢰계수 내에서 모수값을 포함하리라고 추정하는 구간
- 신뢰 한계$confidence\,\,limit$: 신뢰구간의 상한과 하한

### 3.신뢰구간 계산방법

- $t$분포의 퍼센트포인트를 사용한다. 신뢰계수를 95%로 한다고 하면 2.5% 지점과 97.5% 지점을 계산한다.
- 구간추정에 필요한 정보는 자유도:샘플사이즈-1/ 표본평균/표준오차 3가지를 요구한다.

```python
#자유도 구하기
dof= len(fish)-1
#표본 표준편차구하기
std_val=np.std(fish,ddof=1)
#표준오차 구하기
se=std_val/np.sqrt(len(fish))
#신뢰구간 구하기: alpha:신뢰계수, df:자유도, loc:표본평균, scale:표준오차
interval= stats.t.interval(alpha=0.95,df=dof,loc=mean_val,scale=se)
interval

result)
(array([3.597]), array([4.777]))
```

### 4.구간추정 결과의 해석

- 신뢰구간이 95%라는 것은  모집단분포에서 표본추출을 계속 반복했을 때 각각의 표본의 신뢰구간안에 모평균이 포함되어 있을 확률이 100개중 95개정도 될것이란 말이다

```python
included_array=np.zeros(20000,dtype='bool')
#95% 신뢰구간을 구하는 시행을 20000번 반복하자
#신뢰구간이 모평균(4)를 포함하면 True
np.random.seed(1)
norm_dist= stats.norm(loc=4,scale=0.8)
for i in range(0,20000):
    sample= norm_dist.rvs(size=10)
    df=len(sample)-1
    mean_val= np.mean(sample)
    std_val=np.std(sample,ddof=1)
    se=std_val/np.sqrt(len(sample))
    interval= stats.t.interval(0.95,df,mean_val,se)
    if(interval[0]<=4 and interval[1]>=4):
        included_array[i]=True

#신뢰구간안에 모평균이 포함된 비율
sum(included_array)/len(included_array)

result)
0.948
```

## 8.통계적 가설 검정$statistical\,\,hypothesis\,\,test$

모수 또는 모집단의 분포에 대해 가설을 세우고, 표본 정보를 활용하여 가설의 합당성 여부를 판단하는 방법

- 귀무가설$null\,\,hypothesis$ $H_0$: 가설이 잘못되었단 증거가 발견되었다기 전까진 참으로 받아들이는 모수의 수치에 대한 주장/ 현재의 통념일 경우가 많다
- 대립가설$alternative\,\,hypothesis$ $H_a$:귀무가설을 기각된다면  참으로 받아들이는 가설
- $p$값:  귀무가설이 맞다는 전제하에 해당 관측치가 나올 확률
- 단측검정$one-side\,\,test$: 예측한 모수의 수치가 특정 값 이상 일때/ 특정값 이하 일 때인 둘중 한 경우에만 기각하는 검정
- 양측 검정$two-side \,\,test$: 예측한 모수의 수치가 특정 값 이상 또는 특정 값 이하일 때 기각하는 검정

- 통계적 유의미$statistical\,\,significance$
    
    어떤 실험결과가 단순히 우연한 결과로 나오기엔 어려운 확률을 가지고 있다(= 귀무가설을 기각한다)
    
    - 표준 편차가 작다: 측정기기의 성능이 정밀하다
    - 샘플사이즈가 크다: 표준오차(표본평균의 표준편차 값이 작다)
    - 평균 값의 차이가 크다

```python
junk_food=pd.read_csv('sample/3-8-1-junk-food-weight.csv')
junk_food.head()
#귀무가설: 봉지과자 평균 중량은 50g이다/ 대립가설: 봉지과자 평균중량은 50g이 아니다
# 유의수준: 5%
#t값 구하기: 표본평균과 표본오차 구하기
#표본오차 구하기: 표본표준편차과 샘플사이즈 구하기
mean_val= np.mean(junk_food)
dof_val=len(junk_food)-1
std_val=np.std(junk_food,ddof=1)
se= std_val/np.sqrt(len(junk_food))
t_val=(mean_val-50)/se
t_val

#alpha:  t_표본 이하 구간의 확률
#양측검정하기
alpha= stats.t.cdf(t_val,df=dof_val)
(1-alpha)*2

#이 식으로도 측정가능
stats.ttest_1samp(junk_food,50)

result)
0.013
:귀무가설이 맞다는 전제하에 이러한 관측치가 나올 확률은 1.3%이다.  p값이 
유의수준 이하이므르 귀무가설을 기각한다 
```

### 시뮬레이션으로 p값 검증

```python
size=len(junk_food)
std_val=np.std(junk_food,ddof=1)
t_val_array=np.zeros(50000)
np.random.seed(1)
norm_dist=stats.norm(loc=50,scale=std_val )
for i in range(0,50000):
    sample = norm_dist.rvs(size=size)
    sample_mean =np.mean(sample)
    sample_std = np.std(sample,ddof=1)
    sample_se= sample_std/ np.sqrt(size)
    t_val_array[i] = (sample_mean-50)/sample_se

    
print(t_val_array)
print(len(t_val_array))

#t_표본값을 넘어선 t의 갯수 비율 세기
countN=0
for i in range(0,50000):
    if t_val_array[i] > float(t_val):
        countN= countN+1
        
print(countN/50000 *2)
```

## 9. 평균값의 차이 검정

### 1. 2집단 사이의 $t$검정

```python
#두 집단 사이의 t검정
paired_test_data= pd.read_csv('sample/3-9-1-paired-t-test.csv')

#약물 조치로 그룹을 나누고 body_temperature 열 데이터값만 나타내도록 설정함
before= paired_test_data.query('medicine=="before"')['body_temperature']
after= paired_test_data.query('medicine=="after"')['body_temperature']

#배열형으로 변환시키기
before= np.array(before)
after=np.array(after)

#차이
diff= after-before
diff

#t테스트를 해주는 함수: 데이터값과 평균값을 input으로 한다
stats.ttest_1samp(diff,0)
#statistics= t값 / p-value를 제공하는 함수

result)
Ttest_1sampResult(statistic=2.901693483620596, pvalue=0.044043109730074276)
#p-value가 0.044 이므로 귀무가설을 기각한다:약이 유의미한 효과가 있다
```

### 2. 독립표본 $t$검정

$t=\cfrac{\bar{x}-\bar{y}}{\sqrt{{s_x^2}/m+{s_y^2/n}}}$

- 두 집단간 평균값의 차이를 비교하는 방법

```python
#평균값
mean_bef= np.mean(before)
mean_aft=np.mean(after)
#분산
var_bef=np.var(before,ddof=1)
var_aft=np.var(after,ddof=1)
#샘플사이즈
m=len(before)
n=len(after)
#t값
t_val= (mean_aft-mean_bef)/ np.sqrt(var_bef/m+var_aft/n)
print(t_val)

#독립표본 t검정 함수가 존재한다/ 걍 함수쓰자..
#equal_var=False 는 두 집단간의 비교를 할 때 분산이 같음을 가정하지 않는다는 것이다. 
#scipy에선 Welch 검정을 채택한다는 의미이다
#statistics: t값 
stats.ttest_ind(after,before,equal_var=False)

result)
Ttest_indResult(statistic=3.1557282344421034, pvalue=0.013484775682079892)
```

## 10.$\chi^2$검정

- 관측도수: 실제로 관측된 데이터 값
- 기대도수: 카테고리가 결과값에 영향이 없을 것이라고 가정했을 때의 예측한 데이터의 값

$\chi^2=\sum_{i}\sum_{j}\cfrac{(O_{ij}-E_{ij})^2}{E_{ij}}$, $O_{ij},E_{ij}$는 각각 관측도수, 기대도수

- 예시)
    - 버튼 클릭
    - A/B 테스트(변수 A와 B 둘중 하나씩을 적용한 서비스를 유저에게 제공하면서 그 반응을 살펴 어떤것이 더 효과적인지 파악하는 통계)를 할 때 호의적 반응 뿐만 아니라 호의적이지 않은 반응 까지 고려할 수 있다
    - 조사횟수가 적은지 많은지도 고려한다
    
    |  | 클릭함 | 클릭하지 않음 | 합계 |
    | --- | --- | --- | --- |
    | 파랑 | 20 | 230 | 250 |
    | 빨강 | 10 | 40 | 50 |
    | 합계 | 30 | 270 | 300 |
    - 기대도수 (클릭: 클릭하지 않음 비가 1:9 이므로)
    
    |  | 클릭 | 클릭하지 않음 |
    | --- | --- | --- |
    | 파랑 | 25 | 225 |
    | 빨강 | 5 | 45 |

```python
#일단 카이제곱값과 자유도를 구하고 나면 p값을 계산할 수 있다
1-sp.stats.chi2.cdf(x=6.667,df=1)
result)
0.009821437357809604
```

## 3.11 검정 결과 해석

- $p<0.05$ : A는 B와 유의미한 차이가 있다
- $p>0.05$: A는 B와 유의미한 차이가 있다고 말할 수 없다
- 검정의 비대칭성
    - 제 1종 오류: 귀무가설이 올바르지만 실수하여 귀무가설을 기각하는 경우
    - 제 2종 오류:귀무가설이 틀렸지만 실수하여 귀무가설을 채택하는 경우
    - 통계적 가설검정은 제 1종 오류를 범할 확률을 계산하여 $p$값으로 표현한다. 하지만 제 2종 오류가 일어날 확률을 계산하진 못한다