###  통계모델
- 모델의 정의
- 기초분포모델

## 1. 모델이란?

- 수학적 모델/ 수리모델 Mathematical Model
	- 수학적 개념과 언어를 활용하여 서술된 시스템(일정한 규칙에 따라 상호작용하는 요소들의 집합)이다
	- 수학적 모델의 분류 기준
		- 선형인가 비선형인가? 
			- 수학적 선형성 linearlity 를 따르는가로 구분
		- 정적인가 동적인가? 
			- 시스템의 상태가 시간에 따라 변화하는지 안하는지로 구분
		- 명시적인가 암묵적인가? 
			- 모델의 모든 입력 파라미터가 알려져있고, 출력 파라미터가 유한번의 계산을 통해 구해질 수 있는가? 없는가?
		- 연속적인가 비연속적인가?
		- 결정론적인가 확률론적인가?
			- 상태 변수가 이전 상태 변수에 의해 고유하게 결정되는가 아닌가? 
			- 만일 전자라면 초기조건이 동일하다면 그 후 과정은 항상 동일한 결과를 갖는다
		- 연역적인가 귀납적인가?
			- 귀납적 모델: 경험적 사실로부터 일반화된 법칙을 존재함을 주장하는 것
			- 연역적 모델: 주어진 사실을 논리적으로 전개하여 새로운 사실을 발견하는 것
	
- 확률 모델
	- 관측되는 데이터에 대응되는 발생확률을 수학모델로 제작한 것이다
	- $y=f(\mathbb{X})+\epsilon$ 으로 표현될 수 있다
		- $y$ 는 종속변수, $\mathbb{X}$ 는 독립변수, $\epsilon$ 는 오차항이다
		- 이때 $\epsilon$는 독립적이고 평균이 0인 무작위 오차항이다
		- $\hat{y}=\hat{f}(\mathbb{X})$ 로 $y$ 에 대한 추정모델 $\hat{f}$를 세울 수 있다
		- 이때 $y-\hat{y}=(f(\mathbb{X})-\hat{f}(\mathbb{X}))+\epsilon$ 에 대하여 전자($f(\mathbb{X})-\hat{f}(\mathbb{X}$))는 $\hat{f}(\mathbb{X})$의 정확도를 높여 줄일수 있는 부분이기에 reducible error라고 하며, 후자($\epsilon$)는 아무리 잘 추정하더라도 없앨수 없는 오류이기에 irreducible error라고 부른다

### 변수들

- 독립변수 independent varialbe (원인)
	- 다른 변수에 영향을 받지 않는 변수이면서 다른 변수에 영향을 주는 변수
	- 연구자가 의도적으로 변화시키는 변수
    
- 종속변수 dependent variable (결과)
	- 다른 변수에 영향을 받으면서 다른 변수에 영향을 미칠 수 없는 변수
	- 연구자의 관찰대상이 되는 변수
    
- 매개변수 parametric variable 
	- 다른 변수에 영향을 받을 수도 다른 변수에 영향을 줄 수 있는 변수
	- 독립변수와 종속변수 사이 간접적으로 영향을 준다
    
- 외재변수 extraneous variable
	- 종속변수에 영향을 미칠 수 있으나 연구에선 다루지 않는 변수
	- 외재변수로서의 작용을 금하기 위해 변수를 제거하거나, 외재변수를 동일한 상태로 유지하려 할 때 해당 변수를 통제변수 control variable이라 부른다

### 계수와 가중치

- 계수$coefficient$: 변수 앞에 곱해진 상수/ 머신러닝에선 주로 가중치$weight$란 이름으로 불린다

### 모델의 구축

- 모델의 특정: 모델의 구조를 수식으로 표현하기
    - 변수 선택하기
        - 통계적 가설검증 활용: 귀무가설을 세워 기각되는 경우에는 독립변수를 필요하다고 판단/ 기각되지 않는 경우에는 독립변수를 제거하여 모델을 단순화 시킨다
        - 정보 기준: AIC라는 것을 활용하여 모델에서 가능한 변수의 패턴을 총 망라하고 AIC가 가장 적은 모델을 선택한다
- 파라미터 추정하기
- 모델 평가

### 모델의 종류

- 파라메트릭/ 논파라메트릭
	- 파라메트릭 모델: 가능한 현상을 단순화 하여 소수의 파라미터만 사용하는 모델
		-  함수 형태에 대해 가정한다.
			- 가장 단순한 형태의 가정은 함수 $f$가 선형이란 것으로 다음과 같다
			- $Y\sim f(X)=\beta_o+\beta_1X_1+\beta_2X_2+...+\beta_pX_p$
		- $training\,\,data$를 활용하여 모델을 학습시킨다.
			- 선형모델의 경우 파라미터 $\beta_0,\beta_1,\beta_2,...,\beta_p$의 추정을 한다
			- 가장 일반적인 방법은 최소제곱법 $ordinary\,\,least\,\,square$ 이다
		- 장점과 단점
			- 함수의 종잡을수 형태를 추정하는 문제를 파라미터 $\beta_0,\beta_1,\beta_2,...,\beta_p$를 추정하는 문제로 난이도를 낮춘다
			- 대신 이 가정한 함수의 형태가 진짜 함수 $f$와 다를수록 추정결과는 나쁠 수 밖에 없다
				- ⇒ 이러한 문제를 극복하기 위해 좀 더 다양한 유연한$flexible$ 형태의 모델  을 가정한다
				- ⇒ 한편 유연한 형태의 모델을 만들기 위해선 더 많은 수의 파라미터를 요구한다. 파라미터가 많은 모델은 $overfitting$이라 불리는 문제현상을 야기할 수 있다
    
	- 논파라메트릭 모델: 소수의 파라미터를 사용한다는 방침을 취하지 않는 모델/ 복잡한 모델이 되기 쉬워 추정과 해석이 어려워질 수 있다
		-  함수 형태에 대해 어떤 가정도 하지 않는다
			- 대신 함수가 데이터포인트와 최대한 근접해 있으며, 지나치게 구불구불하거나 거칠지 않다고 가정한다
		- 장점과 단점
			- 좀 더 다양한 함수의 형태를 추정하는 데 좋은 방식이다
			- 적은 수의 파라미터로 추정하는 것이 아니기에 큰 수의 관측값 데이터가 필요하다
    
- 선형회귀모델linear regression model
	- $y_i=\displaystyle\sum_{j=1}x_{ij}\beta_j+\beta_{0}$ 로 정의된 수학적 모델
	- ( $x_{ij},\beta_j$는 각각 $i$번째 데이터의 $j$번째 성분의 값, $j$번째 계수를 의미한다.)
	- 종속변수에 대하여 계수는 선형변환 linear transformation의 관계를, 독립변수는 아핀 변환 affine transformation의 관계를 갖는다
	- 독립변수 $x_{ij}$를 1개 사용한 식을 단순회귀분석식 simple regression / 독립변수 $x_{ij}$를 2개 이상 사용한 식을 다중회귀분석식 multiple regression이라 한다

- 정규선형모델
	- 종속변수가 정규분포를 따르는 것을 가정한 선형모델
	- $y \sim{N(\displaystyle\sum_{j=1}x_{ij}\beta_j+\beta_{0},\sigma_{i}^2)}$
	- 모집단분포를 정규분포로 가정하는 것이 올바른가를 평가하는 것과 파라미터의 값을 추정하는 두 단계로 나뉜다
	- 분산분석: 독립변수가 카테고리형 변수인 정규선형모델
		- 독립변수가 1종류면 일원분산분석 / 독립변수가 2종류면 이원분산분석이라 한다
	    
- 일반선형모델 GLM: Generalized Linear Model
	- 종속변수가 정규분포 이외의 다른 분포까지 가능하다 전제하는 일반적인 선형모델


### 가능도함수 Likelihood Function
- 정의
	- 표본 $\mathbb{x}=\{x_{1},x_{2},...,x_{n}\}$에 대한 확률질량함수/확률밀도함수를 $f(\mathbb{x}|\theta)$ 라 하자. 이때 함수 $f$를 파라미터 $\theta=(\theta_{1},\theta_{2},...,\theta_m)$에 대한 함수로 다시 보자
	- $L(\theta|\mathbb{x})=f(\mathbb{x}|\theta)=\prod_{i=1}^{n}{f(x_{i}|\theta)}$ , $L$을 우도함수 likelihood function이라 정의한다
	- $L(\theta|\mathbb{x})=log(f(\mathbb{x}|\theta))$ 계산의 편의를 위해 이와같이 로그를 취하여 정의할 수도 있고 이를 log-likelihood function이라 부른다

- 최대우도추정 MLE: Maximum Likelihood Estimation
	- $L(\theta|\mathbb{x})$ 값을 최대로 하는 $\theta$를 $\hat{\theta}$라 할때, $\hat{\theta}$를 모수 $\theta$의 최대우도추정량이라 부른다
	- $\displaystyle\frac{\partial {}}{\partial {\theta}}L(\theta|x)=\displaystyle\frac{\partial {}}{\partial {\theta}}log(f(\mathbb{x}|\theta))=\displaystyle\sum_{i=1}^{n}{\displaystyle\frac{\partial {}}{\partial {\theta}}}f(x_{i}|\theta)=0$ 를 만족시키는 $\theta$를 찾는다
	- 예: 푸아송 분포의 최대우도 검정량
		- $f(x|\mu)=\displaystyle\frac{e^{-\mu}\mu^{x}}{x!}$이고 $\mathbb{x}=\{x_{1},x_{2},...,x_{n}\}$ 인 표본이 있다하자. 이때 이 푸아송 분포에 대하여 $\mu$의 최대우도추정량을 구하라
		- $L(\mu|\mathbb{x})=f(\mathbb{x}|\mu)=\prod_{i=1}^{n}{f(x_{i}|\mu)}=\prod_{i=1}^{n}{\displaystyle\frac{e^{-\mu}\mu^{x_{i}}}{x_{i}!}}$
		- $\log_{}{L(\mu|\mathbb{x})}=-n \mu+\displaystyle\sum_{i=1}^{n}{x_i}ln(\mu)+\mathbb{C}$
		- $\displaystyle\frac{\partial {}}{\partial {\mu}}\log_{}{L(\mu|\mathbb{x})}=-n+\displaystyle\frac{1}{\mu}\displaystyle\sum_{i=1}^{n}{x_i}=0$
		- $\hat{\mu}=\displaystyle\frac{1}{n}\displaystyle\sum_{i=1}^{n}{x_i}=\bar{x}$


## 2. 기초분포모델

### 1.정규분포
- $f(x)=\displaystyle\frac{1}{\sqrt{2\pi}\sigma}exp[-\displaystyle\frac{1}{2}(\displaystyle\frac{x-\mu}{\sigma})^2]$

### 2. 이항분포와 관련분포
- 베르누이 시행 Bernouli Trial
	- 결과가 성공 또는 실패 두 가지 경우만 존재하고, 각 시행마다 성공확률이 $p$로 동일한 시행
- 이항분포 Binomial Distribution
	- $P(x;n)=\displaystyle\binom{n}{x}p^x(1-p)^{n-x}$
	- 성공확률이 $p$ 일때,베르누이 시행을 $n$ 번하여,  $x$ 번 성공했음을 의미한다
- 다항분포 Multinomial Distribution
	- $P(x_1,x_2,...,x_k;n)=\displaystyle\frac{n!}{x_1!x_{2!\cdot}x_{k-1}!x_{k}!}p_{1}^{x_{1}}p_{2}^{x_{2}}\cdot p_{k-1}^{x_{k-1}}p_{k}^{x_{k}}$
	- 이때 $n=\displaystyle\sum_{i=1}^{k}{x_i}$ 이고 $1=\displaystyle\sum_{i=1}^{k}{p_i}$ 이다
	- 한번의 시행에서 $k$개 범주가 존재하는 시행이  이에 대응되는 고정된 성공확률 $p_{1},p_{2},...,p_{k}$일때, $n$번 시도하여 , 각 범주가   $x_{1},x_{2},...,x_{k}$ 번씩 성공했음을 의미한다


### 3. 푸아송 분포
- 푸아송 분포 Poisson Distribution
	- $P(x;\lambda)=\displaystyle\frac{\lambda^{x} e^{-\lambda}}{x!}$
	- $1=\displaystyle\sum_{x=0}^{\infty}{p(x)}$ 라는 성질을 갖는다. $\displaystyle\sum_{x=0}^{\infty}{\displaystyle\frac{\lambda^x}{x!}}=e^{\lambda}$이기 때문이다 
	- 정해진 시간 내에 어떤 사건이 일어날 횟수의 기댓값을 $\lambda$라고 할때, 그 사건이 $x$회 일어날 확률을 의미한다 
	-  성공확률 $p$값이 매우 작은 베르누이 시행을 고려하자. 이 경우 $p$를 다룰순 없지만, 정해진 시간내에 시행횟수 $n$을 높여, $np$는 특정 수로 기댓값을 갖는다고 하자. 푸아송 분포는 $n,p$ 대신 주어진 시간내의 성공횟수 $\lambda=np$ 를 다루는 것이다.
		- 증명
			- $\lim_{n\to\infty}{P(x;n)}=\lim_{n\to\infty}{\displaystyle\frac{n!}{x!(n-x)!}}{(\displaystyle\frac{\lambda}{n})^x}{(1-\displaystyle\frac{\lambda}{n})^{n-x}}$
			- $=\lim_{n\to \infty  }{\displaystyle\frac{n!}{n^x(n-x)!}}\displaystyle\frac{\lambda^x}{x!}(1-\displaystyle\frac{\lambda}{n})^n(1-\displaystyle\frac{\lambda}{n})^{-x}$
			- $=\lim_{n\to \infty }{\displaystyle\frac{n(n-1)(n-2)\cdots(n-x+1)}{n^x}}\displaystyle\frac{\lambda^x}{x!}e^{-\lambda}$
			- $=\displaystyle\frac{\lambda^x}{x!}e^{-\lambda}$
	- 특성
		- $x=\lambda$ 에서 1계도함수 값이 0이고, 2계도함수값이 음수므로 극값이 되는 것을 확인할 수 있다
		- 기댓값과 분산 모두 $\lambda$의 값을 갖는다

### 4. 베타,감마,카이제곱 분포

- 모수 $\alpha,\beta$에 따라 다양한 형태가 존재하기 때문에, 베이지안에서 사전확률분포을 가정할 때 주로 활용된다
- 베타함수와 감마함수
	- 베타함수
		- $B(\alpha,\beta)=\displaystyle\int_{0}^{1}{x^{\alpha-1}(1-x)^{\beta-1}dx}$
		- $=\displaystyle\frac{\Gamma(\alpha)\Gamma(\beta)}{\Gamma(\alpha+\beta)}$
	 - 감마함수
		 - $\Gamma(\alpha)=\displaystyle\int_{0}^{\infty }{x^{\alpha-1}e^{-x}}{dx}$
		 - $=(\alpha-1)\Gamma(\alpha-1)$
		 - $=(\alpha-1)!\,\,(if\,\, \alpha\in \mathbb{N})$
	- 이 함수들은 다양한 형태의 바리에이션이 존재한다. 자세한 설명은 Boas- Special Functions 파트를 참고하자
	
- 베타 분포
	- $f(x;\alpha,\beta)=\displaystyle\frac{\Gamma(\alpha+\beta)}{\Gamma(\alpha) \Gamma(\beta)}x^{\alpha-1}(1-x)^{\beta-1}$
	- 특성
		- $E(x)=\displaystyle\frac{\alpha}{\alpha+\beta}$
		- $Var(x)=\displaystyle\frac{\alpha \beta}{(\alpha+\beta)^{2}(\alpha+\beta+1)}$
		
- 감마분포
	- $f(x;\alpha,\beta)=\displaystyle\frac{\beta^{\alpha}}{\Gamma(\alpha)} x  ^{\alpha-1} e  ^{-\beta x}$
	- 이때 $\alpha,\beta$를 각각 shape parameter, rate parameter라고 부르고 때때론 $\theta=1/\beta$ scale parameter라는 이름으로 표기할 수 도 있다
	- 특성
		- $E(x)=\displaystyle\frac{\alpha}{\beta}$
		- $Var(x)=\displaystyle\frac{\alpha}{\beta^2}$




 