###  통계학의 기본  
- 통계학의 목적 및 분류
- 용어 정의 및 정리
	- 집합
	- 변수
	- 방법들
	- 통계량
	- 모수
	- 추측통계학에서의 3가지 추측
	- 추측통계학에서의 3가지 차이
	- 중심극한정리



## 1. 통계학의 목적
- 통계학이란?
	- 데이터를 잘 사용하는 방법을 알아내는 학문
- 통계학의 분류
	- 기술통계학 Descriptive Statistics: 데이터셋 전체의 특성을 정리 요약하기 위해 사용되는 통계학
	- 추측통계학 Inferential Statistics
		- 가지고 있지 않는 미지의 데이터unknown data를 추측할 목적으로 사용되는 통계학
		- 표본이란 일부 데이터를 활용하여, 모집단이란 전체 데이터를 추측한다



## 2. 통계학의 기본 용어

#### 집합
- 모집단 Population
	- 정보를 얻고자 하는 관심 대상의 데이터셋
- 표본 Sample $\mathcal{C}$
	- 현재 보유하고 있는 데이터셋으로 모집단의 부분집합
	- 샘플사이즈 Sample Size: 표본이 갖고 있는 데이터의 수 
- 공간 $space \,\, \mathcal{D}$
    - $\mathcal{D}=\{x:x =X(c), c\in \mathcal{C}\}$
    - $\mathcal{C}$는 표본공간
- 받침 $support$ $S$
    - $supp \,P=\{x\in\mathcal{D} : p_X(x) >0\}$
    - $S \subseteq \mathcal{D}$ 의 관계를 갖는다

#### 변수
- 확률변수 Random Variable
	- 표본공간의 원소를 실수에 대응시킨 함수값
	- 변수의 종류
		- 수치형 변수: 정량적인 값으로 표현할 수 있는 데이터
			- 이산형 변수: 1마리,2마리와 같이 정수값만 가질 수 있는 데이터
			- 연속형 변수: 2.3cm, 4.5kg과 같이 실수값을 가질 수 있는 데이터
			- 수치형 변수는 때떄로 값을 몇개의 범위로 분할하여 지정할 수 있고, 이를 계급 class라 한다
		- 카테고리형 변수: 정량적인 수치로 표현할 수 없는 데이터
		
-  확률분포 Probability Distribution
	- 확률변수와 그 값이 나올 확률을 대응시킨 함수
	- 이때 모집단이 따르는 확률분포를 모집단분포 Population Distribution이 되는데, 추론통계학에서 주로 알아내고자 하는 대상이 된다
	
	- 확률분포의 수학적 정의
		- 확률집합함수 $Probability \,\,Set \,\,Function$
			- 조건
				- $\mathcal{C}$: 표본공간
				- $\mathcal{B}$ : 사건의 집합
				- $P$ : $\mathcal{B}$ 상의 정의된 실함수
			- 정의: 다음의 세 조건을 만족시키면 $P$를 확률집합함수라고 부른다
				- 모든 $A\in \mathcal{B}$에 대해 $P(A) \ge 0$
				- $P(\mathcal{C})=1$
				- 만약 $\{A_n \}$이 $\mathcal{B}$의 사건열이고 모든 $m \ne n$에 대해 $A_m \cap A_n = \emptyset$ 이면 $P(\cup_{n=1}^{\infty}A_n)=\sum_{n=1}^{\infty}P(A_n)$ 이다
					- $ref.$ 모든 $m \ne n$에 대해 $A_m \cap A_n = \emptyset$ 이면 서로 배타적 $mutually\,\,exclusively$이라고 하며 이 모임의 합집합은 배반인 합집합$disjoint\,\,unioin$으로 공통의 원소가 존재하지 않는다
			- 이에 따라오는 성질들
				- 조건
					- $A,B \in \mathcal{B}$ 이다
				- 정리
					- $P(A)=1-P(A^c)$ 이다
					- $P(\emptyset)=0$ 이다
					- $A\subseteq B$ 이면 $P(A) \le P(B)$ 이다
					- $0\le P(A) \le 1$ 이다
					- $P(A\cup B)= P(A)+P(B)-P(A\cap B)$
				- 증명
					- $\mathcal{C}= A\cup A^c$ 이고 $A \cap A^c =\emptyset$ 이므로 $1=P(A)+P(A^c)$
					- $\mathcal{C} \cap \emptyset=\mathcal{C}$ ,  $\mathcal{C} \cap \emptyset =\emptyset$ 이므로 $1=P(\mathcal{C})+P(\emptyset)$
					- $B=(B\cap A) \cup (B \cap A^c)$, $B \cap A= A$, $P(B \cap A^c) \ge 0$ 이므로
						- $P(B)=P(A)+P(B \cap A^c) \ge P(A)$
					- 임의의 사건 $A \in \mathcal{B}$는 $\emptyset \le A \le \mathcal{C}$ 이므로
						- $P(\emptyset) \le P(A) \le P( \mathcal{C})  \,\,\,, 0 \le P(A) \le 1$
					- $A\cup B =A \cup (A^c \cap B)$
						- $B=(A\cap B) \cup (A^c \cap B)$ 이므로 $P(B)=P(A \cap B)+P(A^c\cap B)$
						- $P(A \cup B)=P(A)+P(A^c \cap B) =P(A)+P(B)-P(A\cap B)$
					
		- 확률질량함수 $Probability \,\,Mass\,\,Function$
			- 조건
				- 공간 $\mathcal{D}$를 가진 이산형 확률변수 $X$가 있다 하자
			- 정의
				- $x\in \mathcal{D}$에 대해 $p_X(x)=P[X=x]$
			- 이에 따라오는 성질
				- $0 \le p_X(x) \le 1, x \in \mathcal{D}$
				- $\sum_{x\in \mathcal{D}}p_X(x)=1$
				
		- 확률밀도함수 $Probability \,\,Density \,\,Function$
			- 조건
				- 공간 $\mathcal{D}= \mathbb{R}$을 가진 연속형 확률변수 $X$가 있다하자
				- (연속형 확률변수란 확률변수 $X$의  누적분포함수 $F_X(x)$가 모든 $x\in \mathbb{R}$에 대해 연속함수인 경우를 지칭한다)
			- 정의
				- $f(x)= \displaystyle\frac{d}{dx}F_X(x)=\displaystyle\frac{d}{dx} \displaystyle\int_{-\infty}^{x} f_X(t)dt$  를 만족하는
					- $f(x)$를 확률밀도함수라고 정의한다
			- 이에 따라오는 성질
				- $f_X(x) \ge 0$
				- $\displaystyle\int_{-\infty}^{\infty} f_X(t)dt=1$

- 도수 Frequency
	- 관심있는 데이터가 등장한 횟수
- 상대 도수 Relative Frequency
	- 관심 있는 데이터가 등장한 횟수/ 전체 데이터의 수 비율

#### 방법들
- 샘플링 Sampling
	- 모집단에서 표본을 얻는 과정
- 전수조사 Census
	- 모집단 전체를 조사하는 방법
- 표본조사 Sample Survey
	- 모집단의 일부만 조사하는 것 
- 시행 trial
	- 1회의 조사를 수행하는 것
	- 일반적으로 하나의 표본평균을 측정하는 것을 1회 시행하였다고 한다

#### 통계량 Statistic
- 데이터셋의 값을 집계하여 나타내는 값
- 통계량의 종류
	- 평균값 Mean 
		- $\mu=\displaystyle\frac{1}{N}\displaystyle\sum_{i=1}^{N}{x_i}$, 이때 $N$ 는 샘플 데이터셋의 크기
		- 확률이란 개념이 포함되지 않은 상태에서 정의된다
		
	- 기대값 Expectation Value
		- $\mu=\displaystyle\sum_{i=1}^{N}{P(x_{i})\cdot x_i}$
		- 어떤 확률과정을 무한히 반복하였을 때, 얻을수 있는 평균으로 기대되는 값
	
	- 분산 Variance
		- 데이터들이 평균으로부터 얼마나 떨어져있는가를 측정하는 척도
		- 모분산 Population Variance
			- $\sigma^2=\displaystyle\frac{1}{N}\displaystyle\sum_{i=1}^{N}{(x_i-\mu)^2}$
			- $\sigma^2=\displaystyle\sum_{i=1}^{N}P(x_i){(x_i-\mu)^2}$
			- 전체 데이터가 모평균으로 부터 얼마나 벗어나있는지를 측정하는 척도
			
		- 표본분산 Sample Variance
			- $s^2=\displaystyle\frac{1}{N-1}\displaystyle\sum_{i=1}^{N}{(x_{i}-E(x_{i}))^2}$
			- 표본 데이터가 기대값으로부터 얼마나 벗어나있는지 측정하는 척도
			- 표본분산의 기댓값이 모분산과 같게 하기 위하여 샘플의 크기 $N$ 대신 $N-1$로 나누는 특징을 갖는다
			
		- 공분산 Covariance
			- $Cov(x,y)=\displaystyle\frac{1}{N}\displaystyle\sum_{i=1}^{N}{(x_{i}-\mu_{x})(y_{i}-\mu_y)}$
			- $Cov(x,y)=E[(x-E(x))(y-E(y))]$
			- 2개 이상의 연속확률변수의 선형적 관계를 측정하는 척도이다
			
		- 표본 공분산 Sample Covaraince
			- $S_{xy}^{2}=\displaystyle\frac{1}{N-1}\displaystyle\sum_{i=1}^{N}{(x_{i}-\mu_{x})(y_{i}-\mu_{y})}$
			
		- 분산- 공분산 행렬 Variance-Covariance Matrix
			- $Cov(x,y)=\begin{bmatrix} \sigma_{x}^2 & Cov(x,y) \\ Cov(x,y) & \sigma_{y}^2 \end{bmatrix}$
			
		- 피어슨 상관계수 Pearson Correlation Coefficient
			- $\rho_{xy}=\displaystyle\frac{Cov(x,y)}{\sqrt{\sigma_{x}^{2}\sigma_{y}^{2}}}$
			- 공분산의 최대값을 1, 최솟값이 -1이 되도록 표준화 시킨 값
		
		- 표본 피어슨 상관계수 Sample PCC
			- $r_{xy}=\displaystyle\frac{\displaystyle\frac{\displaystyle\sum_{i=1}^{N}{(x_{i}-E(x))(y_i-E(y))}}{N-1}}{\sqrt{\displaystyle\frac{\displaystyle\sum_{i=1}^{N}{(x_i-E(x))^2}}{N-1}}\sqrt{\displaystyle\frac{\displaystyle\sum_{i=1}^{N}{(y_{i}-E(y))^2}}{N-1}}}=\displaystyle\frac{\displaystyle\sum_{i=1}^{n}{(x_{i}-E(x))(y_{i}-E(y))}}{\sqrt{\displaystyle\sum_{i=1}^{N}{(x_i-E(x))^2}}\sqrt{\displaystyle\sum_{i=1}^{N}({y_{i}-E(y))^2}}}$
			-  계산하면 알수 있지만 $N$이나 $N-1$이나 $r_{xy}$의 계산값이 동일하므로, 피어슨 상관계수와 표본 피어슨 상관계수의 값은 동일하다.
			
		- 표준오차 Standard Error
			- 표본 통계량의 표준 편차
			- 통계량 추정치에 대한 불확실정도를 정량화한 것이다

#### 모수 Population Parameter
- 모집단을 분석하여 측정할 수 있는 모집단의 특성값들
- 주로 확률분포를 결정하는 parameter로서 활용된다


#### 추측 통계학의 3가지 추측
- 추정 $estimation$
	- 표본데이터를 활용 및 분석하여 모수를 추론해내는 것
		 - 점추정
			- 모수의 값에 가깝다 예상되는 하나의 값을 추정하는 것
		  - 구간추정
			 - 모수를 포함할 구간과 그 구간에 있을 확률을 추정하는 것
	
- 예측 $predict$
	- 모델을 사용하여 새 데이터 포인트에 대한 결과를 예측하는 것
	- 예측 과정
		- 모델링: 여러 모델과 파라미터들을 고려한다
		- 모델 선택: 그중 최고의 퍼포먼스를 보이는 모델을 선택한다
		- 예측: 선택한 최적한 모델에 데이터를 사용하여 원하는 정보를 예측한다
	
- 추론 $inference$
	- 독립변수가 종속변수에 어떻게 영향을 미쳤는지 탐구하고 모델을 개선하는 것

### 추측 통계학에서의 3가지 차이

- 편차 $deviation$
	- 모집단 평균과 관측치 사이의 차이
	
- 잔차 $residual$
	- 표본의 회귀식으로 추정한 값과  관측값 사이 차이
		- $y_{i}-\hat{y_{i}}$
	- 이때 잔차제곱합 Residual Sum of Square를  다음과 같이 계산한다
		- $RSS= \displaystyle\sum_{i=1}^{n}{(y_{i}-\hat{y_{i}})^2}$
	
- 오차$error$
	- 모집단의 회귀식으로 추정한 값과 관측값 사이 차이(실수를 하지 않은 관측)
	- 표준오차
	    - 모수 예측값과 표본평균(추정된 통계량) 사이의 차이
	    - 표본평균의 표준편차

### 자유도
- 통계학에서 자유도란 계산의 자유도로 '서로 독립적인 정보의 수'를 의미한다
- 예
	- 표본분산의 자유도는 표본의 갯수$n$-1인가?
		- 표본 $x_1,x_2,x_3$ 가 있다 하자. 그리고 표본평균 $\bar{x}=\displaystyle\frac{x_1+x_2+x_3}{3}$ 이라하자
		- $s^2=\displaystyle\frac{(\bar{x}-x_1)^2+(\bar{x}-x_2)^2+(\bar{x}-x_3)^2}{2}$
		- 이 식에서 $x_1,x_2,x_3$ 라는 3개의 변수가 있었다. 이때 평균 $\bar{x}$ 의 값이 주어진다음에 $x_1,x_2$의 값을 정한다고 하자. 그러면 $x_3$는 자동으로 값이 정해지기 때문에 기존의 자유도에서 1이 줄어든다고 설명할 수 있다

## 3. 통계학의 주요 정리

### 중심극한정리 Central Limit Theorem
- 표본의 크기 $N$이 커지면 커질수록, 표본 평균의 분포는 모집단의 분포모양에 관계없이 정규분포에 가까워진다는 정리이다
- 이때 표본 평균의 기댓값은 모평균과 같고, 표본평균의 표준편차는 모표준편차에서 표본크기 $N$의 제곱근으로 나눈값과 같다
- 조건
	- 독립항등분포$i.i.d$를 따르는 확률변수 $x_1,x_2,...,x_n$이 있다하자
		- (독립항등분포 independent and identically distributed: 확률변수 $X_1,X_2,...,X_n$ 들이 모두 서로 상호독립적이며, 동일한 확률분포에서 추출되었을 것이라는 가정 ) 
	- 각각의 변수들은 평균과 표준편차가 각각  $\mu,\sigma$인 모수 분포로부터 추출되었다고 하자
- 결론
	- $Z=\lim_{n\to \infty}{\displaystyle\frac{\bar{X_n}-\mu}{\sigma_{\bar{X}}}}$( $\bar{X}=\displaystyle\frac{1}{n}\displaystyle\sum_{i=1}^{n}{X_i}$ ,$\sigma_{\bar{X}}=\displaystyle\frac{\sigma}{\sqrt{n}}$ )은 표준정규분포를 향해간다
	- 표본평균의 표준편차 $\sigma_{\bar{X}}$ 는 표준오차 $SE$ 라고도 불린다

### 큰수의 법칙 Law of Large Numbers
- 표본의 크기 $N$이 커질수록 표본 평균의 값이 모평균에 가까워질 가능성이 높다는 정리이다
- $\lim{n\to \infty}\,\,P(|\bar{X}_{n}-\mu|< \epsilon)=1$


