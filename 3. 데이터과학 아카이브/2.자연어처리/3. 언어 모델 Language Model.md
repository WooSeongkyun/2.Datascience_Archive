## 언어모델이란?
-  언어 모델은 단어 시퀀스에 확률을 할당(assign) 하는 것이다
-  언어 모델링(Language Modeling) 은 주어진 단어들로부터 아직 모르는 단어를 예측하는 작업이다
- 방법론들
	- 방법론1. 언어 모델이 이전 단어들이 주어졌을 때 다음 단어를 예측하도록 하기
	-   방법론2.  주어진 양쪽의 단어들로부터 가운데 비어있는 단어를 예측하도록 하기(문장의 가운데에 있는 단어를 비워놓고 양쪽의 문맥을 통해서 빈 칸의 단어인지 맞춤)
    

## 카운트 기반 접근의 한계 - 희소 문제(Sparsity Problem)
- 코퍼스에 나온 단어 시퀀스를 카운트하여 확률을 계산하는 방식으로 학습시킨다고 하자. 현실에서의 단어 시퀀스 확률 분포와 가까울정도가 나올려면 대량의 코퍼스를 필요로 한다. 그러나 현실적으로 그러한 데이터를 확보하는 것은 무리가 있고, 이러한 데이터 부족으로 발생되는 문제를 희소 문제 sparsity problem이라 한다
- 완화법 (희소 문제에 대한 근본적인 해결책은 되지 못함)
	- n-gram 언어 모델
	- 스무딩
	- 백오프 등의 일반화(generalization) 기법 
    -> 이러한 한계로 인해 언어 모델의 트렌드는 통계적 언어 모델에서 인공 신경망 언어 모델로 넘어


## N-gram 언어 모델(N-gram Language Model)
-  카운팅 기반 확률을 계산할 때 앞선 모델과 달리 모든 단어를 고려하는 것이 아니라 N개의 단어만 고려하는 접근 방법을 사용한다.
- 앞선 $N-1$개의 단어들을 고려하여 다음에 올 단어의 확률을 계산한다
- N을 작게 선택하면 훈련 코퍼스에서 카운트는 잘 되겠지만 근사의 정확도는 현실의 확률분포와 멀어진다. 그렇기 때문에 적절한 N을 선택해야 한다. 앞서 언급한 trade-off 문제로 인해 정확도를 높이려면 **n은 최대 5를 넘게 잡아서는 안 된다고 권장**되고 있다.

## 한국어에서의 언어 모델(Language Model for Korean Sentences)  
- 영어나 기타 언어에 비해 한국어는 언어 모델로 다음 단어를 예측하기가 훨씬 까다로움


### 1. 한국어는 어순이 중요하지 않다.
-   어순이 중요하지 않아, 이전 단어가 주어졌을때 다음 단어가 나타날 확률을 구해야하는데 다음 단어로 어떤 단어든 등장할 수 있음
    
-   예
    -   ① 나는 운동을 합니다 체육관에서.
    -   ② 나는 체육관에서 운동을 합니다.
    -   ③ 체육관에서 운동을 합니다.
    -   ④ 나는 운동을 체육관에서 합니다.
-   4개의 문장은 전부 의미가 통함
    
-   단어 순서를 뒤죽박죽으로 바꾸어놔도 한국어는 의미가 전달 됨
-   확률에 기반한 언어 모델이 제대로 다음 단어를 예측하기가 어려움

### 2. 한국어는 교착어이다.  
- 교착어(膠着語, 영어: agglutinative language)는 어근과 접사에 의해 단어의 기능이 결정되는 언어의 형태 (위키백과, 우리 모두의 백과사전)  
- 띄어쓰기 단위인 어절 단위로 토큰화를 할 경우 문장에서 발생가능한 단어의 수가 굉장히 늘어남  
- 예: 교착어인 한국어의 조사 (영어는 조사가 없음)  
  - 어떤 행동을 하는 동사의 주어나 목적어를 위해서 조사가 있음  
  - '그녀' -> 그녀가, 그녀를, 그녀의, 그녀와, 그녀로, 그녀께서, 그녀처럼 등  
  - -> 한국어에서는 토큰화를 통해 접사나 조사 등을 분리하는 것은 중요한 작업임

  ### 3. 한국어는 띄어쓰기가 제대로 지켜지지 않는다.
-   한국어는 띄어쓰기를 제대로 하지 않아도 의미가 전달됨
-   한국어 코퍼스는 띄어쓰기가 제대로 지켜지지 않는 경우가 많음
-   토큰이 제대로 분리 되지 않는채 훈련 데이터로 사용되면 언어 모델이 제대로 동작 불가


##  펄플렉서티(Perplexity, PPL)
-   두 개의 모델 A, B의 성능을 비교하기 위해 오타 교정, 기계 번역 등의 평가에 투입해 볼 수 있음
-   -> 일일히 모델들에 대해서 실제 작업을 시켜보고 정확도를 비교하는 작업은 공수가 너무 많이 드는 작업
-   식으로 계산되는 더 간단한 평가 방법: 모델 내에서 자신의 성능을 수치화하여 결과를 내놓는 펄플렉서티(perplexity)