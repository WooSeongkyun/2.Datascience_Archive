## 1. 딥러닝의 정의
- 인공지능 Artificial Intellgience 
	- 문제를 인식하고 해결할 수 있는 능력인 지능을 구현하는 기술
- 머신러닝 Machine Learning
	- 기계 스스로 학습하여 지능을 습득하는 기술.
	- 학습 알고리즘을 통해 데이터에 숨겨진 정보와 규칙을 스스로 학습하고, 이를 통해 새로운 것을 예측하는 기술이다
- 딥러닝 Deep Learning
	- 생체 신경망을 모방하여 만든 인공 신경망 Artificial Neural Network 를 활용한 머신러닝 기술
	- 전통적인 머신러닝 기법이 특정한 문제에 맞게 알고리즘이 특화된 것에 반해 딥러닝은 데이터의 복잡한 관계를 잘 표현하므로 다양한 문제에 보편적으로 활용될 수 있다

### 머신러닝 기법 분류
- 지도 학습 Supervised Learning
	- 정답을 학습 데이터에서 제공받는 학습방법이다
	- 데이터를 분류classification 하거나 데이터의 함수적 관계를 알아내는 회귀 regression 등으로 응용된다
- 비지도 학습 Unsupervised Learning
	- 정답을 학습 데이터에서 제공받지 않는 학습법이다
	- 비슷한 데이터끼리 묶는 클러스터링 clustering , 고차원 데이터를 저차원 데이터로 변환하는 차원 축소 dimension reduction, 데이터의 핵심 정보를 낮은 차원의 잠재 데이터로 표현하는 표현 학습 representation learning, 새로운 데이터를 생성하는 데이터 생성 data generation, 데이터간의 규칙을 찾는 연관 규칙 association rule, 협업 필터링 collaborative filtering 등이 있다
- 강화 학습  Reinforcement Learning
	- 순차적인 의사결정문제sequential decision problem을 다룬다
	- 현재 의사결정이 미래에 영향을 미칠 때 목표를 달성하기 위한 순차적인 의사결정 방법을 학습한다. 
	- 행동 심리학의 '보상과 강화가 행동 형성 과정에 큰 영향을 미친다'는 행동강화이론을 토대로 보상을 최대화하는 행동을 선택하는 것이다.
	- 비디오 게임, 보드게임 분야나 기기 및 로봇제어, 자율 주행과 같이 전문가의 행동을 모방하는 모방학습, 추천 시스템 분야에서도 활용하여 점점 적용 범위가 확장되어 가고 있다

### 딥러닝의 장점과 한계
- 장점
	- 함수를 근사하는 능력이 뛰어나다
		- 딥러닝은 범용적인 함수 근사능력을 갖고 있으므로, 복잡한 형태의 비선형 함수를 근사하거나, 기존 ML 기법으로 한계가 있는 클래스간 경계 분류에 뛰어난 성능을 보인다
	- 특성을 자동으로 추출한다
		- 기존 ML 방법을 사용할 땐 도메인 전문가가 모델에 입력할 특징을 설계하고, 데이터에서 직접 특징을 추출 feature extraction 해야 한다. 그러나 인공 신경망은 중요한 특징에선 높은 가중치를, 중요도가 떨어지는 특징에는 낮은 가중치를 부여함으로서 특징을 자동으로 추출한다. 그 결과 사람에서 발생되는 편향을 줄일 수 있다
	- 모델의 확장성이 뛰어나다
		- 뉴런의 연산이 병렬처리가 가능한 구조로 되어있어, 모델을 대규모로 확장하기 쉽다
	- 기존 ML보다 훨씬 좋은 성능을 보인다
		- 딥러닝은 이미지 분류, 객체 탐지, 비전 분야에서 오래전부터 인간의 인지능력을 뛰어넘는 성능을 보인다
		- 이미지 처리, 자연어 처리, 음성 인식과 같은 분야에서 성능적 발전이 급격히 이루어지면서 광범위한 분야에 실용적으로 응용되고 있다
- 단점
	- 딥러닝은 파라미터parameter가 많기 때문에 다른 머신러닝 모델보다 상대적으로 많은 학습 데이터가 필요하다
		- 대게 AI 제품 및 서비스의 성능이 데이터에 달려있다 해도 과언이 아닐 정도이다
	- 딥러닝은 훈련을 위한 시간과 비용이 든다
		- 다만 이런 훈련과 비용을 줄이기 위해, 데용량 데이터로 사전에 학습된 모델을 이용하여 빠르게 학습하는 전이 학습 transfer learning 방법이 연구되고 있다. 이를 활용하면 적은 양의 데이터로 모델을 빠르게 튜닝하여 새로운 목적에 맞게 활용할 수 있다
		- 또한 여러 작업의 학습방법을 학습하는 메타학습 meta learning 또한 그 중요도가 올라가고 있다
	- 딥러닝 모델에는 설정 파라미터가 많아 최적의 모델과 훈련방법을 찾기 위해선 상당히 많은 검색 시간과 튜닝 시간이 필요하다.
	- 인공 신경망 모델은 오류를 파악하거나 디버깅 하기 어렵다. 
		- 설명가능한 인공지능 XAI 분야에선 신경망 모델 내부에서 일어나는 일이 무엇인지 확인할 수 있는 기법들을 연구하고 있다
	- 지도학습에선 타깃데이터를 만드는 비용이 만만치 않다
		- 그래서 생성 모델을 활용하여 훈련 데이터를 자동으로 생성하거나, 레이블과 논레이블 데이터를 활용하는 준 지도학습 semi-supervised learning, 학습 과정에 사람이 개입하지 않는 자기지도 학습 self-supervised learning 등에 대한 관심이 커져가고 있다


### 뇌: 생체 신경망의 연구
- 지능은 어떤 문제에 당면하였을 때 자신의 지식과 경험을 활용하여 문제를 해결하는 능력이다
- 인간은 다른 동물과 비교할 수 없을 정도로 높은 지능을 갖는다. 유전학적으로 가장 가까운 침팬치와 비교하였을 때 3배에 달하는 대뇌피질을 갖고 있다. 
- 지능을 모방하고자 할 때 가장 자연스럽게 떠오르는 방법이 바로 생체 지능을 모방하는 것이다.
- 생물학적 뇌의 연구
	- 1890년대 부터 현미경과 염색법이 개발되어 신경 세포인 뉴런의 존재를 알게 되었다. 20세기 부터 뇌의 각 영역은 특정 기능을 담당한다는 구조 이론이 성립되고, 1960년대부터 학습과 기억 저장에 대한 뉴런의 생화학적 연구를 계속하였다
	- 생체 신경망은 외부로부터 들어온 자극을 뇌에 전달하고, 뇌는 기억에 저장된 경험을 활용하여 새로운 자극에 대한 반응을 명령한다.
	- 뉴런에 같은 자극이 반복되면 소포체와 수용체 수가 점점 늘어나, 신경 전달 물질을 원활히 전달할 수 있는 구조로 변화하는데, 이 성질을 시냅스 가소성 plasticity라고 한다
	- 사람의 두뇌는 대뇌,소뇌,뇌간,변연계로 나뉘고 이중 지능인 대뇌랑 관련되어 있다. 대뇌의 겉부분은 전두엽, 두정엽, 측두엽, 후두엽으로 나뉘어진다

### 인공신경망의 역사
- 1956년 스스로 학습하는 인공 신경망 perceptron이 등장하였다. 그후 2006년이 되어서야 딥러닝이란 용어가 등장하게 된다
- 최초의 신경망 모델은 매컬리-피츠 McCulloch-Pitts 모델로, 인간의 신경계를 범용 계산 장치로 묘사한 모델이다. 이들은 활성 사태와 비활성 상태를 갖는 이진 뉴런으로 구성된 신경망이 튜링 머신과 동등한 연산을 수행할 수 있는가를 증명하였다
- 프랭크 로젠블릿 Frank Rosenblatt는 헵의 학습 가설에 따라 스스로 문제에 따라 인공지능이 학습하는 모델인 퍼셉트론 perceptron을 개발하였다. 퍼셉트론은 알파벳과 숫자를 인식하는데 성공하였다
- 퍼셉트론의 형태는 $y=f(\mathbf{\beta}^T\mathbf{x}+\mathbf{b})$ 의 형태로, 이떄 활성함수로 계단함수 $f(x)=1 \,\,if \,\,  x \ge 0 \,\,else \,\,0$ 를 활용하였다. 이는 현대 인공뉴런까지 활성함수를 제외하곤 변하지 않고 유지되고 있다
- 퍼셉트론은 두 종류의 클래스를 분류하는 선형 분류 linear classifier로, $\mathbf{\beta}^{T}\mathbf{x} +\mathbf{b}$  는 결정 경계를 이루는 직선의 방적식이다. 가중치 $\mathbf{\beta}$ 는 직선의 법선 벡터 normal vector 인 것이다. 직선을 경계로 법선 벡터 방향의 데이터포인트들은 계단 함수 실행 결과가 1이 되어 클래스 1로 분류되고, 법선 벡터 반대 방향에 있는 점들은 계단 함수 실행결과가 0 이 되어 클래스 2로 분류된다 
- 생체 신경망과의 비교
	-  $\mathbf{x}$  : 이전 뉴런에서 발화된 신호
	- $\mathbf{\beta}$ : 생체 신경망에서 두 시냅스 사이 연결 강도
	- 수상 돌기를 통해 동시에 신호가 시포체에 모이는 과정 :퍼셉트론 가중 합산과정
	- 생체 뉴런에서 세포체에 모인 신호가 임계치가 섬었을 때 새로운 신호 발화:퍼셉트론의 활성함수 실행

### 신경망 연구의 암흑기를 불러온 책: 퍼셉트론
- 기호주의 symbolism
	- 실세계의 사물과 사물을 기호화하고 그 둘 사이 관계를 정해주면 논리적 추론을 통해 지능을 만들 수 있다
- 연결주의 connectionism
	- 뉴런 수준에서부터 지능이 형성되는 과정을 모방하면 데이터로부터 스스로 지능을 만들 수 있다
- 퍼셉트론
	- 기호주의 학파의 수장이였던 마빈 민스키와 시모어 페퍼트가 쓴 퍼셉트론이란 책은 퍼셉트론이 비선형 문제를 풀 수 없다는 한계를 지적하고 이를 입증하였다. 이 비판이 신경망 연구에 대한 비관적 분위기를 형성하면서 약 20년간 신경망 연구에 대한 투자가 동결되고 신경망 연구의 암흑기가 찾아왔다
- XOR 논리 연산으로 제기된 다층 퍼셉트론의 필요성
	- 퍼셉트론이 비선형 문제를 풀수 없음을 증명했을 때 사용한 예는 XOR 논리 연산문제이다. XOR 논리 연산은 두 논리값이 참이거나 거짓이면 결과가 거짓이고, 하나씩 각각 참과 거짓일 때 결과가 참이된다
	- 좌표평면상에 나타내면$\begin{bmatrix} 0,0 \end{bmatrix},\begin{bmatrix} 0,1 \end{bmatrix}, \begin{bmatrix} 1,0 \end{bmatrix}, \begin{bmatrix} 1,1 \end{bmatrix}$ 이고 이때 $\begin{bmatrix} 0,1 \end{bmatrix}, \begin{bmatrix} 1,0 \end{bmatrix}$ 만 결과가 참인 상태로 이를 분류하기 위해 영역을 구분하려면 구분선 두개로 띄 모양을 만들어야 한다.
	- 띄 모양의 영역을 표시하기 위해선, 각 경계선에 대한 퍼셉트론을 만들고, 이를 AND연산으로 묶어줘야 한다

### 역전파 알고리즘의 발견
- 1974년 폴 워보스는 박사학위 논문에서 다층 퍼셉트론을 학습시킬 수 있는 역전파backpropagation 알고리즘을 제안한다. 안타깝게도 당시는 인공신경망 연구 침체기였기 떄문에 제안된 알고리즘의 존재가 알려지지 않았고, 그의 학위 논문은 1982년 논문으로만 발표되고 그치게 된다
- 1985년과 1986년 사이 인공 신경망을 연구하는 과학자들은 역전파 알고리즘을 재발견하게 된다. 
- 역전파 알고리즘이란
	- 인공 신경망은 학습과정에서 출력과 정답의 오차를 최소화하도록 최적화 optimization을 수행한다. 각 파라미터의 오차에 대한 기여도를 측정하고, 이를 미분하여, 오차를 최소화하는 방향으로 파라미터를 조정한다.
- 역전파 알고리즘은 마빈 민스키가 '퍼셉트론'을 통해 지적했던 비선형문제의 풀이를 가능하게 함으로서 딥러닝의 새로운 활로를 열었다

### 딥러닝의 장애물
- 과적합
	- 딥러닝 모델이 학습 데이터셋에만 지나치게 들어맞아, 새로운 데이터에 대해선 예측력이 떨어지는 현상
- 기울기 소실 gradient vanishing
	- 깊은 신경망을 학습시킬 때 역전파과정에서 미분값이 사라지며 학습이 중단되는 현상이다
	- 각 계층에서 계산된 미분값이 0에 가까울수록 아주 작은 숫자가 여러번 곱해져 0으로 수렴하여 미분값이 사라지는 현상이다.
	- 이는 신경망이 깊어질수록 이런 현상이 두드러져 학습에 어려움을 발생시킨다

### 제한적 볼츠만 머신 RBM
- 깊은 신경망을 안정적으로 학습시킬 수 있는 방법을 2006년 제프리 힌턴이 제시한다
- 각 계층을 제한적 볼츠만 머신으로 정의하여 사전 학습 시킨후, 한계층씩 쌓아 만드는 깊은 신경망을 만드는 방식이다
	- 첫번째 계층이 될 RBM1을 사전 학습시킨다. 
	- RBM1의 사전학습이 완료되면 RBM1의 은닉계층을 두번째 계층이 될 RBM2의 입력계층으로 사용하여 RBM2의 가중치를 사전 학습한다
	- 이런 식으로 나머지 RBM도 사전학습을 진행한다
	- 모든 계층의 RBM이 학습되면, 입력 계층과 RBM의 은닉 계층을 싸하 올려 깊은 신뢰 신경망 Deep Belief Network를 만들고, 다시 출력 계층을 추가하여 깊은 신경망을 완성시킨다