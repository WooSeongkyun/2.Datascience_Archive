
## 신경망과 행렬의 관계

![](입력3_출력2_신경망_행렬.png)

- 입력층 뉴런이 3개 출력층의 뉴런이 2개, 활성화함수는 소프트맥스인 기초적 형태의 신경망을 고려해보자
- 이때 파라미터의 갯수는 (입력층 뉴런수 +1)$\times$ (출력층 뉴런수)로 이 경우 8개이다
- 이때 입력벡터와 곱해지는 계수행렬을 가중치 행렬 $W$ Weigh Matrix 라 부르고, 절편들을 담은 벡터를 편향 $b$ bias라고 한다. 또 다른 표기법으론 편향을 따로 두는 대신 입력벡터를 $[1,x_1,x_2,x_3]$ , 가중치행렬을 $\begin{bmatrix}b_{1} & b_{2} \\ w_{1} & w_4 \\ w_{2} & w_{5} \\ w_{3} & w_{6} \\ \end{bmatrix}$ 로 표기하는 방식도 있다


![](입력3_출력2_병렬연산.png)
- 행렬곱을 사용하면 병렬연산(여러개의 데이터 샘플을 동시에 연산)할 수 있다



## 딥러닝의 학습 방법
- 손실함수 Loss function
	- 실제값과 예측값의 차이를 수치화하는 함수
	- 분류에서는 주로 크로스 엔트로피를, 회귀에서는 주로 평균 제곱 오차를 사용한다

### 손실함수의 종류
- 분류
	- 이진 크로스 엔트로피 Binary Cross Entropy
		- `metric=['binary_crossentropy']` 
			- 출력층이 시그모이드인 이진분류모델에서 활용된다.
	- 카테고리컬 크로스 엔트로피 Categoical Cross Entropy
		- `metric=['categorical_crossentropy']`
		- 출력층이 소프트맥스인 다중분류모델에서 사용된다
- 회귀
	- MSE(Mean Squared Error)
		- `metrics=['mse']` 를 통해 사용가능
		- 주로 연속형 변수를 예측할 때 사용된다


### 배치 크기Batch에 따른 경사하강법 
- 배치: 가중치등의 매개변수 값을 조정하기 위해 사용되는 데이터의 양
- 배치 하강법의 종류
	- 배치 경사 하강법 Batch Gradient Descent
		- 옵티마이저중 하나로, 오차 하나를 구할 때 전체 데이터를 고려하는 방법.
		- 전체 데이터에 대한 한번의 훈련횟수를 1에포크라 하는데 , 이 훈련법은 1에포크당 한번의 매개변수 업데이트만 있어서 시간이 상당히 오래걸리게 된다
	- 확률적 경사하강법 SGD(Stochastic Gradient Descent)
		- 매개변수 값의 조정을 조정하기 위해 전체 데이터가 아니라 랜덤으로 하나의 데이터만 사용하는 방법. 
		- 매개변수 변경폭이 불안정하고, 배치 경사 하강법보다 정확도가 낮을 수 있지만, 상대적으로 적은 메모리로 사용가능하다는 장점이 있다
	- 미니 배치 경사 하강법 Mini-Batch Gardient Descent
		- 전체 데이터도, 1개 데이터도 아닌 특정 데이터 갯수만큼 배치 사이즈를 정하는 방법

> Ref. 경사하강법의 알고리즘
- 경사하강법의 정의  
	- $x_{i,j+1}= x_{i,j} - \alpha \nabla f(x_{i,j})$=  
	- $i$ 번째 변수의 $j$번째 값을 갱신할때 다음과 같은 공식을 활용한다. 이때 $\alpha$는 hyperparameter이다  
- 비용함수에서의 경사하강법  
	- $J(\theta)= \displaystyle\frac{1}{N}*\sum_{i}(y_i-x_i\theta+\phi_i)^2$ 
	- $\displaystyle\frac{\partial{J}}{\partial{\theta}}=\displaystyle\frac{2}{N}(y_i-\theta)$
	- $\theta_{i,j+1}= \theta_{i,j}-\alpha\displaystyle\frac{2}{N}\cdot\sum_{i}x_i(y_i-x_i\theta_{i,j})$
	- $\phi_{i,j+1}= \phi_{i,j}-\alpha\displaystyle\frac{2}{N}\cdot\sum_{i}(y_i-x_i\theta_{i,j})$
	- (여기서 $\theta$는 가중치weight, $\phi$는 편향bias이다)

### 옵티마이저
- 모멘텀 Momentum 
	- $v_{n}= \alpha v_{n-1}-\eta\nabla f(x_n),\,\,\,\,v_{-1}=0$
	- $x_{n+1}=x_n+v_n$
	- 관성(물체가 기존의 운동방향대로 운동하려는 성질)에서 착안해온 알고리즘으로 현 단계의 파라미터 갱신에 전 단계의 파라미터 갱신값 일부를 추가한다
	- 함수 전체 구간에선 최소가 아니지만 어떤 점 근방에서 최솟값을 갖는 경우 그 점을 극솟값Local Minumum(기울기가 0인 성질을 갖는다) 이라 부르는데, 손실함수의 경사하강법 알고리즘에서 우리는 극솟값이 아니라 최솟값(함수 구간 전체에서 최소값)을 구한다. 
		- 경사하강법의 경우 극솟값에 파라미터가 갖히게 되는 문제가 발생될 수 있는데 모멘텀은 이러한 문제를 일부 예방할 수 있다
- 아다그라드 Adagrade
	- $G_t=G_{t−1}+(∇_ΘJ(Θ_t))^2$  
	- $Θ_{t+1}=Θ_{t}−η/√{(G_{t}+ε)}⋅∇_ΘJ(Θ_t)$
	- 각 매개변수에 다른 학습률을 적용시키는 방법
	- 이 알고리즘의 기본적인 아이디어는 ‘지금까지 많이 변화하지 않은 변수들은 step size를 크게 하고, 지금까지 많이 변화했던 변수들은 step size를 작게 하자’ 라는 것이다.
	- 이계도함수를 계산해야 하기 때문에 계산 비용이 많이 든다. 또, Adagrad에는 학습을 진행하면 진행할 수록 학습률이 줄어든다는 문제점이 있다 최솟값에 도달하기도 전에 학습률이 0에 수렴해버릴 수도 있다.
- RMSprop
	-   RMSProp은 Adagrad에서의 G_t 값이 무한히 커지는 단점을 해결하기 위해서 지수 이동평균(exponentially weighted moving average)를 이용한다
	- 아다그레드의 업그레이드 방법이라고 함(원리가 어렵네요..)
- Adam (Adaptive Moment Estimation)
	- 각 파라미터마다 다른 크기의 업데이트를 진행하는 방식
	- RMSProp의 업그레이드 방법이라고 함(원리가 어렵네요..)


## 역전파 이해하기
- 역전파는 출력층에서 입력층 방향으로 계산하면서 가중치를 업데이트 하는 일이다
- 예
	- ![](Pasted%20image%2020220827154429.png)
	- 여기서 $w_5$ 에 대한 업데이트를 진행한다고 해보자
		- $\displaystyle\frac{\partial{E_{total}}}{\partial{w_5}}=\displaystyle\frac{\partial{E_{total}}}{\partial{o_{1}}}\times \displaystyle\frac{\partial{o_1}}{\partial{z_{3}}}\times\displaystyle\frac{\partial{z_3}}{\partial{w_5}}$
		
		- $E_{total}= \displaystyle\frac{1}{2}(target_{0_1}-output_{0_1})^2+\displaystyle\frac{1}{2}(target_{0_2}-output_{0_2})^2$
			-  $\displaystyle\frac{\partial{E_{total}}}{\partial{o_1}}=-(target_{0_1}-output_{0_1})$
		- $\displaystyle\frac{\partial{o_1}}{\partial{z_3}}=o_1\times(1-o_1)$
		- $\displaystyle\frac{\partial{z_3}}{\partial{w_5}}=h_1$
		- $w_5=w_{5}- \alpha\displaystyle\frac{\partial{E_{total}}}{\partial{w_5}}$	
			- 이때 $\alpha$는 학습률 learning rate로 사람이 직접 지정하는 변수이다
		- 이와 같은 방법으로 $w_6,w_7,w_8$ 에 대한 업데이트를 시행할 수 있고, 여기까지를 역전파 1단계BackPropagation Step1라고 칭한다
	- 여기서 $w_1$ 에 대한 업데이트를 진행한다고 해보자
		- $\displaystyle\frac{∂E_{total}}{∂w_{1}} = \displaystyle\frac{∂E_{total}}{∂h_{1}} \text{×} \displaystyle\frac{∂h_{1}}{∂z_{1}} \text{×} \displaystyle\frac{∂z_{1}}{∂w_{1}}$
		-  이와 같은 방법으로 $w_2,w_3,w_4$ 에 대한 업데이트를 시행할 수 있고, 여기까지를 역전파 1단계BackPropagation Step2라고 칭한다



## 과적합 문제 해결하기
- 데이터의 양 늘리기
	- 데이터 양이 적을 경우 노이즈까지 패턴으로 인식해버릴 수 있으므로 과적합 현상이 발생할 확률이 높아진다. 
	- 만약 데이터 양이 적을 경우 의도적으로 기존 데이터를 조금씩 변형하여 추가하는 방식을 사용할 수 있는데 이를 데이터 증강 Data Augmentation 이라고 부른다. 텍스트 데이터의 경우 데이터를 증강후 번역하고, 다시 재번역을 통해 새로운 데이터를 만들어내는 역번역 Back Translation 등의 방법이 있다
- 모델의 복잡도를 줄이기
- 가중치 규제 적용하기
	- $L_1$ 규제: 가중치 $w$ 들의 절대값 합계를 비용함수에 추가하는 방식 
	- $L_2$ 규제: 가중치 $w$ 들의 제곱합을 비용함수에 추가하는 방식
	- 기존 비용함수식에 전자는 $\lambda |w|$  후자는 $\displaystyle\frac{1}{2} \lambda w^2$를 더하여 규제를 하는데, 이때 $\lambda$는 규제의 강도를 정하는 하이퍼파라미터의 기능을 하게 된다. 만약 $\lambda$가 크다면 모델이 훈련 데이터에 대해 적합한 매개 변수를 찾는 것 보다 규제를 위해 추가한 항들을 작게 유지하는 것을 유지한다는 의미가 된다
- 드롭 아웃 Dropout
	- 학습과정에서 일부 신경망을 사용하지 않는 방법이다
	- 매번 랜덤 선택으로 뉴런을 사용하므로, 서로 다른 신경망들을 앙상블하여 사용하는 것과 같은 효과를 내어 과적합을 방지한다
	- 예: 케라스에서 드랍아웃 적용
```python
from tensorflow.keras.models import Sequential  
from tensorflow.keras.layers import Dropout, Dense  
  
max_words = 10000  
num_classes = 46  
  
model = Sequential()  
model.add(Dense(256, input_shape=(max_words,), activation='relu'))  
model.add(Dropout(0.5)) # 드롭아웃 추가. 비율은 50%model.add(Dense(128, activation='relu'))  
model.add(Dropout(0.5)) # 드롭아웃 추가. 비율은 50%model.add(Dense(num_classes, activation='softmax'))
```


## 기울기 소실 Gradient Vanishing 과 폭주 Exploding

-  기울기 소실
	- 역전파 과정에서 입력층으로 갈수록 기울기가 점차 작아져, 입력층에 가까운 층일수록 가중치가 제대로 업데이트가 되지 않는 현상
	- 기울기 소실 완화 방법
		- 은닉층에서 시그모이드 함수를 사용하지 말것. 은닉층에선 ReLU나 그 변형계열 함수를 사용할 것
		- ReLU 대신 Leaky RELU를 사용하여 죽은 ReLU문제를 피할것
		
- 그래디언트 클리핑 Gradient Clipping
	- 기울기 폭주를 막기 위해 특정 기울기 임계값을 넘는 경우 임계치까지만 남기고 절삭시키는 방법
	
- 가중치 초기화 Weight Initialization
	- 같은 모델이더라도 가중치가 초기에 어떤 값을 가졌는가에 따라 모델의 훈련 결과가 달라질 수 있다. 가중치 초기화가 적절히 이루어져도 기울기 소실과 같은 문제를 어느정도 완화할 수 있다
- 배치 정규화 Batch Normalization
	- 인공 신경망에 들어가는 배치단위를  정규화하여 학습을 효율적으로 만드는 것
		- 배치 정규화를 사용하면 시그모이드나 하이퍼볼릭탄젠트 함수를 사용하더라도 기울기 소실 문제가 크게 개선된다
		- 가중치 초기화에 훨씬 덜 민감해 진다
		- 훨씬 큰 학습률을 사용할 수 있어 학습 속도를 개선시킨다
		- 그러나 배치 정규화는 모델을 복잡하게 만들어 테스트 데이터에 대한 예측 시 실행시간이 느려진다. 따라서 서비스 속도를 고려하는 관점에선 배치 정규화가 꼭 필요한지 고민이 필요하다
		- RNN에 적용하기 어렵다
		- 
