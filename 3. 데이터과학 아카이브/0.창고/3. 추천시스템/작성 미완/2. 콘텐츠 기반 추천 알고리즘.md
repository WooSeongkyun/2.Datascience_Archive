

# Course 1. Non-Personalized and Content-Based
- What to expect
	- Learn when and how to recommend items and products based on overall preference and popularity
	- Learn how to construct demographic and stereotyped recommenders
	- Learn how to build content-based filtering recommenders using the vector space model

### MovieLens 홈페이지 형태
- 구성된 형태
	- 화면 형태
		- Top Picks
		- Recent Realased
		- Favorites from the past years
		- your wishlist
	- Predicted Star 표시
	- 본인이 평가한 영화수가 몇개인지 표시
	- 'Change your Recommender'라는  옵션을 통해 추천 알고리즘을 바꿀 수 있음
		- 예: The Warrior, The Wizard ,The Peasant 등이 있었음
	- Personalizae your Recommendations 옵션을 통해 추천 알고리즘을 바꿀 수 있음
		- 예: 'less popular', 'more popular'
	- 다양한 community tag가 존재
		- Dead Pool-dark humor, Funny, antihero, 4th wall, x-men, Marvel, superhero, Action, comic book, ryan reynolds,.. 등
	- 평가 비율을 히스토그램으로 표현함

## Introduction
- recommdender가 어떻게 데이터를 활용하여 유저가 좋아하는 것을 학습하는가
- 유저로부터 어떤 유형의 데이터를 얻을 수 있는가
- 어떤 데이터가 사용 가능하고, 적합한가
- 시스템에 사용되기 용이한 형태의 데이터는 무엇인가

### Preference Model
- preference
	- 유저가 특정 아이템에 대해 선호하는 경향성
	- 개인에 대해 측정할 수도 있고, 집단에 대해 측정할 수도 있다
	- 어떻게 preference를 측정할 수 있는가?
		- Explicit
			- Rating
				- 종류
					- Star Rating (5 Star Scale이 일반적) 
					- Thumbs and Likes (상대적으로 저관여인 매체에서 주로 사용)
				- 한계점
					- 많은 심리학 실험에서 rating을 반복 요구할 때 그 응답값의 차이, noise가 존재한다는 결과를 발견하였다
					- 시간이 지나 유저는 동일한 아이템에 대해 다른 평가를 하게될 수 있다
					- 유저가 메긴 Rating Score는 각자 다른 의미를 내포하고 있을 수 있다
			- Review
			- Vote
		- Implicit (유저 행동을 통해 수집되는 데이터)
			- Click
			- Purchase
			- Follow

## Prediction and Recommendations
- To understand the ways in which recommender output can be used
- To understand the distinction between predictions and recommendations
- To understand the distinction between organic and explicit presentation
- To review examples and understand which presentation makes most sense in difference applications

## Content-Based Recommenders
### Learning Objects
- To understand the range and value of content-based approaches to reccomdendation
	- Pure information filtering system
	- Case-based reasoning systems
	- knowledge- based navigation systems
- Identify situations in which content-based filtering does or does not work well
- Build vector models representing user preferences and item expression in terms of keywords, tags, or other attributes
- Compute recommendations and predictions using 
	- TF-IDF 
	- cosine similarity algorithms

### How to build preferences
- Lets start with the idea of a set of 'keywords'
- we could simply count the number of times the user choose (or fails to choose) items whti each keywords
- or We can get more sophisticated

### Challenges and Drawbacks
- Depend on well-structured attributed that allign with preferences
	- eg: considering patings
- Depend on having a reasonable distribution of attributes across items(and vice versa)
- Significance in Documents
	- Titles, Headings,...에 대한 가중치는 어떻게 할 것인가?
	- 좋은 평판을 가지고 있는 유저는 다른 유저에 비해 얼마나 좋은 가중치를 가져야 하는가?
- Phrases and n-grams
	- 'Computer Science' != 'Computer' + 'Science'
- Implied Content
	- document에서 표현되지 않지만 중요한 내용은 무엇이 있는가?
	- eg: New York Yankees의 스케줄
		- New York Yankees가 Home에서 경기를 하던지, Chicago에서 경기를 하던지를 서술하기 보다는 May 3, 4, 5 at Chicago 6,7,8 host Tampa Bay 라는 식으로 표현한다

### 용어
- Keywords : a piece of metadatas
- Tags: individual words or phrasee that are applied by community

### How does TFIDF apply to CBF
- TFIDF concepts can be used to creat a profile of a document / object
	- eg: A movie could be described as a weighted vector of its tag
- These TFIDF profiles can be combined with ratings to create user profiles, and then matched agianst future documents


### Learning Objectives
- To how to build content-based recommenders based on TFIDF concepts, including:
	- Computing vectors to describe items
	- Building profiles of user preference
	- predicting user interest in items
- To understand key variants in implementing CBF recommenders and their strengths and weaknesses

### Keyword vector
- The universe of possible keywords defines a content space
- 특징
	- Each keyword is a dimension
	- Each item has a position in that space
	- **Each user has a taste profile that is also a vector in that space**
	- The match between user preference and items is measured by how closely the two vectors align
	- May want to limit/collapse keyword space(e.g stem and stop)
		- 어간 추출 Stemming: 정해진 규칙에 따라 어미로 추정되는 단어의 뒷부분을 삭제하는 방법
		- 불용어 stopwords:분석에 필요없는 단어들을 삭제하는 방법
- Challanges and Drawback
	- 키워드 수(차원수)가 많아지면 계산이 어려질 수 있다

### Where choices come into play
- Representing an item through a keyword bector
	- One-Hot encoding (Simple 0/1)
	- Simple occurence count
	- TFIDF 
- e.g: movie
	- Do we consider tags to be yes-or-no
		- Actor(we don't really get a measure for how much 'Tom Hanks' has)
		- Descriptive(is how often a tag is applied a proxy for how relavant/significant the feature is )
	- Do we care about IDF?
		- Actor(are infrequent actors more significant than stars?)
		- Descriptive(is 'prison scene' more significant than 'car chase' or 'romance'?)


### From Items to User Profiles
- Vector Space model conflates liking with importance
	- Works well in some applications(query terms)
- How do we accumulate profiles?
	- Add together the item vectors
	- Do we normalize first
		- Do we believe an item with a more poluated vector is more descriptive of preference? => **Then don't normalize**
		- Do we think all items should be the same weight? => **Then normalize**
	- 

### Limitations
- This is a highly simplified model, cannot handle interdependencies

### Take -aways
- content-based filtering based on assessing the content profile of each item cn be done from metadata or user tagging
- User profiles built by aggregating profiles of items rated/consumed, possibly with a weighting scheme
- Evaluate unrated items by matching item profile against user profile : vector cosine
