### 관련 용어
- 태스크 지향 다이얼로그 Task Oriented Dialog
	- 식당 예약과 같이 뚜렷한 목적이 있는 대화 시나리오
- 칫챗 다이얼로그 Chit-Chat Dialog
	- 아무 목적없이 자유로운 소통을 하는 대화 시나리오
- 발화 utterance
	- 대화를 이루는 문장 그 자체, 대화 시나리오를 처리하기 위해 가공되기 이전 형태를 지칭한다
- 인텐트 intent
	- 발화의 의도
- 컨텍스트 context
	- 대화의 문맥 정보로 사용자의 중의적 표현을 보충하여 사용자의 정확한 질의나 요청을 처리하는데 활용된다
- 슬롯 slot
	- 발화에 포함되어 태스트에 관련된 의미있는 정보
- 인텐트-슬롯 페어 / 페어 intent- slots pair
	- 편의상 인텐트와 슬롯을 쌍으로 묶어 처리하기 위해 사용되는 개념
- 턴 turn 
	- 챗봇에서 대화를 이루는 단위, 마치 탁구에서 서브를 주고 받듯이, 시스템과 사용자가 번갈아 가면서 주고받는 문장을 턴이라고 한다
- 멀티 턴 multi-turn
	- 사용자의 한 턴만으로는 태스트를 해결할 수 없어, 태스크 처리를 위하여 추가적인 정보를 시스템이 질문하고, 사용자가 답변하는 과정
- 팔로업 퀘스쳔 follow up question
	- 사용자의 대화를 진행하기 위해 하는 추가 질문
- 지식 그래프 Knowledge Graph
	- 그래프 형태로 지식을 체계적으로 집적한 것. 
	- 지식 그래프는 데이터를 의미있는 방식으로 통합하고, 의사결정을 지원하는데 사용된다
	- 지식이란 정보를 체계화하고 개념화한 것이다. 체계화를 통해 용어의 목록을 만들고, 용어의 의미, 정의를 정리한 집합을 만든다. 또 용어간의 체계를 만든다.
- Knowledge (Graph) Completion
	- 완전하지 않은 지식 그래프에 누락된 엔티티가 무엇인지 추론하는 기술이다
	- 다음과 같은 3가지의 태스크가 존재한다
		- Triple Classification
			- 주어진 트리플$(h,r,t)$  에 대한 참 거짓을 판별하는 문제이다
		- Link Prediction
			- $\langle {h},{r},t \rangle \,\,or \,\,\langle {?},{r,t} \rangle$ 가 주어졌을 때 누락된 ?가 무엇인지 알아내는 문제이다. 일반적으로 ?에 들어갈 엔티티의 확률을 계산하여 랭킹으로 나열한다
		- Relation Prediction
			- $\langle {h},{r},t \rangle$ 가 주어진 경우 올바른 릴레이션이 무엇인지 찾아내는 방법이다. Link Prediction과 마찬가지로 릴레이션에 대한 확률을 계산한다
- transductive learning 
	- unlabeled training data이 갖고 있는 특성들을 활용하여 새로운 prediction을 할 수 있도록 하는 학습
	- induction 유도/귀납법은 이와는 대조되어 관찰된 학습 데이터에서 테스트 데이터에 적용될 일반적 규칙을 추론하는 것


### Emp-RFT: 
Empathetic Response Generation via Recognizing Feature Transitions between Utterances
- Abstract
	- 발화 간의 기능 전환은 자연스럽게 발생된다
	- 그러나 기존 corase-grained level 로 컨텍스트에서 특징을 추출하는 방법은 대화 맥락의 변화를 읽기 어렵다
	- *우리는 이런 문제를 해결하기 위하여 주의가 필요한 발화의 특징을 더 잘 파악하고, 맥락의 변화가 일어나는 것을 잘 인지할 수 있는 방법을 제시한다*
	- *또한 대화의 감정과 키워드에 맞춰 응답을 생성하는 전략에 대해서도 제시한다*
	- *우리의 접근 방식은 실험결과 multi-turn dialogues에서 큰 개선이 있었음을 보려주었다*
- Introduction
	- 인간은 특정 상황속 타인이 경험하고 느낀 감정에 대해 공감하는 능력을 갖고 있다 그 능력이 타인에게 흥미를 갖고, 또한 위로를 할 수 있게끔 하였다
	- multi-turn empathetic dialogues에선 대화자가 무엇을 느끼고 주로 이야기 하는지에 대한 감정과 키워드들과 같은 특징들이 담겨져 있다
	- 대화가 길어짐에 따라 발화의 특징들은 변화한다
	- 인간들은 이러한 특징의 전환을 본능적으로 인식하고, 대화가 어떤 흐름으로 흘러가는지 이해한다


## Active Learning
on Pre-trained Language Model with Task-Independent Triplet Loss

- Abstract
	- Active Learning이란 unlabled data pool로부터 유용한 정보가 있는 샘플들의 셋을 획득하여, 모델의 성능을 극대화 하는 것이다
	- 이전의 능동학습은 특정 네트워크 아키텍처 또는 task-dependent sample-acquisition algorithms에 의존한다
	- 게다가 배치 샘플을 선택할때마다,각 샘플들의 informative-ness만 고려하였기 때문에, 다양성이 부족한 문제가 발생하였었다
	- 본 논문에서는 triplet loss를 활용하여 유사한 피처를 갖고 있지만, 레이블을 식별하기 어려운 데이터풀속 샘플에 대하여 task-independent batch acquisition 방법을 제시한다.
- Introduction
	- DNN는 다양한 영역에서 전례없는 비약적인 발전을 이루게 해주었다. 특별히 자연어 처리 분야에서. 사전학습된 언어모델인 GPT나 BERT들은 높은 성능을 보여주었었다. 하지만 사전 훈련된 언어 모델들이 대규모 말뭉치로 학습되었음에도, target task를 수행하기 위해선 충분한 양의 지도학습용 데이터가 필요하다. 이러한 자원 부족 문제를 설명하기 위하여, active learning는 점차 많은 연구자들의 관심을 끌기 시작하였다
	- unsupervised와 semi-supervised 학습이 unlabled sample 전체를 활용하는 것에 반해, active learning은 unlabeled sample 일부만 활용한다 
	- active learning의 key challange 는 가장 informative한 unlabeled sample을 찾는 것이다. (여기선 레이블을 붙이고 학습에 사용되었을 때 가장 높은 성능을 갖는 데이터로 정의한다)
	- 작업 분류기가 fixed feature representation에 의존한다면, 다양한 문제를 야기할 수 있다. 또한 분류기의 불안정한 응답에 기반하여 가장 유용한 샘플을 찾는 것 또한 불안정할 것이다

# Open-world knowledge graph completion 
for unseen entities and relations via attentive feature aggregation

- Knowledge Graph는 본질적으로 transductive learning이다. 이렇게 학습된 entitiy와 relation은 많은 KG에서 고정된 것으로 가정되었지만, 시간이 지남에 따라 엔티티와 릴레이션이 계속 추가되고, 삭제되고, 변화되기 때문에 KGC 또한 진화하는(시간에 따라 변동하는)것이 더 적절할 것이다
- 우리가 제안하는 open-world KGC를 위한 Inductive KG Embedding 모델은 KG 외부의 엔티티와 릴레이션도 수용한다. 
- Introduction
	- Knowledge Graph란 현실세계속 사실 정보들을 기계가 이해할 수 있도록 연결한 것이다
	- head entity $h$ 와 tail entitiy $t$ 는 semantic relation $r$ 로 연결되어 있는 구조이다
	- KG는 heterogeneous 한 데이터들을 상호운용하느데 도움이 됨으로써 주목받게 되었다
	- KG는 question answering, recommender system, information extraction, entity linking등의 응용등으로 활용되었다
	- 